{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.7.6 64-bit",
      "language": "python",
      "name": "python37664bit17cc54603a5a49bf946cac7f856dc37b"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Assignment 1_Linear Classifiers.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammad-hosseini-s/Applied-Machine-Learning/blob/master/Assignment_1_Linear_Classifiers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrkV37FOaQPp",
        "colab_type": "text"
      },
      "source": [
        " # Applied Machine Learning, Assignment 1: Linear classiers (Perceptron, SVM)\n",
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCuhCTZuaQPq",
        "colab_type": "text"
      },
      "source": [
        "In this assignment, you will explore linear classication on the forest cover-type dataset created by Jock Blackard et. al. in 1998. It is used frequently enough that scikit-learn has made it a standard dataset.  \n",
        "https://scikit-learn.org/stable/datasets/index.html#covtype-dataset  \n",
        "https://archive.ics.uci.edu/ml/datasets/Covertype  \n",
        "The data set includes 54 features (reals, integers, and booleans) and 7 classications numbered 1-7: spruce/firr, lodgepole pine, Ponderosa pine, cottonwood/willow, aspen, Douglas-fir, and Krummholz. The scikit-learn implementation has converted all of these values to real numbers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqprbWFOaQPr",
        "colab_type": "text"
      },
      "source": [
        "## 1. Importing and Partitioning the Data\n",
        "### 1.1 Get the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mG8x4C5KaQPs",
        "colab_type": "text"
      },
      "source": [
        "Using scikit-learn, import the Forest covertype data set, shuffling it with random state 5984 in the call to fetch it. Set these to X and y."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gU6iBhFwaQPs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "325c6d5b-4e7e-4153-d738-72a7a33fd464"
      },
      "source": [
        "# import libraries\n",
        "%matplotlib inline\n",
        "from sklearn import datasets\n",
        "import pandas as pd  \n",
        "import numpy as np  \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# fetch dataset, set random_state and shuffle\n",
        "covtype = datasets.fetch_covtype(data_home=None, download_if_missing=True, random_state=5984, shuffle=True)\n",
        "X = covtype[\"data\"]\n",
        "y = covtype[\"target\"]\n",
        "\n",
        "print(\"X = \\n\" + str(X) + \"\\n\")\n",
        "print(\"y = \" + str(y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://ndownloader.figshare.com/files/5976039\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "X = \n",
            "[[2903.   87.   27. ...    0.    0.    0.]\n",
            " [2674.   52.   11. ...    0.    0.    0.]\n",
            " [2867.  357.   14. ...    0.    0.    0.]\n",
            " ...\n",
            " [3053.  166.   18. ...    0.    0.    0.]\n",
            " [2981.  352.   18. ...    0.    0.    0.]\n",
            " [3041.   37.    5. ...    0.    0.    0.]]\n",
            "\n",
            "y = [5 2 2 ... 1 2 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dphgT5aVaQPz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "4edb87ff-2118-4efd-c2f8-078e12371884"
      },
      "source": [
        "print(\"X dim =\", X.shape, \"\\ny dim =\", y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X dim = (581012, 54) \n",
            "y dim = (581012,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yULW_7LLaQP7",
        "colab_type": "text"
      },
      "source": [
        "-----\n",
        "### 1.2 Checking the Labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qji78nHcaQP7",
        "colab_type": "text"
      },
      "source": [
        "How many instances of each of the seven classes exist in the data set?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bEDLkEVaQP8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "c7609cd4-ea1f-4d77-8552-e029740975a9"
      },
      "source": [
        "for i in range(1,8):\n",
        "    name = \"instances in class_\" + str(i) + \" =\"\n",
        "    print(name, y[y == i].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "instances in class_1 = (211840,)\n",
            "instances in class_2 = (283301,)\n",
            "instances in class_3 = (35754,)\n",
            "instances in class_4 = (2747,)\n",
            "instances in class_5 = (9493,)\n",
            "instances in class_6 = (17367,)\n",
            "instances in class_7 = (20510,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrDyTprEaQP_",
        "colab_type": "text"
      },
      "source": [
        "-----\n",
        "### 1.3 Choosing Subsets "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w04kV3j-aQQA",
        "colab_type": "text"
      },
      "source": [
        "Create data and label subsets of size 5000, 10000, and 100000, choosing the first\n",
        "N elements of the shu\u000fed imported data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRGnVTFJaQQB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_5k, y_5k = X[0:5000,:], y[0:5000]\n",
        "X_10k, y_10k = X[0:10000,:], y[0:10000]\n",
        "X_100k, y_100k = X[0:100000,:], y[0:100000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4zkmlCoaQQF",
        "colab_type": "text"
      },
      "source": [
        "-----\n",
        "### 1.4 Splitting the Subsets into Training and Test Sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBOitAXCaQQG",
        "colab_type": "text"
      },
      "source": [
        "Use `train_test_split` to set aside 20% of each test set with random state 5984."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUwdLP4haQQH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_5k, X_test_5k, y_train_5k, y_test_5k = train_test_split(X_5k, y_5k, test_size=0.20, random_state=5984)\n",
        "X_train_10k, X_test_10k, y_train_10k, y_test_10k = train_test_split(X_10k, y_10k, test_size=0.20, random_state=5984)\n",
        "X_train_100k, X_test_100k, y_train_100k, y_test_100k = train_test_split(X_100k, y_100k, test_size=0.20, random_state=5984)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ablTtsSQaQQV",
        "colab_type": "text"
      },
      "source": [
        "-----\n",
        "### 1.5 Remaking the Labels for Binary Classi\fcation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1tSX4sWaQQY",
        "colab_type": "text"
      },
      "source": [
        "For each y subset, create a label vector that indicates if each label is spruce/fir\n",
        "(1) or not (0). Use the subsets you already created as the basis for this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QelKo8g7aQQZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "e29b3671-7398-4d16-d0a6-1dbac633543e"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "# binary values for spruce/fir label\n",
        "lb = preprocessing.LabelBinarizer()\n",
        "y_train_5k_lb = lb.fit_transform(y_train_5k == 1).ravel()\n",
        "y_train_10k_lb = lb.fit_transform(y_train_10k == 1).ravel()\n",
        "y_train_100k_lb = lb.fit_transform(y_train_100k == 1).ravel()\n",
        "\n",
        "y_test_5k_lb = lb.fit_transform(y_test_5k == 1).ravel()\n",
        "y_test_10k_lb = lb.fit_transform(y_test_10k == 1).ravel()\n",
        "y_test_100k_lb = lb.fit_transform(y_test_100k == 1).ravel()\n",
        "\n",
        "## as an example just to check\n",
        "print(\"5k: original labels =\", y_train_5k)\n",
        "print(\"5k: binary labels   =\", y_train_5k_lb)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5k: original labels = [1 2 3 ... 2 6 2]\n",
            "5k: binary labels   = [1 0 0 ... 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmvH_KRkaQQc",
        "colab_type": "text"
      },
      "source": [
        "-----\n",
        "### 1.6 Baseline Accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_lRfQMoaQQd",
        "colab_type": "text"
      },
      "source": [
        "For each training subset, calculate the accuracy of a NOT spruce/fir\" estimator,\n",
        "that is, one that outputs 0 for every input. Hint: the sum of the labels in each\n",
        "training label subset can be used to quickly calculate this value without making\n",
        "a specfic function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I78p3E87aQQd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## a classifier that say every inputs is NOT spruce/fir\n",
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "class Never1Classifier(BaseEstimator):\n",
        "    def fit(self, X, y=None):\n",
        "        pass\n",
        "    def predict(self, X):\n",
        "        return np.zeros((len(X), 1), dtype=bool)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQdmEAn1aQQf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "0ba26123-b8a5-485e-cfe9-a74b9fa880ac"
      },
      "source": [
        "## 5k sample\n",
        "never_1_clf_5k = Never1Classifier()\n",
        "never_1_clf_5k_acc = cross_val_score(never_1_clf_5k, X_train_5k, y_train_5k_lb, scoring=\"accuracy\")\n",
        "print(\"5k: accuracy of folds = \" + str(never_1_clf_5k_acc.round(5)))\n",
        "print(\"5k: av. accuracy of folds = \" + str(np.mean(never_1_clf_5k_acc).round(5)))\n",
        "\n",
        "# accuracy using the labels\n",
        "manual_5k_acc = y_train_5k_lb[y_train_5k_lb == 0].size / y_train_5k_lb.size\n",
        "print(\"5k: accuracy using labels = \" + str(round(manual_5k_acc, 5)) + \"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5k: accuracy of folds = [0.66    0.6575  0.62875 0.62375 0.6375 ]\n",
            "5k: av. accuracy of folds = 0.6415\n",
            "5k: accuracy using labels = 0.6415\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIfmtebkaQQi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "6350cccf-bab2-4dc3-94eb-ae6813c6a750"
      },
      "source": [
        "## 10k sample\n",
        "never_1_clf_10k = Never1Classifier()\n",
        "never_1_clf_10k_acc = cross_val_score(never_1_clf_10k, X_train_10k, y_train_10k_lb, scoring=\"accuracy\")\n",
        "print(\"10k: accuracy of folds = \" + str(never_1_clf_10k_acc.round(5)))\n",
        "print(\"10k: av. accuracy of folds = \" + str(np.mean(never_1_clf_10k_acc).round(5)))\n",
        "\n",
        "# accuracy using the labels\n",
        "manual_10k_acc = y_train_10k_lb[y_train_10k_lb == 0].size / y_train_10k_lb.size\n",
        "print(\"10k: accuracy using labels = \" + str(round(manual_10k_acc, 5)) + \"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10k: accuracy of folds = [0.635   0.64875 0.64438 0.62687 0.64562]\n",
            "10k: av. accuracy of folds = 0.64013\n",
            "10k: accuracy using labels = 0.64013\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMaJMQTjaQQo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "f93fa35a-03b5-47fd-f3d4-d00ccd49d93d"
      },
      "source": [
        "## 100k sample\n",
        "never_1_clf_100k = Never1Classifier()\n",
        "never_1_clf_100k_acc = cross_val_score(never_1_clf_100k, X_train_100k, y_train_100k_lb, scoring=\"accuracy\")\n",
        "print(\"100k: accuracy of folds = \" + str(never_1_clf_100k_acc.round(5)))\n",
        "print(\"100k: av. accuracy of folds = \" + str(np.mean(never_1_clf_100k_acc).round(5)))\n",
        "\n",
        "# accuracy using the labels\n",
        "manual_100k_acc = y_train_100k_lb[y_train_100k_lb == 0].size / y_train_100k_lb.size\n",
        "print(\"100k: accuracy using labels = \" + str(round(manual_100k_acc, 5)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100k: accuracy of folds = [0.6325  0.638   0.63513 0.63475 0.63356]\n",
            "100k: av. accuracy of folds = 0.63479\n",
            "100k: accuracy using labels = 0.63479\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huxqS0WlaQQq",
        "colab_type": "text"
      },
      "source": [
        "-----\n",
        "## 2. Perceptron Classication"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLT9vFOIaQQr",
        "colab_type": "text"
      },
      "source": [
        "For the 5000 sample and 100000 sample subsets, you will create a Perceptron\n",
        "classifier that determines whether each sample point is spruce/fir or not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJvNIdUsaQQr",
        "colab_type": "text"
      },
      "source": [
        "### 2.1 Perceptron Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ayg-oSXCaQQs",
        "colab_type": "text"
      },
      "source": [
        "For each binary data and label subset, train the `Perceptron` classifier with no\n",
        "added arguments, using only the training subsets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5qPycwgaQQt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "e4f57769-06a2-4a0e-f478-23941ccf66fd"
      },
      "source": [
        "from sklearn.linear_model import Perceptron\n",
        "\n",
        "## perceptron for 5k sample\n",
        "clf = Perceptron()\n",
        "perc_clf_5k = clf.fit(X_train_5k, y_train_5k_lb)\n",
        "print(perc_clf_5k)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
            "           fit_intercept=True, max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
            "           penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
            "           validation_fraction=0.1, verbose=0, warm_start=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5-zYeuEaQQv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "3f57cd37-5eb8-4fd2-e60b-e7d0ad8f3806"
      },
      "source": [
        "## intecept and coefficients\n",
        "print(\"intercept = \" + str(perc_clf_5k.intercept_) + \"\\n\")\n",
        "print(\"coefficients = \\n\" + str(perc_clf_5k.coef_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "intercept = [-830.]\n",
            "\n",
            "coefficients = \n",
            "[[ 2.36920e+04 -8.62500e+03 -4.08030e+04 -1.08500e+04 -2.99760e+04\n",
            "  -5.08500e+03 -1.63245e+05 -1.21804e+05 -4.31710e+04 -2.18500e+03\n",
            "   4.85000e+02  7.73000e+02 -1.44500e+03 -6.43000e+02 -2.70000e+01\n",
            "  -1.18000e+02 -5.70000e+01 -2.29000e+02 -2.10000e+01 -8.90000e+01\n",
            "   0.00000e+00 -6.00000e+00  9.00000e+00 -9.23000e+02 -2.96000e+02\n",
            "  -6.96000e+02 -3.77000e+02 -1.40000e+01  0.00000e+00 -4.20000e+01\n",
            "  -8.90000e+01 -8.00000e+00  5.40000e+01  1.62000e+02  7.80000e+01\n",
            "   1.18800e+03  1.69500e+03  2.80000e+02 -1.50000e+01 -8.50000e+01\n",
            "  -1.00000e+01 -3.30000e+01 -6.96000e+02 -3.11000e+02 -6.60000e+01\n",
            "  -1.15000e+02 -2.12000e+02 -3.10000e+01  2.00000e+00 -1.10000e+01\n",
            "  -8.00000e+00  2.58000e+02 -8.10000e+01  1.10000e+02]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSvOCdfEaQQ0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "62e331f8-5458-46e3-8154-7ec5398a6642"
      },
      "source": [
        "## perceptron for 100k sample\n",
        "perc_clf_100k = clf.fit(X_train_100k, y_train_100k_lb)\n",
        "print(perc_clf_100k)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
            "           fit_intercept=True, max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
            "           penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
            "           validation_fraction=0.1, verbose=0, warm_start=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnFYeU_kaQQ5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "7122cff7-5385-4c20-8225-1942871b9882"
      },
      "source": [
        "## intercept and coefficients\n",
        "print(\"intercept = \" + str(perc_clf_100k.intercept_) + \"\\n\")\n",
        "print(\"coefficients = \\n\" + str(perc_clf_100k.coef_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "intercept = [-6011.]\n",
            "\n",
            "coefficients = \n",
            "[[ 4.16210e+04 -5.85200e+03 -4.94300e+05 -1.44390e+04 -2.42920e+04\n",
            "  -1.41300e+03 -3.63998e+05 -2.40740e+04 -2.18044e+05 -1.02000e+03\n",
            "   1.02980e+04  2.67300e+03 -1.68680e+04 -2.11400e+03 -5.90000e+01\n",
            "  -5.58000e+02 -2.42000e+02 -1.05100e+03 -2.80000e+01 -1.86000e+02\n",
            "  -1.11000e+02 -4.30000e+01  4.76000e+02 -5.95700e+03 -2.19400e+03\n",
            "  -9.01400e+03 -4.31000e+03 -1.40000e+01  0.00000e+00 -2.90000e+01\n",
            "  -3.96000e+02 -2.91000e+02  1.48400e+03  2.04600e+03  9.19000e+02\n",
            "   2.22450e+04  2.43180e+04  2.40000e+01 -2.01000e+02 -6.42000e+02\n",
            "   5.52000e+02 -3.80000e+02 -9.53000e+03 -5.92800e+03  1.64500e+03\n",
            "  -4.60800e+03 -2.70000e+02 -8.23000e+02 -1.05000e+03 -6.50000e+01\n",
            "  -4.95000e+02 -3.82200e+03 -4.50900e+03 -2.91400e+03]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xSKOwwLaQQ9",
        "colab_type": "text"
      },
      "source": [
        "-----\n",
        "#### 2.1.1 Accuracy on the training sets and the test sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDIoUoUcaQQ-",
        "colab_type": "text"
      },
      "source": [
        "What is the accuracy on the training sets and the test sets?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bG6IzuypaQQ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "ce3460b4-6676-415d-bdf5-cb7e0a228704"
      },
      "source": [
        "## 5k samples\n",
        "perc_clf_5k_train_acc = perc_clf_5k.score(X_train_5k, y_train_5k_lb)\n",
        "perc_clf_5k_test_acc = perc_clf_5k.score(X_test_5k, y_test_5k_lb)\n",
        "\n",
        "print(\"5k: training set accuracy = \" + str(perc_clf_5k_train_acc))\n",
        "print(\"5k: test set accuracy     = \" + str(perc_clf_5k_test_acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5k: training set accuracy = 0.72375\n",
            "5k: test set accuracy     = 0.724\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_JBvydWaQRC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "ddd920f3-f678-4e72-94c2-0f0fa0802c75"
      },
      "source": [
        "## 100k samples\n",
        "perc_clf_100k_train_acc = perc_clf_100k.score(X_train_100k, y_train_100k_lb)\n",
        "perc_clf_100k_test_acc = perc_clf_100k.score(X_test_100k, y_test_100k_lb)\n",
        "\n",
        "print(\"100k: training set accuracy = \" + str(perc_clf_100k_train_acc))\n",
        "print(\"100k: test set accuracy     = \" + str(perc_clf_100k_test_acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100k: training set accuracy = 0.7195875\n",
            "100k: test set accuracy     = 0.7166\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXSfYUN9aQRG",
        "colab_type": "text"
      },
      "source": [
        "-----\n",
        "#### 2.1.2 Confusion matrices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wj3fVocpaQRH",
        "colab_type": "text"
      },
      "source": [
        "What is the confusion matrix on the test sets? Use the predicted labels\n",
        "as a basis for comparison to the true labels for each test set. What does\n",
        "the confusion matrix tell you about the classifier's ability to correctly and\n",
        "incorrectly predict whether each sample is a spruce/fir cover or not?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrSe5L7qaQRH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "4ed28698-ba05-4760-8f18-144dddb12461"
      },
      "source": [
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "## 5k sample\n",
        "print(\"===============================================\")\n",
        "print(\"5k: number of true (1) labels in test set = \" + str(y_test_5k_lb[y_test_5k_lb == 1].size))\n",
        "print(\"===============================================\\n\" + \"confusion matrix =\")\n",
        "\n",
        "perc_clf_5k_test_pred = perc_clf_5k.predict(X_test_5k)\n",
        "confusion_matrix(y_test_5k_lb, perc_clf_5k_test_pred)\n",
        "# First row is 0's, second row is 1's\n",
        "# First column is number correctly predicted, second is incorrectly predicted\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===============================================\n",
            "5k: number of true (1) labels in test set = 377\n",
            "===============================================\n",
            "confusion matrix =\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[569,  54],\n",
              "       [222, 155]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo92h93DaQRK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "f1b0d9c9-3837-4347-d4fc-876aae184b2a"
      },
      "source": [
        "## 100k sample\n",
        "print(\"==================================================\")\n",
        "print(\"100k: number of true (1) labels in test set = \" + str(y_test_100k_lb[y_test_100k_lb == 1].size))\n",
        "print(\"==================================================\\n\" + \"confusion matrix =\")\n",
        "\n",
        "perc_clf_100k_test_pred = perc_clf_100k.predict(X_test_100k)\n",
        "confusion_matrix(y_test_100k_lb, perc_clf_100k_test_pred)\n",
        "# First row is 0's, second row is 1's\n",
        "# First column is number correctly predicted, second is incorrectly predicted\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "100k: number of true (1) labels in test set = 7191\n",
            "==================================================\n",
            "confusion matrix =\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[11400,  1409],\n",
              "       [ 4259,  2932]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBvupVDjaQRM",
        "colab_type": "text"
      },
      "source": [
        ">  **Answer**:  \n",
        "> We can see that the number of False-Postives and False-Negatives on the off-diagonal entries for both samples sizes, is not small compared to the number of correctly predicted labels. This means our calssifier is not doing a good job predicting the binary labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tHRSHDCaQRN",
        "colab_type": "text"
      },
      "source": [
        "-----\n",
        "#### 2.1.3 Precision and recall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwlO4TRfaQRN",
        "colab_type": "text"
      },
      "source": [
        "What are the precision and recall on the test sets?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnwQNXkXaQRO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "5e2f7daf-a193-4fe7-9715-e5bb3b4b928e"
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "## 5k sample\n",
        "perc_clf_5k_test_pred_precision = precision_score(y_test_5k_lb, perc_clf_5k_test_pred)\n",
        "perc_clf_5k_test_pred_recall = recall_score(y_test_5k_lb, perc_clf_5k_test_pred)\n",
        "print(\"5k: precision = \" + str(perc_clf_5k_test_pred_precision))\n",
        "print(\"5k: recall    = \" + str(perc_clf_5k_test_pred_recall) + \"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5k: precision = 0.7416267942583732\n",
            "5k: recall    = 0.41114058355437666\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0O-NrxaaQRR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "ef6a57a3-fab4-4589-c596-8f66031ba079"
      },
      "source": [
        "## 100k sample\n",
        "perc_clf_100k_test_pred_precision = precision_score(y_test_100k_lb, perc_clf_100k_test_pred)\n",
        "perc_clf_100k_test_pred_recall = recall_score(y_test_100k_lb, perc_clf_100k_test_pred)\n",
        "print(\"100k: precision = \" + str(perc_clf_100k_test_pred_precision))\n",
        "print(\"100k: recall    = \" + str(perc_clf_100k_test_pred_recall))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100k: precision = 0.6754204100437687\n",
            "100k: recall    = 0.40773188708107355\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CW25j9pFaQRU",
        "colab_type": "text"
      },
      "source": [
        "-----\n",
        "#### 2.1.4 Precision and recall vs. threshold plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4-2lv5RaQRU",
        "colab_type": "text"
      },
      "source": [
        "Using the decision function as the threshold, plot precision and recall vs.\n",
        "threshold."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-glLpeH5aQRW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## helper function\n",
        "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
        "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\", linewidth=2)\n",
        "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\", linewidth=2)\n",
        "    plt.xlabel(\"Threshold\", fontsize=16)\n",
        "    plt.legend(loc=\"upper left\", fontsize=16)\n",
        "    plt.ylim([0, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YY4ddMCSaQRa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "092c7d2c-1635-4b3b-9a3c-b13b8ce1a6a1"
      },
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "## 5k samples\n",
        "perc_5k_test_y_scores = perc_clf_5k.decision_function(X_test_5k)\n",
        "perc_5k_precisions, perc_5k_recalls, perc_5k_thresholds = precision_recall_curve(y_test_5k_lb, perc_5k_test_y_scores)\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.title(\"5k Sample\", fontsize=18)\n",
        "plot_precision_recall_vs_threshold(perc_5k_precisions, perc_5k_recalls, perc_5k_thresholds)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xzg9ep6QaQRd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "7027a5ce-8a19-4f9f-9cd5-ca9f6acd8719"
      },
      "source": [
        "## 100k sample\n",
        "perc_100k_test_y_scores = perc_clf_100k.decision_function(X_test_100k)\n",
        "perc_100k_precisions, perc_100k_recalls, perc_100k_thresholds = precision_recall_curve(y_test_100k_lb, perc_100k_test_y_scores)\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.title(\"100k Sample\", fontsize=18)\n",
        "plot_precision_recall_vs_threshold(perc_100k_precisions, perc_100k_recalls, perc_100k_thresholds)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blJ2tMHKaQRf",
        "colab_type": "text"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fROt-J-uaQRf",
        "colab_type": "text"
      },
      "source": [
        "-----\n",
        "#### 2.1.5 F score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHeYdU2vaQRf",
        "colab_type": "text"
      },
      "source": [
        "Using the decision function as the threshold, what threshold value maximizes the F score, and what is the value?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8xr6vSnaQRg",
        "colab_type": "text"
      },
      "source": [
        "> **Answer**:   \n",
        ">`F-score` maximizes at the point where the percision and recall are very close or equal to 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuFf9n5qaQRg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "5cf20f85-721e-49ce-9edf-8251016c9b58"
      },
      "source": [
        "## 5k samples\n",
        "perc_5k_test_y_scores = perc_clf_5k.decision_function(X_test_5k)\n",
        "perc_5k_precisions, perc_5k_recalls, perc_5k_thresholds = precision_recall_curve(y_test_5k_lb, perc_5k_test_y_scores)\n",
        "\n",
        "f1_scores_5k = 2*perc_5k_recalls*perc_5k_precisions/(perc_5k_recalls + perc_5k_precisions)\n",
        "print('5k: best threshold = ', perc_5k_thresholds[np.argmax(f1_scores_5k)])\n",
        "print('5k: best F1-Score  = ', np.nanmax(f1_scores_5k).round(5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5k: best threshold =  -9447000.0\n",
            "5k: best F1-Score  =  0.70575\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KS8-MA_SaQRk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "5d4ec1be-0bd9-4548-d3b3-d14d7d812879"
      },
      "source": [
        "## 100k sample\n",
        "perc_100k_test_y_scores = perc_clf_100k.decision_function(X_test_100k)\n",
        "perc_100k_precisions, perc_100k_recalls, perc_100k_thresholds = precision_recall_curve(y_test_100k_lb, perc_100k_test_y_scores)\n",
        "                                                                                       \n",
        "f1_scores_100k = 2*perc_100k_recalls*perc_100k_precisions/(perc_100k_recalls + perc_100k_precisions)\n",
        "print('100k: best threshold = ', perc_100k_thresholds[np.argmax(f1_scores_100k)])\n",
        "print('100k: best F1-Score  = ', np.nanmax(f1_scores_100k).round(5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100k: best threshold =  28655956.0\n",
            "100k: best F1-Score  =  0.68904\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in true_divide\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdueHNI-aQRq",
        "colab_type": "text"
      },
      "source": [
        "### 2.2 Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rw1pm3ohaQRq",
        "colab_type": "text"
      },
      "source": [
        "Would you say the old-fashioned Perceptron algorithm is useful for this data\n",
        "set? Is it better than a NOT spruce/fir\" classifier in any scenario? Why or why\n",
        "not?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2li0kT5aQRr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "89dc21d5-2547-4b2c-9382-f87d5a5be530"
      },
      "source": [
        "perc_clf_10k_test_acc = perc_clf_100k.score(X_test_10k, y_test_10k_lb)\n",
        "perc_clf_10k_test_pred = perc_clf_100k.predict(X_test_10k)\n",
        "perc_clf_10k_test_pred_precision = precision_score(y_test_10k_lb, perc_clf_10k_test_pred)\n",
        "perc_clf_10k_test_pred_recall = recall_score(y_test_10k_lb, perc_clf_10k_test_pred)\n",
        "\n",
        "print(\"test set accuracy of perc_clf = \" + str(perc_clf_10k_test_acc))\n",
        "print(\">> precision for perc_clf = \" + str(perc_clf_10k_test_pred_precision.round(5)))\n",
        "print(\">> recall for perc_clf    = \" + str(perc_clf_10k_test_pred_recall.round(5)))\n",
        "\n",
        "## never-1-calssifier defined in Problem 1\n",
        "never_1_clf_10k_acc = cross_val_score(never_1_clf_10k, X_train_10k, y_train_10k_lb, scoring=\"accuracy\")\n",
        "print(\"\\nave_CV accuracy of never_1_clf = \" + str(np.mean(never_1_clf_10k_acc).round(4)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test set accuracy of perc_clf = 0.717\n",
            ">> precision for perc_clf = 0.69362\n",
            ">> recall for perc_clf    = 0.43583\n",
            "\n",
            "ave_CV accuracy of never_1_clf = 0.6401\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYDCvoZnaQRt",
        "colab_type": "text"
      },
      "source": [
        "> **Answer**:   \n",
        "> Blindly labeling every point with `0` is 64% accurate whereas running the perceptron gives the accuracy of 71%, slightly better than the `never_1_clf`. Using perceptron does not seem to be useful with this accuracy. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiI0lj7uaQRu",
        "colab_type": "text"
      },
      "source": [
        "-----\n",
        "## 3. Support Vector Machine Binary Classi\fcation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxuxUjOaaQRu",
        "colab_type": "text"
      },
      "source": [
        "In this problem you will use the 10000 sample subset you made back in Problem\n",
        "1 and will learn how to use grid search to tune hyperparameters to get the\n",
        "performance you want."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg6TdeeOaQRv",
        "colab_type": "text"
      },
      "source": [
        "### 3.1 Scaling and Solver Speed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtAyhd_paQRv",
        "colab_type": "text"
      },
      "source": [
        "For `C=1`, `polydeg=3`, `class weight=None`, create a both `SVC` classifer, and a\n",
        "`Pipeline` that uses `StandardScalar` to scale the `X` subset prior to using another `SVC` classifier. Try running both. What can you say about the relative speeds?\n",
        "Why do you think this is happening?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEDkB39FaQRw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "aa21bbe9-432a-4aea-f00f-4b104e17de2a"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "import time\n",
        "\n",
        "## SVM with unscaled dataset\n",
        "svm_clf_poly_unscaled = SVC(C=1.0, degree=3, class_weight=None, kernel='poly')\n",
        "svm_clf_poly_unscaled"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='poly',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpg9A2L0aQR0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "1d3ebee3-56d3-46d9-de58-72480697b0db"
      },
      "source": [
        "time_start_unscaled = time.perf_counter()\n",
        "svm_clf_poly_unscaled.fit(X_train_10k, y_train_10k_lb)\n",
        "\n",
        "time_elapsed_unscaled = (time.perf_counter() - time_start_unscaled)\n",
        "print (\"unscaled dataset computation time = %5.1f secs\" % time_elapsed_unscaled + \"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unscaled dataset computation time =   4.2 secs\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qM2mKCDjaQR4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "7997dd78-3349-4dbe-a244-0045d9b7a00b"
      },
      "source": [
        "## SVM with scaled dataset\n",
        "svm_clf_poly_scaled = Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"svc\", SVC(C=1.0, degree=3, class_weight=None, kernel='poly'))\n",
        "    ])\n",
        "svm_clf_poly_scaled"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('scaler',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('svc',\n",
              "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
              "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
              "                     gamma='scale', kernel='poly', max_iter=-1,\n",
              "                     probability=False, random_state=None, shrinking=True,\n",
              "                     tol=0.001, verbose=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sltbBAnOaQR6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "db4e4fd7-10f3-4415-cd7d-940a63406d4b"
      },
      "source": [
        "time_start_scaled = time.perf_counter()\n",
        "svm_clf_poly_scaled.fit(X_train_10k, y_train_10k_lb)\n",
        "\n",
        "time_elapsed_scaled = (time.perf_counter() - time_start_scaled)\n",
        "print (\"scaled dataset computation time = %5.1f secs\" % time_elapsed_scaled)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "scaled dataset computation time =   3.9 secs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jofqkzdiaQR9",
        "colab_type": "text"
      },
      "source": [
        "> **Answer**:   \n",
        "> The program computes faster with the scaled data since the variance in all directions is 1 and data set in not skewed (balanced) which helps the solver to find the solution faster and makes the SVM more reliable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0fhsj6waQR9",
        "colab_type": "text"
      },
      "source": [
        "-----\n",
        "### 3.2 Polynomial Kernel Grid Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y08OpdBpaQR9",
        "colab_type": "text"
      },
      "source": [
        "Without using scikit-learn's `GridSearchCV` module, create a loop that trains an\n",
        "SVC over each combination of the following parameters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ej_pcKP4aQR-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Cs = [0.001,1,100]\n",
        "class_weights = [None,'balanced']\n",
        "polydegs = [3,5,7]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fbq979kaaQSA",
        "colab_type": "text"
      },
      "source": [
        "If you did this right, you should have 18 different classifiers. Hint: use\n",
        "Python's `itertools.product` to generate the 18 option sets without using 3\n",
        "nested for loops."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uk1pTDkGaQSA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "12560ea2-98c6-4d83-e6c0-84210b49dcf3"
      },
      "source": [
        "import itertools\n",
        "\n",
        "classifier_name_list = []\n",
        "for i,comb in enumerate(itertools.product(Cs, class_weights, polydegs)):\n",
        "    degree = comb[2]\n",
        "    class_weight = comb[1]\n",
        "    C = comb[0]\n",
        "    \n",
        "    global name\n",
        "    if C != Cs[0]:\n",
        "        name = \"svm_poly\" + str(comb[2]) + \"_\" +  str(comb[1]) + \"_C\" +  str(comb[0])\n",
        "    else:\n",
        "        name = \"svm_poly\" + str(comb[2]) + \"_\" +  str(comb[1]) + \"_C001\"\n",
        "    \n",
        "    classifier_name_list.append(name)\n",
        "    print(\"classifier\", str(i) + \":\", classifier_name_list[i])\n",
        "    \n",
        "    globals()[name] = Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"svc\", SVC(C=C, degree=degree, class_weight=class_weight, kernel='poly'))\n",
        "        ])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classifier 0: svm_poly3_None_C001\n",
            "classifier 1: svm_poly5_None_C001\n",
            "classifier 2: svm_poly7_None_C001\n",
            "classifier 3: svm_poly3_balanced_C001\n",
            "classifier 4: svm_poly5_balanced_C001\n",
            "classifier 5: svm_poly7_balanced_C001\n",
            "classifier 6: svm_poly3_None_C1\n",
            "classifier 7: svm_poly5_None_C1\n",
            "classifier 8: svm_poly7_None_C1\n",
            "classifier 9: svm_poly3_balanced_C1\n",
            "classifier 10: svm_poly5_balanced_C1\n",
            "classifier 11: svm_poly7_balanced_C1\n",
            "classifier 12: svm_poly3_None_C100\n",
            "classifier 13: svm_poly5_None_C100\n",
            "classifier 14: svm_poly7_None_C100\n",
            "classifier 15: svm_poly3_balanced_C100\n",
            "classifier 16: svm_poly5_balanced_C100\n",
            "classifier 17: svm_poly7_balanced_C100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gR5vKNonaQSC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "0a4c523b-8c49-4359-cd0c-237264560c48"
      },
      "source": [
        "## an example to check if everything is fine\n",
        "svm_poly7_balanced_C001"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('scaler',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('svc',\n",
              "                 SVC(C=0.001, break_ties=False, cache_size=200,\n",
              "                     class_weight='balanced', coef0=0.0,\n",
              "                     decision_function_shape='ovr', degree=7, gamma='scale',\n",
              "                     kernel='poly', max_iter=-1, probability=False,\n",
              "                     random_state=None, shrinking=True, tol=0.001,\n",
              "                     verbose=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkoHdgvzaQSP",
        "colab_type": "text"
      },
      "source": [
        "-----\n",
        "#### 3.2.1 Accuracy scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkxsAOluaQSP",
        "colab_type": "text"
      },
      "source": [
        "Use `cross_val_score` to generate accuracy scores for each validation set.\n",
        "Using the average CV score, what is the best combination?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjUb2fA5aQSP",
        "colab_type": "text"
      },
      "source": [
        "> **Answer**:   \n",
        "> We pick the one with the highest CV score mean."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-w0LjiQaQSQ",
        "colab_type": "code",
        "colab": {},
        "outputId": "925466b4-7827-491c-849a-ba2a17e97b02"
      },
      "source": [
        "classifier_acc = {}\n",
        "classifier_acc_mean = {}\n",
        "\n",
        "for i in range(0,len(classifier_name_list)):\n",
        "    time_start = time.perf_counter()\n",
        "    \n",
        "    classifier = globals()[classifier_name_list[i]]\n",
        "    temp_acc = cross_val_score(classifier, X_train_10k, y_train_10k_lb, scoring=\"accuracy\")\n",
        "    classifier_acc[classifier_name_list[i]] = temp_acc\n",
        "    classifier_acc_mean[classifier_name_list[i]] = np.mean(temp_acc)\n",
        "    \n",
        "    time_elapsed = (time.perf_counter() - time_start)\n",
        "    print (\"iteration\", i+1, \"=%5.1f secs\" % time_elapsed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iteration 1 = 20.8 secs\n",
            "iteration 2 = 21.0 secs\n",
            "iteration 3 = 20.3 secs\n",
            "iteration 4 = 40.4 secs\n",
            "iteration 5 = 29.1 secs\n",
            "iteration 6 = 28.9 secs\n",
            "iteration 7 = 16.5 secs\n",
            "iteration 8 = 20.2 secs\n",
            "iteration 9 = 21.9 secs\n",
            "iteration 10 = 21.5 secs\n",
            "iteration 11 = 24.5 secs\n",
            "iteration 12 = 30.4 secs\n",
            "iteration 13 = 34.3 secs\n",
            "iteration 14 = 25.7 secs\n",
            "iteration 15 = 25.6 secs\n",
            "iteration 16 = 27.6 secs\n",
            "iteration 17 = 33.0 secs\n",
            "iteration 18 = 29.9 secs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsaz9-MiaQST",
        "colab_type": "code",
        "colab": {},
        "outputId": "e2860bea-b41c-45f0-9182-45a013135393"
      },
      "source": [
        "## accuracy for CV folds\n",
        "for i, key in enumerate(classifier_acc.keys()):\n",
        "    if i == 0: print(\"accuracy for classifiers using CV:\\n\")\n",
        "    print(str(key) + \" = \" + str(classifier_acc[key].round(5)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy for classifiers using CV:\n",
            "\n",
            "svm_poly3_None_C001 = [0.64188 0.64188 0.6425  0.63938 0.64312]\n",
            "svm_poly5_None_C001 = [0.64312 0.64562 0.64375 0.64188 0.6425 ]\n",
            "svm_poly7_None_C001 = [0.64312 0.64938 0.64562 0.63875 0.64625]\n",
            "svm_poly3_balanced_C001 = [0.38    0.38    0.37688 0.3825  0.38875]\n",
            "svm_poly5_balanced_C001 = [0.40875 0.41688 0.41062 0.41812 0.43062]\n",
            "svm_poly7_balanced_C001 = [0.42188 0.42062 0.42312 0.43    0.44   ]\n",
            "svm_poly3_None_C1 = [0.76312 0.7575  0.7725  0.76312 0.7525 ]\n",
            "svm_poly5_None_C1 = [0.71938 0.7375  0.725   0.71375 0.71812]\n",
            "svm_poly7_None_C1 = [0.69375 0.69812 0.68875 0.67062 0.69188]\n",
            "svm_poly3_balanced_C1 = [0.72375 0.74625 0.73812 0.705   0.7675 ]\n",
            "svm_poly5_balanced_C1 = [0.62062 0.635   0.63438 0.62438 0.66938]\n",
            "svm_poly7_balanced_C1 = [0.56625 0.56063 0.56625 0.55188 0.6325 ]\n",
            "svm_poly3_None_C100 = [0.80625 0.81875 0.82375 0.82688 0.81625]\n",
            "svm_poly5_None_C100 = [0.81062 0.81625 0.80812 0.80062 0.79938]\n",
            "svm_poly7_None_C100 = [0.79    0.78188 0.7725  0.77188 0.77375]\n",
            "svm_poly3_balanced_C100 = [0.79188 0.80812 0.80562 0.8     0.82188]\n",
            "svm_poly5_balanced_C100 = [0.795   0.80688 0.8     0.78375 0.82   ]\n",
            "svm_poly7_balanced_C100 = [0.70562 0.70938 0.71188 0.685   0.7625 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tu6WSn9baQSZ",
        "colab_type": "code",
        "colab": {},
        "outputId": "eeae9df7-180c-48e6-b420-f5093658b99b"
      },
      "source": [
        "## average accuracy of the folds\n",
        "for i, key in enumerate(classifier_acc_mean.keys()):\n",
        "    if i == 0:\n",
        "        print(\"average accuracy of the folds for the classifiers:\\n\")        \n",
        "    print(str(key) + \" = \" + str(classifier_acc_mean[key].round(5)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "average accuracy of the folds for the classifiers:\n",
            "\n",
            "svm_poly3_None_C001 = 0.64175\n",
            "svm_poly5_None_C001 = 0.64338\n",
            "svm_poly7_None_C001 = 0.64462\n",
            "svm_poly3_balanced_C001 = 0.38162\n",
            "svm_poly5_balanced_C001 = 0.417\n",
            "svm_poly7_balanced_C001 = 0.42712\n",
            "svm_poly3_None_C1 = 0.76175\n",
            "svm_poly5_None_C1 = 0.72275\n",
            "svm_poly7_None_C1 = 0.68862\n",
            "svm_poly3_balanced_C1 = 0.73612\n",
            "svm_poly5_balanced_C1 = 0.63675\n",
            "svm_poly7_balanced_C1 = 0.5755\n",
            "svm_poly3_None_C100 = 0.81838\n",
            "svm_poly5_None_C100 = 0.807\n",
            "svm_poly7_None_C100 = 0.778\n",
            "svm_poly3_balanced_C100 = 0.8055\n",
            "svm_poly5_balanced_C100 = 0.80113\n",
            "svm_poly7_balanced_C100 = 0.71487\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eV2GXDIaQSd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## helper function\n",
        "def clf_spec(classifier_name):\n",
        "    [type, degree, class_weights, C] = classifier_name.split(\"_\")\n",
        "    print(\"\\nclassifier name = \" + str(classifier_name))\n",
        "    print(\"              C = \" + str(C[1:])) if C != \"C001\" else print(\"              C = 0.001\")\n",
        "    print(\"         degree = \" + str(degree[4:]))\n",
        "    print(\"  class_weights = \" + str(class_weights))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nvZg4U6aQSg",
        "colab_type": "code",
        "colab": {},
        "outputId": "714a0c1c-8d19-4452-fdc7-86c28ecc64ed"
      },
      "source": [
        "## max CV mean among the classifier\n",
        "classifier_acc_mean_max = np.max(list(classifier_acc_mean.values()))\n",
        "print(\"max CV score mean= \" + str(classifier_acc_mean_max))\n",
        "\n",
        "key_cv_max = list(classifier_acc_mean.keys())[list(classifier_acc_mean.values()).index(classifier_acc_mean_max)]\n",
        "clf_spec(key_cv_max)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max CV score mean= 0.818375\n",
            "\n",
            "classifier name = svm_poly3_None_C100\n",
            "              C = 100\n",
            "         degree = 3\n",
            "  class_weights = None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBglnR5WaQSj",
        "colab_type": "text"
      },
      "source": [
        "----\n",
        "#### 3.2.2 CV scores vs. the score generated by the overall training set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gOLxaOoaQSk",
        "colab_type": "text"
      },
      "source": [
        "Compare the average of the CV scores to the score generated by the overall\n",
        "training set. Which combination overfits the most? The least?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3_txypAaQSk",
        "colab_type": "text"
      },
      "source": [
        "> **Answer**:   \n",
        "> We calculate the difference between the average CV and the overal accuracy scores. The biggest difference would be the most overfitted model and the smallest difference would be the least overfitted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9KxjiysaQSm",
        "colab_type": "code",
        "colab": {},
        "outputId": "59f9a77d-0ce8-4203-db3b-1593249ce733"
      },
      "source": [
        "classifier_acc_overall = {}\n",
        "\n",
        "for i in range(0,len(classifier_name_list)):\n",
        "    time_start = time.perf_counter()\n",
        "    \n",
        "    classifier = globals()[classifier_name_list[i]]\n",
        "    classifier.fit(X_train_10k, y_train_10k_lb)\n",
        "    temp_acc_overall = classifier.score(X_train_10k, y_train_10k_lb)\n",
        "    classifier_acc_overall[classifier_name_list[i]] = temp_acc_overall\n",
        "\n",
        "    time_elapsed = (time.perf_counter() - time_start)\n",
        "    print (\"iteration\", i+1, \"=%5.1f secs\" % time_elapsed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iteration 1 =  8.7 secs\n",
            "iteration 2 =  8.6 secs\n",
            "iteration 3 =  8.9 secs\n",
            "iteration 4 = 13.1 secs\n",
            "iteration 5 = 13.1 secs\n",
            "iteration 6 = 11.4 secs\n",
            "iteration 7 =  8.2 secs\n",
            "iteration 8 = 12.9 secs\n",
            "iteration 9 = 10.7 secs\n",
            "iteration 10 = 10.0 secs\n",
            "iteration 11 = 12.6 secs\n",
            "iteration 12 = 12.5 secs\n",
            "iteration 13 = 11.1 secs\n",
            "iteration 14 =  9.7 secs\n",
            "iteration 15 =  9.6 secs\n",
            "iteration 16 =  8.8 secs\n",
            "iteration 17 =  8.4 secs\n",
            "iteration 18 = 10.1 secs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvwmEv0naQSp",
        "colab_type": "code",
        "colab": {},
        "outputId": "c1c435e3-f973-4939-ba70-b0adc3125afd"
      },
      "source": [
        "## overall accuracy of the folds\n",
        "for i, key in enumerate(classifier_acc_overall.keys()):\n",
        "    if i == 0:\n",
        "        print(\"overall accuracy of the classifiers:\\n\")        \n",
        "    print(str(key) + \" = \" + str(classifier_acc_overall[key].round(5)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "overall accuracy of the classifiers:\n",
            "\n",
            "svm_poly3_None_C001 = 0.64175\n",
            "svm_poly5_None_C001 = 0.64462\n",
            "svm_poly7_None_C001 = 0.64938\n",
            "svm_poly3_balanced_C001 = 0.38512\n",
            "svm_poly5_balanced_C001 = 0.41925\n",
            "svm_poly7_balanced_C001 = 0.43262\n",
            "svm_poly3_None_C1 = 0.77762\n",
            "svm_poly5_None_C1 = 0.74412\n",
            "svm_poly7_None_C1 = 0.71462\n",
            "svm_poly3_balanced_C1 = 0.77025\n",
            "svm_poly5_balanced_C1 = 0.66212\n",
            "svm_poly7_balanced_C1 = 0.60788\n",
            "svm_poly3_None_C100 = 0.872\n",
            "svm_poly5_None_C100 = 0.874\n",
            "svm_poly7_None_C100 = 0.83938\n",
            "svm_poly3_balanced_C100 = 0.861\n",
            "svm_poly5_balanced_C100 = 0.87012\n",
            "svm_poly7_balanced_C100 = 0.77938\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xhfXYzYaQSt",
        "colab_type": "code",
        "colab": {},
        "outputId": "cc25a1ca-d573-4334-b6d7-9dde0625865f"
      },
      "source": [
        "## difference between the overall accuracy and the average CV accuracy\n",
        "classifier_acc_dif = {}\n",
        "for k in classifier_acc_overall.keys():\n",
        "    classifier_acc_dif[k] = classifier_acc_overall[k] - classifier_acc_mean[k]\n",
        "    \n",
        "classifier_acc_dif_values = np.reshape(list(classifier_acc_dif.values()), len(classifier_acc_dif.values()), 1)\n",
        "for i,clf in enumerate(classifier_acc_overall.keys()):\n",
        "    print(\"CV dif = \" + str(classifier_acc_dif_values[i].round(5)) + \", \" + str(clf))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CV dif = 0.0, svm_poly3_None_C001\n",
            "CV dif = 0.00125, svm_poly5_None_C001\n",
            "CV dif = 0.00475, svm_poly7_None_C001\n",
            "CV dif = 0.0035, svm_poly3_balanced_C001\n",
            "CV dif = 0.00225, svm_poly5_balanced_C001\n",
            "CV dif = 0.0055, svm_poly7_balanced_C001\n",
            "CV dif = 0.01588, svm_poly3_None_C1\n",
            "CV dif = 0.02137, svm_poly5_None_C1\n",
            "CV dif = 0.026, svm_poly7_None_C1\n",
            "CV dif = 0.03412, svm_poly3_balanced_C1\n",
            "CV dif = 0.02537, svm_poly5_balanced_C1\n",
            "CV dif = 0.03238, svm_poly7_balanced_C1\n",
            "CV dif = 0.05363, svm_poly3_None_C100\n",
            "CV dif = 0.067, svm_poly5_None_C100\n",
            "CV dif = 0.06137, svm_poly7_None_C100\n",
            "CV dif = 0.0555, svm_poly3_balanced_C100\n",
            "CV dif = 0.069, svm_poly5_balanced_C100\n",
            "CV dif = 0.0645, svm_poly7_balanced_C100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOVykW3OaQSz",
        "colab_type": "code",
        "colab": {},
        "outputId": "ed8c8ac8-d86a-4380-e1f8-6fd47870b971"
      },
      "source": [
        "clf_cv_dif_min_value = classifier_acc_dif_values.min()\n",
        "print(\"min CV difference= \" + str(clf_cv_dif_min_value.round(5)))\n",
        "\n",
        "key_cv_dif_min = list(classifier_acc_dif.keys())[list(classifier_acc_dif.values()).index(clf_cv_dif_min_value)]\n",
        "clf_spec(key_cv_dif_min)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "min CV difference= 0.0\n",
            "\n",
            "classifier name = svm_poly3_None_C001\n",
            "              C = 0.001\n",
            "         degree = 3\n",
            "  class_weights = None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8qfhGQ4aQS1",
        "colab_type": "code",
        "colab": {},
        "outputId": "3f19509a-426d-42c1-c10d-93c00fa9bc74"
      },
      "source": [
        "clf_cv_dif_max_value = classifier_acc_dif_values.max()\n",
        "print(\"max CV difference= \" + str(clf_cv_dif_max_value.round(5)))\n",
        "\n",
        "key_cv_dif_max = list(classifier_acc_dif.keys())[list(classifier_acc_dif.values()).index(clf_cv_dif_max_value)]\n",
        "clf_spec(key_cv_dif_max)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max CV difference= 0.069\n",
            "\n",
            "classifier name = svm_poly5_balanced_C100\n",
            "              C = 100\n",
            "         degree = 5\n",
            "  class_weights = balanced\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ycwh7MPQaQS6",
        "colab_type": "text"
      },
      "source": [
        "----\n",
        "#### 3.2.3 The classifier that correctly classifies as many spruce/fir samples as possible"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8K33SAgaQS7",
        "colab_type": "text"
      },
      "source": [
        "If you wanted a classifier that prioritized correctly classifying as many\n",
        "spruce/fir samples as possible without concern for misclassifying other\n",
        "types as spruce/fir, which combination is the best?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnIKNykFaQS7",
        "colab_type": "text"
      },
      "source": [
        "> **Answer**:   \n",
        "> Correctly classifying as many spruce/fir samples as possible without concern for misclassifying other types as spruce/fir means having the highest percision possible. So, we pick the one with the highest recall regradless of recall."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGtwu2PFaQS8",
        "colab_type": "code",
        "colab": {},
        "outputId": "a7ed9733-f660-4815-ed62-4e224029f1c9"
      },
      "source": [
        "classifier_precision = {}\n",
        "classifier_recall = {}\n",
        "\n",
        "for i in range(0,len(classifier_name_list)):\n",
        "    time_start = time.perf_counter()\n",
        "    \n",
        "    classifier = globals()[classifier_name_list[i]]\n",
        "    classifier.fit(X_train_10k, y_train_10k_lb)\n",
        "    svm_clf_10k_train_pred = classifier.predict(X_train_10k)\n",
        "    classifier_precision[classifier_name_list[i]] = precision_score(y_train_10k_lb, svm_clf_10k_train_pred)\n",
        "    classifier_recall[classifier_name_list[i]] = recall_score(y_train_10k_lb, svm_clf_10k_train_pred)\n",
        "\n",
        "    time_elapsed = (time.perf_counter() - time_start)\n",
        "    print (\"iteration\", i+1, \"=%5.1f secs\" % time_elapsed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iteration 1 =  7.8 secs\n",
            "iteration 2 =  7.7 secs\n",
            "iteration 3 =  8.8 secs\n",
            "iteration 4 = 11.6 secs\n",
            "iteration 5 = 12.0 secs\n",
            "iteration 6 = 11.5 secs\n",
            "iteration 7 =  6.7 secs\n",
            "iteration 8 =  8.1 secs\n",
            "iteration 9 =  8.2 secs\n",
            "iteration 10 =  7.5 secs\n",
            "iteration 11 =  8.3 secs\n",
            "iteration 12 =  9.6 secs\n",
            "iteration 13 =  8.9 secs\n",
            "iteration 14 =  9.2 secs\n",
            "iteration 15 = 14.2 secs\n",
            "iteration 16 =  8.6 secs\n",
            "iteration 17 =  8.3 secs\n",
            "iteration 18 = 10.4 secs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n862kN_AaQTC",
        "colab_type": "code",
        "colab": {},
        "outputId": "62d7fd9d-569e-4e51-d5f4-ceb1ae6d2c5c"
      },
      "source": [
        "## percision scores of the classifiers\n",
        "print(\"percision scores of the classifiers:\\n\")\n",
        "\n",
        "for clf in classifier_precision.keys():\n",
        "    print(\"percision = \" + str(classifier_precision[clf].round(5)) + \", \" + str(clf))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "percision scores of the classifiers:\n",
            "\n",
            "percision = 0.93333, svm_poly3_None_C001\n",
            "percision = 0.8913, svm_poly5_None_C001\n",
            "percision = 0.89362, svm_poly7_None_C001\n",
            "percision = 0.369, svm_poly3_balanced_C001\n",
            "percision = 0.38187, svm_poly5_balanced_C001\n",
            "percision = 0.38787, svm_poly7_balanced_C001\n",
            "percision = 0.75253, svm_poly3_None_C1\n",
            "percision = 0.81325, svm_poly5_None_C1\n",
            "percision = 0.87157, svm_poly7_None_C1\n",
            "percision = 0.63187, svm_poly3_balanced_C1\n",
            "percision = 0.51679, svm_poly5_balanced_C1\n",
            "percision = 0.47801, svm_poly7_balanced_C1\n",
            "percision = 0.84725, svm_poly3_None_C100\n",
            "percision = 0.88293, svm_poly5_None_C100\n",
            "percision = 0.90498, svm_poly7_None_C100\n",
            "percision = 0.7635, svm_poly3_balanced_C100\n",
            "percision = 0.78032, svm_poly5_balanced_C100\n",
            "percision = 0.62717, svm_poly7_balanced_C100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohhV2l69aQTF",
        "colab_type": "code",
        "colab": {},
        "outputId": "0676eea2-c87d-49c0-c6d9-48c439207f17"
      },
      "source": [
        "## maximum precision score classifier\n",
        "classifier_precision_values = np.reshape(list(classifier_precision.values()), len(classifier_precision.values()), 1)\n",
        "classifier_precision_max_value = classifier_precision_values.max()\n",
        "print(\"max precision score = \" + str(classifier_precision_max_value.round(5)))\n",
        "\n",
        "key_precision_max_value = list(classifier_precision.keys())[list(classifier_precision.values()).index(classifier_precision_max_value)]\n",
        "clf_spec(key_precision_max_value)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max precision score = 0.93333\n",
            "\n",
            "classifier name = svm_poly3_None_C001\n",
            "              C = 0.001\n",
            "         degree = 3\n",
            "  class_weights = None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-BWa3ThaQTJ",
        "colab_type": "text"
      },
      "source": [
        "----\n",
        "#### 3.2.4 Making sure other cover types are not classified as spruce/fir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tD6NgaFYaQTJ",
        "colab_type": "text"
      },
      "source": [
        "If you wanted a classifier that prioritized making sure other cover types\n",
        "are not classified as spruce/fir even if it means misclassifying spruce/\fr\n",
        "types incorrectly, which combination is the best?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jz3VuyF6aQTK",
        "colab_type": "text"
      },
      "source": [
        "> **Answer**:   \n",
        "> Making sure other cover types are not classified as spruce/fir even if misclassifying spruce/fir\n",
        "types incorrectly implies having the highest recall (or the minimum false negatives) possible. So, we pick the one with the highest recall score regradless of recall."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Czf3iPziaQTM",
        "colab_type": "code",
        "colab": {},
        "outputId": "b5164a3a-b554-4a83-c778-f14c13ad7519"
      },
      "source": [
        "## recall scores of the classifiers\n",
        "print(\"recall scores of the classifiers:\\n\")\n",
        "\n",
        "for clf in classifier_recall.keys():\n",
        "    print(\"recall = \" + str(classifier_recall[clf].round(5)) + \", \" + str(clf))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "recall scores of the classifiers:\n",
            "\n",
            "recall = 0.00486, svm_poly3_None_C001\n",
            "recall = 0.01424, svm_poly5_None_C001\n",
            "recall = 0.02918, svm_poly7_None_C001\n",
            "recall = 0.99792, svm_poly3_balanced_C001\n",
            "recall = 0.99201, svm_poly5_balanced_C001\n",
            "recall = 0.99722, svm_poly7_balanced_C001\n",
            "recall = 0.56929, svm_poly3_None_C1\n",
            "recall = 0.37513, svm_poly5_None_C1\n",
            "recall = 0.24279, svm_poly7_None_C1\n",
            "recall = 0.86627, svm_poly3_balanced_C1\n",
            "recall = 0.94095, svm_poly5_balanced_C1\n",
            "recall = 0.97395, svm_poly7_balanced_C1\n",
            "recall = 0.78604, svm_poly3_None_C100\n",
            "recall = 0.74922, svm_poly5_None_C100\n",
            "recall = 0.61862, svm_poly7_None_C100\n",
            "recall = 0.8892, svm_poly3_balanced_C100\n",
            "recall = 0.88954, svm_poly5_balanced_C100\n",
            "recall = 0.95415, svm_poly7_balanced_C100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqulV7s8aQTP",
        "colab_type": "code",
        "colab": {},
        "outputId": "b3ec2c8d-dab0-49d2-be5c-2c1d44ac2c8c"
      },
      "source": [
        "## maximum recall classifier\n",
        "classifier_recall_values = np.reshape(list(classifier_recall.values()), len(classifier_recall.values()), 1)\n",
        "classifier_recall_max_value = classifier_recall_values.max()\n",
        "print(\"max recall score = \" + str(classifier_recall_max_value.round(5)))\n",
        "\n",
        "key_recall_max_value = list(classifier_recall.keys())[list(classifier_recall.values()).index(classifier_recall_max_value)]\n",
        "clf_spec(key_recall_max_value)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max recall score = 0.99792\n",
            "\n",
            "classifier name = svm_poly3_balanced_C001\n",
            "              C = 0.001\n",
            "         degree = 3\n",
            "  class_weights = balanced\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIx7gHu5aQTS",
        "colab_type": "text"
      },
      "source": [
        "----\n",
        "#### 3.2.5 Accuracy score for each combination of options on the test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-nyXw39aQTS",
        "colab_type": "text"
      },
      "source": [
        "Find the accuracy score for each combination of options on the test set.\n",
        "Which combination actually worked the best on the test set?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBBKCHiraQTT",
        "colab_type": "code",
        "colab": {},
        "outputId": "b9530641-4872-4bbd-b17a-773f89811b4c"
      },
      "source": [
        "classifier_test_acc = {}\n",
        "\n",
        "for i in range(0,len(classifier_name_list)):\n",
        "    time_start = time.perf_counter()\n",
        "    \n",
        "    classifier = globals()[classifier_name_list[i]]\n",
        "    classifier_test_acc[classifier_name_list[i]] = classifier.score(X_test_10k, y_test_10k_lb)\n",
        "    \n",
        "    time_elapsed = (time.perf_counter() - time_start)\n",
        "    print (\"iteration\", i+1, \"=%5.1f secs\" % time_elapsed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iteration 1 =  0.7 secs\n",
            "iteration 2 =  0.8 secs\n",
            "iteration 3 =  0.9 secs\n",
            "iteration 4 =  1.1 secs\n",
            "iteration 5 =  1.0 secs\n",
            "iteration 6 =  1.1 secs\n",
            "iteration 7 =  0.8 secs\n",
            "iteration 8 =  0.8 secs\n",
            "iteration 9 =  0.7 secs\n",
            "iteration 10 =  0.7 secs\n",
            "iteration 11 =  0.9 secs\n",
            "iteration 12 =  0.8 secs\n",
            "iteration 13 =  0.4 secs\n",
            "iteration 14 =  0.5 secs\n",
            "iteration 15 =  0.6 secs\n",
            "iteration 16 =  0.5 secs\n",
            "iteration 17 =  0.6 secs\n",
            "iteration 18 =  0.6 secs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXEf6ZHzaQTX",
        "colab_type": "code",
        "colab": {},
        "outputId": "c359187f-e06c-4410-ec85-d8fdef1d2cc2"
      },
      "source": [
        "## accuracy scores of the classifiers on the test set\n",
        "print(\"accuracy scores of the classifiers on the test set:\\n\")\n",
        "\n",
        "for clf in classifier_test_acc.keys():\n",
        "    print(\"accuracy = \" + str(classifier_test_acc[clf].round(5)) + \", \" + str(clf))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy scores of the classifiers on the test set:\n",
            "\n",
            "accuracy = 0.6265, svm_poly3_None_C001\n",
            "accuracy = 0.6285, svm_poly5_None_C001\n",
            "accuracy = 0.6295, svm_poly7_None_C001\n",
            "accuracy = 0.395, svm_poly3_balanced_C001\n",
            "accuracy = 0.426, svm_poly5_balanced_C001\n",
            "accuracy = 0.437, svm_poly7_balanced_C001\n",
            "accuracy = 0.7535, svm_poly3_None_C1\n",
            "accuracy = 0.7155, svm_poly5_None_C1\n",
            "accuracy = 0.681, svm_poly7_None_C1\n",
            "accuracy = 0.7515, svm_poly3_balanced_C1\n",
            "accuracy = 0.634, svm_poly5_balanced_C1\n",
            "accuracy = 0.583, svm_poly7_balanced_C1\n",
            "accuracy = 0.8285, svm_poly3_None_C100\n",
            "accuracy = 0.819, svm_poly5_None_C100\n",
            "accuracy = 0.7875, svm_poly7_None_C100\n",
            "accuracy = 0.8125, svm_poly3_balanced_C100\n",
            "accuracy = 0.8055, svm_poly5_balanced_C100\n",
            "accuracy = 0.736, svm_poly7_balanced_C100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkoMuIF6aQTY",
        "colab_type": "code",
        "colab": {},
        "outputId": "b30a8b15-aa79-40d9-9e26-cff75f9205ac"
      },
      "source": [
        "## maximum accuracy classifier\n",
        "classifier_test_acc_values = np.reshape(list(classifier_test_acc.values()), len(classifier_test_acc.values()), 1)\n",
        "classifier_test_acc_max_value = classifier_test_acc_values.max()\n",
        "print(\"max accuracy score = \" + str(classifier_test_acc_max_value.round(5)))\n",
        "\n",
        "key_acc_max_value = list(classifier_test_acc.keys())[list(classifier_test_acc.values()).index(classifier_test_acc_max_value)]\n",
        "clf_spec(key_acc_max_value)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max accuracy score = 0.8285\n",
            "\n",
            "classifier name = svm_poly3_None_C100\n",
            "              C = 100\n",
            "         degree = 3\n",
            "  class_weights = None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svdLuXuHaQTc",
        "colab_type": "text"
      },
      "source": [
        "----\n",
        "#### 3.2.6 Overall effect of increasing C"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SaWtuM6aQTc",
        "colab_type": "text"
      },
      "source": [
        "What was the overall effect of increasing C?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGFP0PyUaQTd",
        "colab_type": "text"
      },
      "source": [
        "> **Answer**:   \n",
        "> We take the standard case of `polyDeg = 3` and `class_weight=None` to study the effect of `C` using our classifiers and the evaluation of their performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhzQS21GaQTd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## helper function\n",
        "def clf_eval(classifier_name_list, criteria):\n",
        "    '''\n",
        "    returns the accuracy criteria measure before\n",
        "    for the list of the names of the classifiers provided.\n",
        "    '''\n",
        "    assert criteria in [\"C\", \"degree\", \"class_weight\"], '>>> InputError: criteria NOT in [\"C\", \"degree\", \"class_weight\"]! <<<\\n'\n",
        "    \n",
        "    for i in range(0, len(classifier_name_list)):\n",
        "        clf_acc = classifier_acc[classifier_name_list[i]]\n",
        "        clf_acc_mean = classifier_acc_mean[classifier_name_list[i]]\n",
        "        clf_acc_overall = classifier_acc_overall[classifier_name_list[i]]\n",
        "        clf_precision = classifier_precision[classifier_name_list[i]]\n",
        "        clf_recall = classifier_recall[classifier_name_list[i]]\n",
        "        clf_test_acc = classifier_test_acc[classifier_name_list[i]]\n",
        "        \n",
        "        [type, degree, class_weights, C] = classifier_name_list[i].split(\"_\")\n",
        "        if C == \"C001\":\n",
        "            C = \"C0.001\"\n",
        "        \n",
        "        if criteria == \"C\":\n",
        "            print(\"clf_CV_mean = \" + str(clf_acc_mean.round(3)) + \", \" +\n",
        "                 \"clf_acc_overall = \" + str(clf_acc_overall.round(3)) + \", \" +\n",
        "                 \"clf_precision = \" + str(clf_precision.round(3)) + \", \" +\n",
        "                 \"clf_recall = \" + str(clf_recall.round(3)) + \", \" +\n",
        "                 \"clf_test_acc = \" + str(clf_test_acc.round(3)) + \"   |C = \" + C[1:])\n",
        "            \n",
        "        elif criteria == \"degree\":\n",
        "            print(\"clf_CV_mean = \" + str(clf_acc_mean.round(3)) + \", \" +\n",
        "                 \"clf_acc_overall = \" + str(clf_acc_overall.round(3)) + \", \" +\n",
        "                 \"clf_precision = \" + str(clf_precision.round(3)) + \", \" +\n",
        "                 \"clf_recall = \" + str(clf_recall.round(3)) + \", \" +\n",
        "                 \"clf_test_acc = \" + str(clf_test_acc.round(3)) + \"   |degree = \" + degree[4:])\n",
        "        else:\n",
        "            print(\"clf_CV_mean = \" + str(clf_acc_mean.round(3)) + \", \" +\n",
        "                 \"clf_acc_overall = \" + str(clf_acc_overall.round(3)) + \", \" +\n",
        "                 \"clf_precision = \" + str(clf_precision.round(3)) + \", \" +\n",
        "                 \"clf_recall = \" + str(clf_recall.round(3)) + \", \" +\n",
        "                 \"clf_test_acc = \" + str(clf_test_acc.round(3)) + \"|weight = \" + class_weights)\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvxZgXpLaQTf",
        "colab_type": "code",
        "colab": {},
        "outputId": "114b699a-f33c-41fc-b342-3648567eb211"
      },
      "source": [
        "classifier_compar_C = [\"svm_poly3_None_C001\",\n",
        "                       \"svm_poly3_None_C1\",\n",
        "                       \"svm_poly3_None_C100\"]\n",
        "\n",
        "clf_eval(classifier_compar_C, \"C\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clf_CV_mean = 0.642, clf_acc_overall = 0.642, clf_precision = 0.933, clf_recall = 0.005, clf_test_acc = 0.626   |C = 0.001\n",
            "clf_CV_mean = 0.762, clf_acc_overall = 0.778, clf_precision = 0.753, clf_recall = 0.569, clf_test_acc = 0.754   |C = 1\n",
            "clf_CV_mean = 0.818, clf_acc_overall = 0.872, clf_precision = 0.847, clf_recall = 0.786, clf_test_acc = 0.828   |C = 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uWayhszaQTi",
        "colab_type": "text"
      },
      "source": [
        "> **Answer**:   \n",
        "> `C` is the penalization parameter that controls the tradeoff between smoothness of the boundary curve and the number of correct classification of points. Increasing `C` may lead to overfitting.   \n",
        "As we can see from the printout above, accuracy scores (clf_CV_mean, clf_acc_overall, clf_test_acc) as well as clf_recall increase as `C` increases but clf_precision decreases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtAzi7qbaQTi",
        "colab_type": "text"
      },
      "source": [
        "----\n",
        "#### 3.2.7 Overall effect of increasing the polynomial degree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JH6BgYAZaQTj",
        "colab_type": "text"
      },
      "source": [
        "What was the overall effect of increasing the polynomial degree?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLmkTD6gaQTj",
        "colab_type": "text"
      },
      "source": [
        "> **Answer**:   \n",
        "> We take the standard case of `C = 1` and `class_weight=None` to study the effect of `polyDeg` using our classifiers and the evaluation of their performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7pHNIkyaQTj",
        "colab_type": "code",
        "colab": {},
        "outputId": "fa528148-fe27-49f2-a7c3-c50c3b8fffca"
      },
      "source": [
        "classifier_compar_deg = [\"svm_poly3_None_C1\",\n",
        "                         \"svm_poly5_None_C1\",\n",
        "                         \"svm_poly7_None_C1\"]\n",
        "\n",
        "clf_eval(classifier_compar_deg, \"degree\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clf_CV_mean = 0.762, clf_acc_overall = 0.778, clf_precision = 0.753, clf_recall = 0.569, clf_test_acc = 0.754   |degree = 3\n",
            "clf_CV_mean = 0.723, clf_acc_overall = 0.744, clf_precision = 0.813, clf_recall = 0.375, clf_test_acc = 0.716   |degree = 5\n",
            "clf_CV_mean = 0.689, clf_acc_overall = 0.715, clf_precision = 0.872, clf_recall = 0.243, clf_test_acc = 0.681   |degree = 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NP66Zd0aQTl",
        "colab_type": "text"
      },
      "source": [
        "> **Answer**:   \n",
        "> Using `degree=1` is the same as using a linear kernel. Increasing this parameters increases the complexity of the model and consequently the training time. Increasing the degree of the polynomial does not necessarily lead to overfitting but rather makes the shape of the boundaries more complicated and the computation more time consuming.   \n",
        "As we can see from the printout above, accuracy scores (clf_CV_mean, clf_acc_overall, clf_test_acc) and also clf_recall decrease as `polyDeg` goes up but clf_precision increases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GqgufCIaQTl",
        "colab_type": "text"
      },
      "source": [
        "----\n",
        "#### 3.2.8 Assigning balanced weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9r3HHKWaQTl",
        "colab_type": "text"
      },
      "source": [
        "Assigning balanced weights is meant to mitigate the effect of larger label\n",
        "counts skewing the SVM result. Does it work?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KF3ejmu2aQTl",
        "colab_type": "text"
      },
      "source": [
        "> **Answer**:   \n",
        "> We take the standard case of `C = 1` and `polyDeg = 3` to study the effect of `class_weight` using our classifiers and the evaluation of their performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTlnT2jEaQTm",
        "colab_type": "code",
        "colab": {},
        "outputId": "01094a30-3b5b-4141-bfdc-904301de4e5c"
      },
      "source": [
        "classifier_compar_classWeight = [\"svm_poly3_None_C1\",\n",
        "                                 \"svm_poly3_balanced_C1\"]\n",
        "\n",
        "clf_eval(classifier_compar_classWeight, \"class_weight\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clf_CV_mean = 0.762, clf_acc_overall = 0.778, clf_precision = 0.753, clf_recall = 0.569, clf_test_acc = 0.754|weight = None\n",
            "clf_CV_mean = 0.736, clf_acc_overall = 0.77, clf_precision = 0.632, clf_recall = 0.866, clf_test_acc = 0.752|weight = balanced\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lh3TgUR9aQTo",
        "colab_type": "code",
        "colab": {},
        "outputId": "28ca4ffa-f1ab-4b9c-adbb-71b0b047cc41"
      },
      "source": [
        "classifier_compar_classWeight = [\"svm_poly5_None_C1\",\n",
        "                                 \"svm_poly5_balanced_C1\"]\n",
        "\n",
        "clf_eval(classifier_compar_classWeight, \"class_weight\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clf_CV_mean = 0.723, clf_acc_overall = 0.744, clf_precision = 0.813, clf_recall = 0.375, clf_test_acc = 0.716|weight = None\n",
            "clf_CV_mean = 0.637, clf_acc_overall = 0.662, clf_precision = 0.517, clf_recall = 0.941, clf_test_acc = 0.634|weight = balanced\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80CmVgLGaQTq",
        "colab_type": "text"
      },
      "source": [
        "> **Answer**:   \n",
        ">`C` get multiplied by `class_weight` to change the magnitude of penalization. As we can see from the printouts above, accuracy scores (clf_CV_mean, clf_acc_overall) and also clf_precision decrease when `class_weight = balanced`. In other words, the classifier works more in favor of increasing recall and somehow helps mitigate the effect of larger label."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxBWwpkQaQTq",
        "colab_type": "text"
      },
      "source": [
        "----\n",
        "### 3.3 Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KuSBB5yaQTr",
        "colab_type": "text"
      },
      "source": [
        "Did the CV scores you encountered give you confidence that the polynomial\n",
        "kernal SVM would be an improvement over the \"NOT spruce/fir\" classifier? What\n",
        "would you try to do differently to find a better SVM?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "656ufMEYaQTr",
        "colab_type": "code",
        "colab": {},
        "outputId": "5dc44a3c-1591-4be0-a936-10e0169aa4cb"
      },
      "source": [
        "classifier_acc_mean_values = list(classifier_acc_mean.values())\n",
        "print(\"max ave-CV accuracy of classifiers = \" + str(np.max(classifier_acc_mean_values)))\n",
        "print(\"min ave-CV accuracy of classifiers = \" + str(np.min(classifier_acc_mean_values)))\n",
        "print(\"\\nmean ave-CV accuracy of classifiers = \" + str(np.mean(classifier_acc_mean_values).round(5)))\n",
        "\n",
        "## never-1-calssifier defined in Problem 1\n",
        "never_1_clf_10k_acc = cross_val_score(never_1_clf_10k, X_train_10k, y_train_10k_lb, scoring=\"accuracy\")\n",
        "print(\">>>  ave_CV accuracy of never_1_clf = \" + str(np.mean(never_1_clf_10k_acc).round(5)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max ave-CV accuracy of classifiers = 0.818375\n",
            "min ave-CV accuracy of classifiers = 0.381625\n",
            "\n",
            "mean ave-CV accuracy of classifiers = 0.66677\n",
            ">>>  ave_CV accuracy of never_1_clf = 0.64013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOEFVCRhaQTt",
        "colab_type": "text"
      },
      "source": [
        "> **Answer**:   \n",
        ">As we can see, the average accuracy of CV for the 18 classifiers created earlier is almost the same as `never-1-clf` and it deos not provide any *significant* advantage over the `never-1-clf` even though for some of them the CV accuracy reached around 80%.  \n",
        "We can try tuning other parameters such as `gamma` and try other kernels to see if we get better results using `GridSearchCV`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLDW3BS4aQTu",
        "colab_type": "code",
        "colab": {},
        "outputId": "87c95199-0bda-4403-916e-77391a83a09b"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV \n",
        "\n",
        "# defining parameter range \n",
        "param_grid = {'C': [0.001, 1, 100],\n",
        "              'gamma': [1, 0.01, 0.0001],\n",
        "              'kernel': ['rbf'],\n",
        "              'class_weight': ['balanced', None]\n",
        "             } \n",
        "\n",
        "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3) \n",
        "\n",
        "# fitting the model for grid search \n",
        "grid.fit(X_train_10k, y_train_10k_lb)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
            "[CV] C=0.001, class_weight=balanced, gamma=1, kernel=rbf .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, class_weight=balanced, gamma=1, kernel=rbf, score=0.641, total=   9.1s\n",
            "[CV] C=0.001, class_weight=balanced, gamma=1, kernel=rbf .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    9.0s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, class_weight=balanced, gamma=1, kernel=rbf, score=0.640, total=   8.2s\n",
            "[CV] C=0.001, class_weight=balanced, gamma=1, kernel=rbf .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   17.2s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.001, class_weight=balanced, gamma=1, kernel=rbf, score=0.640, total=   8.3s\n",
            "[CV] C=0.001, class_weight=balanced, gamma=1, kernel=rbf .............\n",
            "[CV]  C=0.001, class_weight=balanced, gamma=1, kernel=rbf, score=0.640, total=   9.1s\n",
            "[CV] C=0.001, class_weight=balanced, gamma=1, kernel=rbf .............\n",
            "[CV]  C=0.001, class_weight=balanced, gamma=1, kernel=rbf, score=0.640, total=   9.5s\n",
            "[CV] C=0.001, class_weight=balanced, gamma=0.01, kernel=rbf ..........\n",
            "[CV]  C=0.001, class_weight=balanced, gamma=0.01, kernel=rbf, score=0.641, total=   9.2s\n",
            "[CV] C=0.001, class_weight=balanced, gamma=0.01, kernel=rbf ..........\n",
            "[CV]  C=0.001, class_weight=balanced, gamma=0.01, kernel=rbf, score=0.640, total=   8.2s\n",
            "[CV] C=0.001, class_weight=balanced, gamma=0.01, kernel=rbf ..........\n",
            "[CV]  C=0.001, class_weight=balanced, gamma=0.01, kernel=rbf, score=0.640, total=   8.3s\n",
            "[CV] C=0.001, class_weight=balanced, gamma=0.01, kernel=rbf ..........\n",
            "[CV]  C=0.001, class_weight=balanced, gamma=0.01, kernel=rbf, score=0.640, total=   8.0s\n",
            "[CV] C=0.001, class_weight=balanced, gamma=0.01, kernel=rbf ..........\n",
            "[CV]  C=0.001, class_weight=balanced, gamma=0.01, kernel=rbf, score=0.640, total=   8.0s\n",
            "[CV] C=0.001, class_weight=balanced, gamma=0.0001, kernel=rbf ........\n",
            "[CV]  C=0.001, class_weight=balanced, gamma=0.0001, kernel=rbf, score=0.641, total=   7.1s\n",
            "[CV] C=0.001, class_weight=balanced, gamma=0.0001, kernel=rbf ........\n",
            "[CV]  C=0.001, class_weight=balanced, gamma=0.0001, kernel=rbf, score=0.640, total=   7.1s\n",
            "[CV] C=0.001, class_weight=balanced, gamma=0.0001, kernel=rbf ........\n",
            "[CV]  C=0.001, class_weight=balanced, gamma=0.0001, kernel=rbf, score=0.640, total=   7.8s\n",
            "[CV] C=0.001, class_weight=balanced, gamma=0.0001, kernel=rbf ........\n",
            "[CV]  C=0.001, class_weight=balanced, gamma=0.0001, kernel=rbf, score=0.640, total=   9.3s\n",
            "[CV] C=0.001, class_weight=balanced, gamma=0.0001, kernel=rbf ........\n",
            "[CV]  C=0.001, class_weight=balanced, gamma=0.0001, kernel=rbf, score=0.640, total=   8.2s\n",
            "[CV] C=0.001, class_weight=None, gamma=1, kernel=rbf .................\n",
            "[CV]  C=0.001, class_weight=None, gamma=1, kernel=rbf, score=0.641, total=   7.4s\n",
            "[CV] C=0.001, class_weight=None, gamma=1, kernel=rbf .................\n",
            "[CV]  C=0.001, class_weight=None, gamma=1, kernel=rbf, score=0.640, total=   7.7s\n",
            "[CV] C=0.001, class_weight=None, gamma=1, kernel=rbf .................\n",
            "[CV]  C=0.001, class_weight=None, gamma=1, kernel=rbf, score=0.640, total=   7.5s\n",
            "[CV] C=0.001, class_weight=None, gamma=1, kernel=rbf .................\n",
            "[CV]  C=0.001, class_weight=None, gamma=1, kernel=rbf, score=0.640, total=   8.1s\n",
            "[CV] C=0.001, class_weight=None, gamma=1, kernel=rbf .................\n",
            "[CV]  C=0.001, class_weight=None, gamma=1, kernel=rbf, score=0.640, total=   7.6s\n",
            "[CV] C=0.001, class_weight=None, gamma=0.01, kernel=rbf ..............\n",
            "[CV]  C=0.001, class_weight=None, gamma=0.01, kernel=rbf, score=0.641, total=   8.4s\n",
            "[CV] C=0.001, class_weight=None, gamma=0.01, kernel=rbf ..............\n",
            "[CV]  C=0.001, class_weight=None, gamma=0.01, kernel=rbf, score=0.640, total=  10.0s\n",
            "[CV] C=0.001, class_weight=None, gamma=0.01, kernel=rbf ..............\n",
            "[CV]  C=0.001, class_weight=None, gamma=0.01, kernel=rbf, score=0.640, total=   8.0s\n",
            "[CV] C=0.001, class_weight=None, gamma=0.01, kernel=rbf ..............\n",
            "[CV]  C=0.001, class_weight=None, gamma=0.01, kernel=rbf, score=0.640, total=   9.5s\n",
            "[CV] C=0.001, class_weight=None, gamma=0.01, kernel=rbf ..............\n",
            "[CV]  C=0.001, class_weight=None, gamma=0.01, kernel=rbf, score=0.640, total=   7.5s\n",
            "[CV] C=0.001, class_weight=None, gamma=0.0001, kernel=rbf ............\n",
            "[CV]  C=0.001, class_weight=None, gamma=0.0001, kernel=rbf, score=0.641, total=   4.7s\n",
            "[CV] C=0.001, class_weight=None, gamma=0.0001, kernel=rbf ............\n",
            "[CV]  C=0.001, class_weight=None, gamma=0.0001, kernel=rbf, score=0.640, total=   4.7s\n",
            "[CV] C=0.001, class_weight=None, gamma=0.0001, kernel=rbf ............\n",
            "[CV]  C=0.001, class_weight=None, gamma=0.0001, kernel=rbf, score=0.640, total=   4.8s\n",
            "[CV] C=0.001, class_weight=None, gamma=0.0001, kernel=rbf ............\n",
            "[CV]  C=0.001, class_weight=None, gamma=0.0001, kernel=rbf, score=0.640, total=   5.1s\n",
            "[CV] C=0.001, class_weight=None, gamma=0.0001, kernel=rbf ............\n",
            "[CV]  C=0.001, class_weight=None, gamma=0.0001, kernel=rbf, score=0.640, total=   4.7s\n",
            "[CV] C=1, class_weight=balanced, gamma=1, kernel=rbf .................\n",
            "[CV]  C=1, class_weight=balanced, gamma=1, kernel=rbf, score=0.641, total=   8.3s\n",
            "[CV] C=1, class_weight=balanced, gamma=1, kernel=rbf .................\n",
            "[CV]  C=1, class_weight=balanced, gamma=1, kernel=rbf, score=0.640, total=   9.1s\n",
            "[CV] C=1, class_weight=balanced, gamma=1, kernel=rbf .................\n",
            "[CV]  C=1, class_weight=balanced, gamma=1, kernel=rbf, score=0.640, total=   8.7s\n",
            "[CV] C=1, class_weight=balanced, gamma=1, kernel=rbf .................\n",
            "[CV]  C=1, class_weight=balanced, gamma=1, kernel=rbf, score=0.640, total=   8.3s\n",
            "[CV] C=1, class_weight=balanced, gamma=1, kernel=rbf .................\n",
            "[CV]  C=1, class_weight=balanced, gamma=1, kernel=rbf, score=0.640, total=   9.2s\n",
            "[CV] C=1, class_weight=balanced, gamma=0.01, kernel=rbf ..............\n",
            "[CV]  C=1, class_weight=balanced, gamma=0.01, kernel=rbf, score=0.641, total=  11.3s\n",
            "[CV] C=1, class_weight=balanced, gamma=0.01, kernel=rbf ..............\n",
            "[CV]  C=1, class_weight=balanced, gamma=0.01, kernel=rbf, score=0.640, total=  12.4s\n",
            "[CV] C=1, class_weight=balanced, gamma=0.01, kernel=rbf ..............\n",
            "[CV]  C=1, class_weight=balanced, gamma=0.01, kernel=rbf, score=0.640, total=  12.6s\n",
            "[CV] C=1, class_weight=balanced, gamma=0.01, kernel=rbf ..............\n",
            "[CV]  C=1, class_weight=balanced, gamma=0.01, kernel=rbf, score=0.640, total=  10.1s\n",
            "[CV] C=1, class_weight=balanced, gamma=0.01, kernel=rbf ..............\n",
            "[CV]  C=1, class_weight=balanced, gamma=0.01, kernel=rbf, score=0.640, total=  10.3s\n",
            "[CV] C=1, class_weight=balanced, gamma=0.0001, kernel=rbf ............\n",
            "[CV]  C=1, class_weight=balanced, gamma=0.0001, kernel=rbf, score=0.751, total=   7.4s\n",
            "[CV] C=1, class_weight=balanced, gamma=0.0001, kernel=rbf ............\n",
            "[CV]  C=1, class_weight=balanced, gamma=0.0001, kernel=rbf, score=0.741, total=   7.8s\n",
            "[CV] C=1, class_weight=balanced, gamma=0.0001, kernel=rbf ............\n",
            "[CV]  C=1, class_weight=balanced, gamma=0.0001, kernel=rbf, score=0.736, total=   8.0s\n",
            "[CV] C=1, class_weight=balanced, gamma=0.0001, kernel=rbf ............\n",
            "[CV]  C=1, class_weight=balanced, gamma=0.0001, kernel=rbf, score=0.747, total=  10.3s\n",
            "[CV] C=1, class_weight=balanced, gamma=0.0001, kernel=rbf ............\n",
            "[CV]  C=1, class_weight=balanced, gamma=0.0001, kernel=rbf, score=0.750, total=   9.9s\n",
            "[CV] C=1, class_weight=None, gamma=1, kernel=rbf .....................\n",
            "[CV]  C=1, class_weight=None, gamma=1, kernel=rbf, score=0.641, total=  13.4s\n",
            "[CV] C=1, class_weight=None, gamma=1, kernel=rbf .....................\n",
            "[CV]  C=1, class_weight=None, gamma=1, kernel=rbf, score=0.640, total=   9.2s\n",
            "[CV] C=1, class_weight=None, gamma=1, kernel=rbf .....................\n",
            "[CV]  C=1, class_weight=None, gamma=1, kernel=rbf, score=0.640, total=   8.2s\n",
            "[CV] C=1, class_weight=None, gamma=1, kernel=rbf .....................\n",
            "[CV]  C=1, class_weight=None, gamma=1, kernel=rbf, score=0.640, total=  11.9s\n",
            "[CV] C=1, class_weight=None, gamma=1, kernel=rbf .....................\n",
            "[CV]  C=1, class_weight=None, gamma=1, kernel=rbf, score=0.640, total=   9.2s\n",
            "[CV] C=1, class_weight=None, gamma=0.01, kernel=rbf ..................\n",
            "[CV]  C=1, class_weight=None, gamma=0.01, kernel=rbf, score=0.641, total=  10.6s\n",
            "[CV] C=1, class_weight=None, gamma=0.01, kernel=rbf ..................\n",
            "[CV]  C=1, class_weight=None, gamma=0.01, kernel=rbf, score=0.640, total=   9.4s\n",
            "[CV] C=1, class_weight=None, gamma=0.01, kernel=rbf ..................\n",
            "[CV]  C=1, class_weight=None, gamma=0.01, kernel=rbf, score=0.640, total=  10.8s\n",
            "[CV] C=1, class_weight=None, gamma=0.01, kernel=rbf ..................\n",
            "[CV]  C=1, class_weight=None, gamma=0.01, kernel=rbf, score=0.640, total=  11.3s\n",
            "[CV] C=1, class_weight=None, gamma=0.01, kernel=rbf ..................\n",
            "[CV]  C=1, class_weight=None, gamma=0.01, kernel=rbf, score=0.640, total=  10.0s\n",
            "[CV] C=1, class_weight=None, gamma=0.0001, kernel=rbf ................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, class_weight=None, gamma=0.0001, kernel=rbf, score=0.734, total=   8.1s\n",
            "[CV] C=1, class_weight=None, gamma=0.0001, kernel=rbf ................\n",
            "[CV]  C=1, class_weight=None, gamma=0.0001, kernel=rbf, score=0.721, total=   8.2s\n",
            "[CV] C=1, class_weight=None, gamma=0.0001, kernel=rbf ................\n",
            "[CV]  C=1, class_weight=None, gamma=0.0001, kernel=rbf, score=0.722, total=   7.9s\n",
            "[CV] C=1, class_weight=None, gamma=0.0001, kernel=rbf ................\n",
            "[CV]  C=1, class_weight=None, gamma=0.0001, kernel=rbf, score=0.729, total=   8.0s\n",
            "[CV] C=1, class_weight=None, gamma=0.0001, kernel=rbf ................\n",
            "[CV]  C=1, class_weight=None, gamma=0.0001, kernel=rbf, score=0.724, total=   7.9s\n",
            "[CV] C=100, class_weight=balanced, gamma=1, kernel=rbf ...............\n",
            "[CV]  C=100, class_weight=balanced, gamma=1, kernel=rbf, score=0.641, total=   9.6s\n",
            "[CV] C=100, class_weight=balanced, gamma=1, kernel=rbf ...............\n",
            "[CV]  C=100, class_weight=balanced, gamma=1, kernel=rbf, score=0.640, total=  10.0s\n",
            "[CV] C=100, class_weight=balanced, gamma=1, kernel=rbf ...............\n",
            "[CV]  C=100, class_weight=balanced, gamma=1, kernel=rbf, score=0.640, total=   9.8s\n",
            "[CV] C=100, class_weight=balanced, gamma=1, kernel=rbf ...............\n",
            "[CV]  C=100, class_weight=balanced, gamma=1, kernel=rbf, score=0.640, total=   9.6s\n",
            "[CV] C=100, class_weight=balanced, gamma=1, kernel=rbf ...............\n",
            "[CV]  C=100, class_weight=balanced, gamma=1, kernel=rbf, score=0.640, total=   9.6s\n",
            "[CV] C=100, class_weight=balanced, gamma=0.01, kernel=rbf ............\n",
            "[CV]  C=100, class_weight=balanced, gamma=0.01, kernel=rbf, score=0.641, total=   9.9s\n",
            "[CV] C=100, class_weight=balanced, gamma=0.01, kernel=rbf ............\n",
            "[CV]  C=100, class_weight=balanced, gamma=0.01, kernel=rbf, score=0.640, total=  10.3s\n",
            "[CV] C=100, class_weight=balanced, gamma=0.01, kernel=rbf ............\n",
            "[CV]  C=100, class_weight=balanced, gamma=0.01, kernel=rbf, score=0.640, total=   9.8s\n",
            "[CV] C=100, class_weight=balanced, gamma=0.01, kernel=rbf ............\n",
            "[CV]  C=100, class_weight=balanced, gamma=0.01, kernel=rbf, score=0.640, total=   9.7s\n",
            "[CV] C=100, class_weight=balanced, gamma=0.01, kernel=rbf ............\n",
            "[CV]  C=100, class_weight=balanced, gamma=0.01, kernel=rbf, score=0.640, total=   8.5s\n",
            "[CV] C=100, class_weight=balanced, gamma=0.0001, kernel=rbf ..........\n",
            "[CV]  C=100, class_weight=balanced, gamma=0.0001, kernel=rbf, score=0.751, total=   7.0s\n",
            "[CV] C=100, class_weight=balanced, gamma=0.0001, kernel=rbf ..........\n",
            "[CV]  C=100, class_weight=balanced, gamma=0.0001, kernel=rbf, score=0.741, total=   7.3s\n",
            "[CV] C=100, class_weight=balanced, gamma=0.0001, kernel=rbf ..........\n",
            "[CV]  C=100, class_weight=balanced, gamma=0.0001, kernel=rbf, score=0.736, total=   8.2s\n",
            "[CV] C=100, class_weight=balanced, gamma=0.0001, kernel=rbf ..........\n",
            "[CV]  C=100, class_weight=balanced, gamma=0.0001, kernel=rbf, score=0.744, total=   7.4s\n",
            "[CV] C=100, class_weight=balanced, gamma=0.0001, kernel=rbf ..........\n",
            "[CV]  C=100, class_weight=balanced, gamma=0.0001, kernel=rbf, score=0.746, total=   6.9s\n",
            "[CV] C=100, class_weight=None, gamma=1, kernel=rbf ...................\n",
            "[CV]  C=100, class_weight=None, gamma=1, kernel=rbf, score=0.641, total=   8.5s\n",
            "[CV] C=100, class_weight=None, gamma=1, kernel=rbf ...................\n",
            "[CV]  C=100, class_weight=None, gamma=1, kernel=rbf, score=0.640, total=   9.8s\n",
            "[CV] C=100, class_weight=None, gamma=1, kernel=rbf ...................\n",
            "[CV]  C=100, class_weight=None, gamma=1, kernel=rbf, score=0.640, total=   9.7s\n",
            "[CV] C=100, class_weight=None, gamma=1, kernel=rbf ...................\n",
            "[CV]  C=100, class_weight=None, gamma=1, kernel=rbf, score=0.640, total=  10.4s\n",
            "[CV] C=100, class_weight=None, gamma=1, kernel=rbf ...................\n",
            "[CV]  C=100, class_weight=None, gamma=1, kernel=rbf, score=0.640, total=   9.7s\n",
            "[CV] C=100, class_weight=None, gamma=0.01, kernel=rbf ................\n",
            "[CV]  C=100, class_weight=None, gamma=0.01, kernel=rbf, score=0.641, total=  10.2s\n",
            "[CV] C=100, class_weight=None, gamma=0.01, kernel=rbf ................\n",
            "[CV]  C=100, class_weight=None, gamma=0.01, kernel=rbf, score=0.640, total=   9.9s\n",
            "[CV] C=100, class_weight=None, gamma=0.01, kernel=rbf ................\n",
            "[CV]  C=100, class_weight=None, gamma=0.01, kernel=rbf, score=0.640, total=   9.7s\n",
            "[CV] C=100, class_weight=None, gamma=0.01, kernel=rbf ................\n",
            "[CV]  C=100, class_weight=None, gamma=0.01, kernel=rbf, score=0.640, total=   9.7s\n",
            "[CV] C=100, class_weight=None, gamma=0.01, kernel=rbf ................\n",
            "[CV]  C=100, class_weight=None, gamma=0.01, kernel=rbf, score=0.640, total=   9.9s\n",
            "[CV] C=100, class_weight=None, gamma=0.0001, kernel=rbf ..............\n",
            "[CV]  C=100, class_weight=None, gamma=0.0001, kernel=rbf, score=0.751, total=   8.3s\n",
            "[CV] C=100, class_weight=None, gamma=0.0001, kernel=rbf ..............\n",
            "[CV]  C=100, class_weight=None, gamma=0.0001, kernel=rbf, score=0.741, total=   8.1s\n",
            "[CV] C=100, class_weight=None, gamma=0.0001, kernel=rbf ..............\n",
            "[CV]  C=100, class_weight=None, gamma=0.0001, kernel=rbf, score=0.736, total=   7.9s\n",
            "[CV] C=100, class_weight=None, gamma=0.0001, kernel=rbf ..............\n",
            "[CV]  C=100, class_weight=None, gamma=0.0001, kernel=rbf, score=0.744, total=   8.0s\n",
            "[CV] C=100, class_weight=None, gamma=0.0001, kernel=rbf ..............\n",
            "[CV]  C=100, class_weight=None, gamma=0.0001, kernel=rbf, score=0.746, total=   8.2s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  90 out of  90 | elapsed: 13.2min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
              "                           class_weight=None, coef0=0.0,\n",
              "                           decision_function_shape='ovr', degree=3,\n",
              "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
              "                           probability=False, random_state=None, shrinking=True,\n",
              "                           tol=0.001, verbose=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'C': [0.001, 1, 100],\n",
              "                         'class_weight': ['balanced', None],\n",
              "                         'gamma': [1, 0.01, 0.0001], 'kernel': ['rbf']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWOw0dleaQTy",
        "colab_type": "code",
        "colab": {},
        "outputId": "2295a8d6-464e-4221-c52b-22ab7ae8ee13"
      },
      "source": [
        "# best parameter after tuning\n",
        "best_params = grid.best_params_\n",
        "best_clf = grid.best_estimator_\n",
        "for key in best_params:\n",
        "    print(str(key) + \" = \" + str(best_params[key]))\n",
        "print(\"\\nbest classifier =\\n\", best_clf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C = 1\n",
            "class_weight = balanced\n",
            "gamma = 0.0001\n",
            "kernel = rbf\n",
            "\n",
            "best classifier =\n",
            " SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma=0.0001, kernel='rbf',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqTfHu_MaQT1",
        "colab_type": "code",
        "colab": {},
        "outputId": "772a847f-5472-4d53-e290-1e18a2db912a"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix \n",
        "\n",
        "grid_pred = grid.predict(X_test_10k) \n",
        "print(classification_report(y_test_10k_lb, grid_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.95      0.83      1252\n",
            "           1       0.84      0.42      0.56       748\n",
            "\n",
            "    accuracy                           0.75      2000\n",
            "   macro avg       0.79      0.68      0.69      2000\n",
            "weighted avg       0.77      0.75      0.73      2000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}