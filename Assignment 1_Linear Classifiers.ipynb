{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ME 5984 Applied Machine Learning, Assignment 1: Linear classiers (Perceptron, SVM)\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will explore linear classication on the forest cover-type dataset created by Jock Blackard et. al. in 1998. It is used frequently enough that scikit-learn has made it a standard dataset.  \n",
    "https://scikit-learn.org/stable/datasets/index.html#covtype-dataset  \n",
    "https://archive.ics.uci.edu/ml/datasets/Covertype  \n",
    "The data set includes 54 features (reals, integers, and booleans) and 7 classications numbered 1-7: spruce/firr, lodgepole pine, Ponderosa pine, cottonwood/willow, aspen, Douglas-fir, and Krummholz. The scikit-learn implementation has converted all of these values to real numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing and Partitioning the Data\n",
    "### 1.1 Get the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using scikit-learn, import the Forest covertype data set, shuffling it with random state 5984 in the call to fetch it. Set these to X and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = \n",
      "[[2903.   87.   27. ...    0.    0.    0.]\n",
      " [2674.   52.   11. ...    0.    0.    0.]\n",
      " [2867.  357.   14. ...    0.    0.    0.]\n",
      " ...\n",
      " [3053.  166.   18. ...    0.    0.    0.]\n",
      " [2981.  352.   18. ...    0.    0.    0.]\n",
      " [3041.   37.    5. ...    0.    0.    0.]]\n",
      "\n",
      "y = [5 2 2 ... 1 2 1]\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "%matplotlib inline\n",
    "from sklearn import datasets\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# fetch dataset, set random_state and shuffle\n",
    "covtype = datasets.fetch_covtype(data_home=None, download_if_missing=True, random_state=5984, shuffle=True)\n",
    "X = covtype[\"data\"]\n",
    "y = covtype[\"target\"]\n",
    "\n",
    "print(\"X = \\n\" + str(X) + \"\\n\")\n",
    "print(\"y = \" + str(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X dim = (581012, 54) \n",
      "y dim = (581012,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X dim =\", X.shape, \"\\ny dim =\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### 1.2 Checking the Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many instances of each of the seven classes exist in the data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instances in class_1 = (211840,)\n",
      "instances in class_2 = (283301,)\n",
      "instances in class_3 = (35754,)\n",
      "instances in class_4 = (2747,)\n",
      "instances in class_5 = (9493,)\n",
      "instances in class_6 = (17367,)\n",
      "instances in class_7 = (20510,)\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,8):\n",
    "    name = \"instances in class_\" + str(i) + \" =\"\n",
    "    print(name, y[y == i].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### 1.3 Choosing Subsets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data and label subsets of size 5000, 10000, and 100000, choosing the first\n",
    "N elements of the shu\u000fed imported data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_5k, y_5k = X[0:5000,:], y[0:5000]\n",
    "X_10k, y_10k = X[0:10000,:], y[0:10000]\n",
    "X_100k, y_100k = X[0:100000,:], y[0:100000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### 1.4 Splitting the Subsets into Training and Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `train_test_split` to set aside 20% of each test set with random state 5984."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_5k, X_test_5k, y_train_5k, y_test_5k = train_test_split(X_5k, y_5k, test_size=0.20, random_state=5984)\n",
    "X_train_10k, X_test_10k, y_train_10k, y_test_10k = train_test_split(X_10k, y_10k, test_size=0.20, random_state=5984)\n",
    "X_train_100k, X_test_100k, y_train_100k, y_test_100k = train_test_split(X_100k, y_100k, test_size=0.20, random_state=5984)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### 1.5 Remaking the Labels for Binary Classi\f",
    "cation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each y subset, create a label vector that indicates if each label is spruce/fir\n",
    "(1) or not (0). Use the subsets you already created as the basis for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5k: original labels = [1 2 3 ... 2 6 2]\n",
      "5k: binary labels   = [1 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# binary values for spruce/fir label\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "y_train_5k_lb = lb.fit_transform(y_train_5k == 1).ravel()\n",
    "y_train_10k_lb = lb.fit_transform(y_train_10k == 1).ravel()\n",
    "y_train_100k_lb = lb.fit_transform(y_train_100k == 1).ravel()\n",
    "\n",
    "y_test_5k_lb = lb.fit_transform(y_test_5k == 1).ravel()\n",
    "y_test_10k_lb = lb.fit_transform(y_test_10k == 1).ravel()\n",
    "y_test_100k_lb = lb.fit_transform(y_test_100k == 1).ravel()\n",
    "\n",
    "## as an example just to check\n",
    "print(\"5k: original labels =\", y_train_5k)\n",
    "print(\"5k: binary labels   =\", y_train_5k_lb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### 1.6 Baseline Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each training subset, calculate the accuracy of a NOT spruce/fir\" estimator,\n",
    "that is, one that outputs 0 for every input. Hint: the sum of the labels in each\n",
    "training label subset can be used to quickly calculate this value without making\n",
    "a specfic function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## a classifier that say every inputs is NOT spruce/fir\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "class Never1Classifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5k: accuracy of folds = [0.66    0.6575  0.62875 0.62375 0.6375 ]\n",
      "5k: av. accuracy of folds = 0.6415\n",
      "5k: accuracy using labels = 0.6415\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 5k sample\n",
    "never_1_clf_5k = Never1Classifier()\n",
    "never_1_clf_5k_acc = cross_val_score(never_1_clf_5k, X_train_5k, y_train_5k_lb, scoring=\"accuracy\")\n",
    "print(\"5k: accuracy of folds = \" + str(never_1_clf_5k_acc.round(5)))\n",
    "print(\"5k: av. accuracy of folds = \" + str(np.mean(never_1_clf_5k_acc).round(5)))\n",
    "\n",
    "# accuracy using the labels\n",
    "manual_5k_acc = y_train_5k_lb[y_train_5k_lb == 0].size / y_train_5k_lb.size\n",
    "print(\"5k: accuracy using labels = \" + str(round(manual_5k_acc, 5)) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10k: accuracy of folds = [0.635   0.64875 0.64438 0.62687 0.64562]\n",
      "10k: av. accuracy of folds = 0.64013\n",
      "10k: accuracy using labels = 0.64013\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 10k sample\n",
    "never_1_clf_10k = Never1Classifier()\n",
    "never_1_clf_10k_acc = cross_val_score(never_1_clf_10k, X_train_10k, y_train_10k_lb, scoring=\"accuracy\")\n",
    "print(\"10k: accuracy of folds = \" + str(never_1_clf_10k_acc.round(5)))\n",
    "print(\"10k: av. accuracy of folds = \" + str(np.mean(never_1_clf_10k_acc).round(5)))\n",
    "\n",
    "# accuracy using the labels\n",
    "manual_10k_acc = y_train_10k_lb[y_train_10k_lb == 0].size / y_train_10k_lb.size\n",
    "print(\"10k: accuracy using labels = \" + str(round(manual_10k_acc, 5)) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100k: accuracy of folds = [0.6325  0.638   0.63513 0.63475 0.63356]\n",
      "100k: av. accuracy of folds = 0.63479\n",
      "100k: accuracy using labels = 0.63479\n"
     ]
    }
   ],
   "source": [
    "## 100k sample\n",
    "never_1_clf_100k = Never1Classifier()\n",
    "never_1_clf_100k_acc = cross_val_score(never_1_clf_100k, X_train_100k, y_train_100k_lb, scoring=\"accuracy\")\n",
    "print(\"100k: accuracy of folds = \" + str(never_1_clf_100k_acc.round(5)))\n",
    "print(\"100k: av. accuracy of folds = \" + str(np.mean(never_1_clf_100k_acc).round(5)))\n",
    "\n",
    "# accuracy using the labels\n",
    "manual_100k_acc = y_train_100k_lb[y_train_100k_lb == 0].size / y_train_100k_lb.size\n",
    "print(\"100k: accuracy using labels = \" + str(round(manual_100k_acc, 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## 2. Perceptron Classication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 5000 sample and 100000 sample subsets, you will create a Perceptron\n",
    "classifier that determines whether each sample point is spruce/fir or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Perceptron Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each binary data and label subset, train the `Perceptron` classifier with no\n",
    "added arguments, using only the training subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
      "           fit_intercept=True, max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
      "           penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
      "           validation_fraction=0.1, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "## perceptron for 5k sample\n",
    "clf = Perceptron()\n",
    "perc_clf_5k = clf.fit(X_train_5k, y_train_5k_lb)\n",
    "print(perc_clf_5k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept = [-830.]\n",
      "\n",
      "coefficients = \n",
      "[[ 2.36920e+04 -8.62500e+03 -4.08030e+04 -1.08500e+04 -2.99760e+04\n",
      "  -5.08500e+03 -1.63245e+05 -1.21804e+05 -4.31710e+04 -2.18500e+03\n",
      "   4.85000e+02  7.73000e+02 -1.44500e+03 -6.43000e+02 -2.70000e+01\n",
      "  -1.18000e+02 -5.70000e+01 -2.29000e+02 -2.10000e+01 -8.90000e+01\n",
      "   0.00000e+00 -6.00000e+00  9.00000e+00 -9.23000e+02 -2.96000e+02\n",
      "  -6.96000e+02 -3.77000e+02 -1.40000e+01  0.00000e+00 -4.20000e+01\n",
      "  -8.90000e+01 -8.00000e+00  5.40000e+01  1.62000e+02  7.80000e+01\n",
      "   1.18800e+03  1.69500e+03  2.80000e+02 -1.50000e+01 -8.50000e+01\n",
      "  -1.00000e+01 -3.30000e+01 -6.96000e+02 -3.11000e+02 -6.60000e+01\n",
      "  -1.15000e+02 -2.12000e+02 -3.10000e+01  2.00000e+00 -1.10000e+01\n",
      "  -8.00000e+00  2.58000e+02 -8.10000e+01  1.10000e+02]]\n"
     ]
    }
   ],
   "source": [
    "## intecept and coefficients\n",
    "print(\"intercept = \" + str(perc_clf_5k.intercept_) + \"\\n\")\n",
    "print(\"coefficients = \\n\" + str(perc_clf_5k.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
      "           fit_intercept=True, max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
      "           penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
      "           validation_fraction=0.1, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "## perceptron for 100k sample\n",
    "perc_clf_100k = clf.fit(X_train_100k, y_train_100k_lb)\n",
    "print(perc_clf_100k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept = [-6011.]\n",
      "\n",
      "coefficients = \n",
      "[[ 4.16210e+04 -5.85200e+03 -4.94300e+05 -1.44390e+04 -2.42920e+04\n",
      "  -1.41300e+03 -3.63998e+05 -2.40740e+04 -2.18044e+05 -1.02000e+03\n",
      "   1.02980e+04  2.67300e+03 -1.68680e+04 -2.11400e+03 -5.90000e+01\n",
      "  -5.58000e+02 -2.42000e+02 -1.05100e+03 -2.80000e+01 -1.86000e+02\n",
      "  -1.11000e+02 -4.30000e+01  4.76000e+02 -5.95700e+03 -2.19400e+03\n",
      "  -9.01400e+03 -4.31000e+03 -1.40000e+01  0.00000e+00 -2.90000e+01\n",
      "  -3.96000e+02 -2.91000e+02  1.48400e+03  2.04600e+03  9.19000e+02\n",
      "   2.22450e+04  2.43180e+04  2.40000e+01 -2.01000e+02 -6.42000e+02\n",
      "   5.52000e+02 -3.80000e+02 -9.53000e+03 -5.92800e+03  1.64500e+03\n",
      "  -4.60800e+03 -2.70000e+02 -8.23000e+02 -1.05000e+03 -6.50000e+01\n",
      "  -4.95000e+02 -3.82200e+03 -4.50900e+03 -2.91400e+03]]\n"
     ]
    }
   ],
   "source": [
    "## intercept and coefficients\n",
    "print(\"intercept = \" + str(perc_clf_100k.intercept_) + \"\\n\")\n",
    "print(\"coefficients = \\n\" + str(perc_clf_100k.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "#### 2.1.1 Accuracy on the training sets and the test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the accuracy on the training sets and the test sets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5k: training set accuracy = 0.72375\n",
      "5k: test set accuracy     = 0.724\n"
     ]
    }
   ],
   "source": [
    "## 5k samples\n",
    "perc_clf_5k_train_acc = perc_clf_5k.score(X_train_5k, y_train_5k_lb)\n",
    "perc_clf_5k_test_acc = perc_clf_5k.score(X_test_5k, y_test_5k_lb)\n",
    "\n",
    "print(\"5k: training set accuracy = \" + str(perc_clf_5k_train_acc))\n",
    "print(\"5k: test set accuracy     = \" + str(perc_clf_5k_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100k: training set accuracy = 0.7195875\n",
      "100k: test set accuracy     = 0.7166\n"
     ]
    }
   ],
   "source": [
    "## 100k samples\n",
    "perc_clf_100k_train_acc = perc_clf_100k.score(X_train_100k, y_train_100k_lb)\n",
    "perc_clf_100k_test_acc = perc_clf_100k.score(X_test_100k, y_test_100k_lb)\n",
    "\n",
    "print(\"100k: training set accuracy = \" + str(perc_clf_100k_train_acc))\n",
    "print(\"100k: test set accuracy     = \" + str(perc_clf_100k_test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "#### 2.1.2 Confusion matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the confusion matrix on the test sets? Use the predicted labels\n",
    "as a basis for comparison to the true labels for each test set. What does\n",
    "the confusion matrix tell you about the classifier's ability to correctly and\n",
    "incorrectly predict whether each sample is a spruce/fir cover or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "5k: number of true (1) labels in test set = 377\n",
      "===============================================\n",
      "confusion matrix =\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[569,  54],\n",
       "       [222, 155]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "## 5k sample\n",
    "print(\"===============================================\")\n",
    "print(\"5k: number of true (1) labels in test set = \" + str(y_test_5k_lb[y_test_5k_lb == 1].size))\n",
    "print(\"===============================================\\n\" + \"confusion matrix =\")\n",
    "\n",
    "perc_clf_5k_test_pred = perc_clf_5k.predict(X_test_5k)\n",
    "confusion_matrix(y_test_5k_lb, perc_clf_5k_test_pred)\n",
    "# First row is 0's, second row is 1's\n",
    "# First column is number correctly predicted, second is incorrectly predicted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "100k: number of true (1) labels in test set = 7191\n",
      "==================================================\n",
      "confusion matrix =\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[11400,  1409],\n",
       "       [ 4259,  2932]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 100k sample\n",
    "print(\"==================================================\")\n",
    "print(\"100k: number of true (1) labels in test set = \" + str(y_test_100k_lb[y_test_100k_lb == 1].size))\n",
    "print(\"==================================================\\n\" + \"confusion matrix =\")\n",
    "\n",
    "perc_clf_100k_test_pred = perc_clf_100k.predict(X_test_100k)\n",
    "confusion_matrix(y_test_100k_lb, perc_clf_100k_test_pred)\n",
    "# First row is 0's, second row is 1's\n",
    "# First column is number correctly predicted, second is incorrectly predicted\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  **Answer**:  \n",
    "> We can see that the number of False-Postives and False-Negatives on the off-diagonal entries for both samples sizes, is not small compared to the number of correctly predicted labels. This means our calssifier is not doing a good job predicting the binary labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "#### 2.1.3 Precision and recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the precision and recall on the test sets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5k: precision = 0.7416267942583732\n",
      "5k: recall    = 0.41114058355437666\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "## 5k sample\n",
    "perc_clf_5k_test_pred_precision = precision_score(y_test_5k_lb, perc_clf_5k_test_pred)\n",
    "perc_clf_5k_test_pred_recall = recall_score(y_test_5k_lb, perc_clf_5k_test_pred)\n",
    "print(\"5k: precision = \" + str(perc_clf_5k_test_pred_precision))\n",
    "print(\"5k: recall    = \" + str(perc_clf_5k_test_pred_recall) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100k: precision = 0.6754204100437687\n",
      "100k: recall    = 0.40773188708107355\n"
     ]
    }
   ],
   "source": [
    "## 100k sample\n",
    "perc_clf_100k_test_pred_precision = precision_score(y_test_100k_lb, perc_clf_100k_test_pred)\n",
    "perc_clf_100k_test_pred_recall = recall_score(y_test_100k_lb, perc_clf_100k_test_pred)\n",
    "print(\"100k: precision = \" + str(perc_clf_100k_test_pred_precision))\n",
    "print(\"100k: recall    = \" + str(perc_clf_100k_test_pred_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "#### 2.1.4 Precision and recall vs. threshold plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the decision function as the threshold, plot precision and recall vs.\n",
    "threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## helper function\n",
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\", linewidth=2)\n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\", linewidth=2)\n",
    "    plt.xlabel(\"Threshold\", fontsize=16)\n",
    "    plt.legend(loc=\"upper left\", fontsize=16)\n",
    "    plt.ylim([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "## 5k samples\n",
    "perc_5k_test_y_scores = perc_clf_5k.decision_function(X_test_5k)\n",
    "perc_5k_precisions, perc_5k_recalls, perc_5k_thresholds = precision_recall_curve(y_test_5k_lb, perc_5k_test_y_scores)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.title(\"5k Sample\", fontsize=18)\n",
    "plot_precision_recall_vs_threshold(perc_5k_precisions, perc_5k_recalls, perc_5k_thresholds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 100k sample\n",
    "perc_100k_test_y_scores = perc_clf_100k.decision_function(X_test_100k)\n",
    "perc_100k_precisions, perc_100k_recalls, perc_100k_thresholds = precision_recall_curve(y_test_100k_lb, perc_100k_test_y_scores)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.title(\"100k Sample\", fontsize=18)\n",
    "plot_precision_recall_vs_threshold(perc_100k_precisions, perc_100k_recalls, perc_100k_thresholds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "#### 2.1.5 F score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the decision function as the threshold, what threshold value maximizes the F score, and what is the value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer**:   \n",
    ">`F-score` maximizes at the point where the percision and recall are very close or equal to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5k: best threshold =  -9447000.0\n",
      "5k: best F1-Score  =  0.70575\n"
     ]
    }
   ],
   "source": [
    "## 5k samples\n",
    "perc_5k_test_y_scores = perc_clf_5k.decision_function(X_test_5k)\n",
    "perc_5k_precisions, perc_5k_recalls, perc_5k_thresholds = precision_recall_curve(y_test_5k_lb, perc_5k_test_y_scores)\n",
    "\n",
    "f1_scores_5k = 2*perc_5k_recalls*perc_5k_precisions/(perc_5k_recalls + perc_5k_precisions)\n",
    "print('5k: best threshold = ', perc_5k_thresholds[np.argmax(f1_scores_5k)])\n",
    "print('5k: best F1-Score  = ', np.nanmax(f1_scores_5k).round(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100k: best threshold =  28655956.0\n",
      "100k: best F1-Score  =  0.68904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohammad Hosseini\\WorkingOn\\ME 5984-Applied Machine Learning\\Homework Assignements\\WPy64-3760\\python-3.7.6.amd64\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "## 100k sample\n",
    "perc_100k_test_y_scores = perc_clf_100k.decision_function(X_test_100k)\n",
    "perc_100k_precisions, perc_100k_recalls, perc_100k_thresholds = precision_recall_curve(y_test_100k_lb, perc_100k_test_y_scores)\n",
    "                                                                                       \n",
    "f1_scores_100k = 2*perc_100k_recalls*perc_100k_precisions/(perc_100k_recalls + perc_100k_precisions)\n",
    "print('100k: best threshold = ', perc_100k_thresholds[np.argmax(f1_scores_100k)])\n",
    "print('100k: best F1-Score  = ', np.nanmax(f1_scores_100k).round(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Would you say the old-fashioned Perceptron algorithm is useful for this data\n",
    "set? Is it better than a NOT spruce/fir\" classifier in any scenario? Why or why\n",
    "not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set accuracy of perc_clf = 0.717\n",
      ">> precision for perc_clf = 0.69362\n",
      ">> recall for perc_clf    = 0.43583\n",
      "\n",
      "ave_CV accuracy of never_1_clf = 0.6401\n"
     ]
    }
   ],
   "source": [
    "perc_clf_10k_test_acc = perc_clf_100k.score(X_test_10k, y_test_10k_lb)\n",
    "perc_clf_10k_test_pred = perc_clf_100k.predict(X_test_10k)\n",
    "perc_clf_10k_test_pred_precision = precision_score(y_test_10k_lb, perc_clf_10k_test_pred)\n",
    "perc_clf_10k_test_pred_recall = recall_score(y_test_10k_lb, perc_clf_10k_test_pred)\n",
    "\n",
    "print(\"test set accuracy of perc_clf = \" + str(perc_clf_10k_test_acc))\n",
    "print(\">> precision for perc_clf = \" + str(perc_clf_10k_test_pred_precision.round(5)))\n",
    "print(\">> recall for perc_clf    = \" + str(perc_clf_10k_test_pred_recall.round(5)))\n",
    "\n",
    "## never-1-calssifier defined in Problem 1\n",
    "never_1_clf_10k_acc = cross_val_score(never_1_clf_10k, X_train_10k, y_train_10k_lb, scoring=\"accuracy\")\n",
    "print(\"\\nave_CV accuracy of never_1_clf = \" + str(np.mean(never_1_clf_10k_acc).round(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer**:   \n",
    "> Blindly labeling every point with `0` is 64% accurate whereas running the perceptron gives the accuracy of 71%, slightly better than the `never_1_clf`. Using perceptron does not seem to be useful with this accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## 3. Support Vector Machine Binary Classi\f",
    "cation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem you will use the 10000 sample subset you made back in Problem\n",
    "1 and will learn how to use grid search to tune hyperparameters to get the\n",
    "performance you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Scaling and Solver Speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `C=1`, `polydeg=3`, `class weight=None`, create a both `SVC` classifer, and a\n",
    "`Pipeline` that uses `StandardScalar` to scale the `X` subset prior to using another `SVC` classifier. Try running both. What can you say about the relative speeds?\n",
    "Why do you think this is happening?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='poly',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import time\n",
    "\n",
    "## SVM with unscaled dataset\n",
    "svm_clf_poly_unscaled = SVC(C=1.0, degree=3, class_weight=None, kernel='poly')\n",
    "svm_clf_poly_unscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unscaled dataset computation time =   4.8 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_start_unscaled = time.perf_counter()\n",
    "svm_clf_poly_unscaled.fit(X_train_10k, y_train_10k_lb)\n",
    "\n",
    "time_elapsed_unscaled = (time.perf_counter() - time_start_unscaled)\n",
    "print (\"unscaled dataset computation time = %5.1f secs\" % time_elapsed_unscaled + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('svc',\n",
       "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
       "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
       "                     gamma='scale', kernel='poly', max_iter=-1,\n",
       "                     probability=False, random_state=None, shrinking=True,\n",
       "                     tol=0.001, verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## SVM with scaled dataset\n",
    "svm_clf_poly_scaled = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svc\", SVC(C=1.0, degree=3, class_weight=None, kernel='poly'))\n",
    "    ])\n",
    "svm_clf_poly_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaled dataset computation time =   4.7 secs\n"
     ]
    }
   ],
   "source": [
    "time_start_scaled = time.perf_counter()\n",
    "svm_clf_poly_scaled.fit(X_train_10k, y_train_10k_lb)\n",
    "\n",
    "time_elapsed_scaled = (time.perf_counter() - time_start_scaled)\n",
    "print (\"scaled dataset computation time = %5.1f secs\" % time_elapsed_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer**:   \n",
    "> The program computes faster with the scaled data since the variance in all directions is 1 and data set in not skewed (balanced) which helps the solver to find the solution faster and makes the SVM more reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### 3.2 Polynomial Kernel Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without using scikit-learn's `GridSearchCV` module, create a loop that trains an\n",
    "SVC over each combination of the following parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = [0.001,1,100]\n",
    "class_weights = [None,'balanced']\n",
    "polydegs = [3,5,7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you did this right, you should have 18 different classifiers. Hint: use\n",
    "Python's `itertools.product` to generate the 18 option sets without using 3\n",
    "nested for loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier 0: svm_poly3_None_C001\n",
      "classifier 1: svm_poly5_None_C001\n",
      "classifier 2: svm_poly7_None_C001\n",
      "classifier 3: svm_poly3_balanced_C001\n",
      "classifier 4: svm_poly5_balanced_C001\n",
      "classifier 5: svm_poly7_balanced_C001\n",
      "classifier 6: svm_poly3_None_C1\n",
      "classifier 7: svm_poly5_None_C1\n",
      "classifier 8: svm_poly7_None_C1\n",
      "classifier 9: svm_poly3_balanced_C1\n",
      "classifier 10: svm_poly5_balanced_C1\n",
      "classifier 11: svm_poly7_balanced_C1\n",
      "classifier 12: svm_poly3_None_C100\n",
      "classifier 13: svm_poly5_None_C100\n",
      "classifier 14: svm_poly7_None_C100\n",
      "classifier 15: svm_poly3_balanced_C100\n",
      "classifier 16: svm_poly5_balanced_C100\n",
      "classifier 17: svm_poly7_balanced_C100\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "classifier_name_list = []\n",
    "for i,comb in enumerate(itertools.product(Cs, class_weights, polydegs)):\n",
    "    degree = comb[2]\n",
    "    class_weight = comb[1]\n",
    "    C = comb[0]\n",
    "    \n",
    "    global name\n",
    "    if C != Cs[0]:\n",
    "        name = \"svm_poly\" + str(comb[2]) + \"_\" +  str(comb[1]) + \"_C\" +  str(comb[0])\n",
    "    else:\n",
    "        name = \"svm_poly\" + str(comb[2]) + \"_\" +  str(comb[1]) + \"_C001\"\n",
    "    \n",
    "    classifier_name_list.append(name)\n",
    "    print(\"classifier\", str(i) + \":\", classifier_name_list[i])\n",
    "    \n",
    "    globals()[name] = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svc\", SVC(C=C, degree=degree, class_weight=class_weight, kernel='poly'))\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('svc',\n",
       "                 SVC(C=0.001, break_ties=False, cache_size=200,\n",
       "                     class_weight='balanced', coef0=0.0,\n",
       "                     decision_function_shape='ovr', degree=7, gamma='scale',\n",
       "                     kernel='poly', max_iter=-1, probability=False,\n",
       "                     random_state=None, shrinking=True, tol=0.001,\n",
       "                     verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## an example to check if everything is fine\n",
    "svm_poly7_balanced_C001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "#### 3.2.1 Accuracy scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `cross_val_score` to generate accuracy scores for each validation set.\n",
    "Using the average CV score, what is the best combination?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer**:   \n",
    "> We pick the one with the highest CV score mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1 = 20.8 secs\n",
      "iteration 2 = 21.0 secs\n",
      "iteration 3 = 20.3 secs\n",
      "iteration 4 = 40.4 secs\n",
      "iteration 5 = 29.1 secs\n",
      "iteration 6 = 28.9 secs\n",
      "iteration 7 = 16.5 secs\n",
      "iteration 8 = 20.2 secs\n",
      "iteration 9 = 21.9 secs\n",
      "iteration 10 = 21.5 secs\n",
      "iteration 11 = 24.5 secs\n",
      "iteration 12 = 30.4 secs\n",
      "iteration 13 = 34.3 secs\n",
      "iteration 14 = 25.7 secs\n",
      "iteration 15 = 25.6 secs\n",
      "iteration 16 = 27.6 secs\n",
      "iteration 17 = 33.0 secs\n",
      "iteration 18 = 29.9 secs\n"
     ]
    }
   ],
   "source": [
    "classifier_acc = {}\n",
    "classifier_acc_mean = {}\n",
    "\n",
    "for i in range(0,len(classifier_name_list)):\n",
    "    time_start = time.perf_counter()\n",
    "    \n",
    "    classifier = globals()[classifier_name_list[i]]\n",
    "    temp_acc = cross_val_score(classifier, X_train_10k, y_train_10k_lb, scoring=\"accuracy\")\n",
    "    classifier_acc[classifier_name_list[i]] = temp_acc\n",
    "    classifier_acc_mean[classifier_name_list[i]] = np.mean(temp_acc)\n",
    "    \n",
    "    time_elapsed = (time.perf_counter() - time_start)\n",
    "    print (\"iteration\", i+1, \"=%5.1f secs\" % time_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for classifiers using CV:\n",
      "\n",
      "svm_poly3_None_C001 = [0.64188 0.64188 0.6425  0.63938 0.64312]\n",
      "svm_poly5_None_C001 = [0.64312 0.64562 0.64375 0.64188 0.6425 ]\n",
      "svm_poly7_None_C001 = [0.64312 0.64938 0.64562 0.63875 0.64625]\n",
      "svm_poly3_balanced_C001 = [0.38    0.38    0.37688 0.3825  0.38875]\n",
      "svm_poly5_balanced_C001 = [0.40875 0.41688 0.41062 0.41812 0.43062]\n",
      "svm_poly7_balanced_C001 = [0.42188 0.42062 0.42312 0.43    0.44   ]\n",
      "svm_poly3_None_C1 = [0.76312 0.7575  0.7725  0.76312 0.7525 ]\n",
      "svm_poly5_None_C1 = [0.71938 0.7375  0.725   0.71375 0.71812]\n",
      "svm_poly7_None_C1 = [0.69375 0.69812 0.68875 0.67062 0.69188]\n",
      "svm_poly3_balanced_C1 = [0.72375 0.74625 0.73812 0.705   0.7675 ]\n",
      "svm_poly5_balanced_C1 = [0.62062 0.635   0.63438 0.62438 0.66938]\n",
      "svm_poly7_balanced_C1 = [0.56625 0.56063 0.56625 0.55188 0.6325 ]\n",
      "svm_poly3_None_C100 = [0.80625 0.81875 0.82375 0.82688 0.81625]\n",
      "svm_poly5_None_C100 = [0.81062 0.81625 0.80812 0.80062 0.79938]\n",
      "svm_poly7_None_C100 = [0.79    0.78188 0.7725  0.77188 0.77375]\n",
      "svm_poly3_balanced_C100 = [0.79188 0.80812 0.80562 0.8     0.82188]\n",
      "svm_poly5_balanced_C100 = [0.795   0.80688 0.8     0.78375 0.82   ]\n",
      "svm_poly7_balanced_C100 = [0.70562 0.70938 0.71188 0.685   0.7625 ]\n"
     ]
    }
   ],
   "source": [
    "## accuracy for CV folds\n",
    "for i, key in enumerate(classifier_acc.keys()):\n",
    "    if i == 0: print(\"accuracy for classifiers using CV:\\n\")\n",
    "    print(str(key) + \" = \" + str(classifier_acc[key].round(5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average accuracy of the folds for the classifiers:\n",
      "\n",
      "svm_poly3_None_C001 = 0.64175\n",
      "svm_poly5_None_C001 = 0.64338\n",
      "svm_poly7_None_C001 = 0.64462\n",
      "svm_poly3_balanced_C001 = 0.38162\n",
      "svm_poly5_balanced_C001 = 0.417\n",
      "svm_poly7_balanced_C001 = 0.42712\n",
      "svm_poly3_None_C1 = 0.76175\n",
      "svm_poly5_None_C1 = 0.72275\n",
      "svm_poly7_None_C1 = 0.68862\n",
      "svm_poly3_balanced_C1 = 0.73612\n",
      "svm_poly5_balanced_C1 = 0.63675\n",
      "svm_poly7_balanced_C1 = 0.5755\n",
      "svm_poly3_None_C100 = 0.81838\n",
      "svm_poly5_None_C100 = 0.807\n",
      "svm_poly7_None_C100 = 0.778\n",
      "svm_poly3_balanced_C100 = 0.8055\n",
      "svm_poly5_balanced_C100 = 0.80113\n",
      "svm_poly7_balanced_C100 = 0.71487\n"
     ]
    }
   ],
   "source": [
    "## average accuracy of the folds\n",
    "for i, key in enumerate(classifier_acc_mean.keys()):\n",
    "    if i == 0:\n",
    "        print(\"average accuracy of the folds for the classifiers:\\n\")        \n",
    "    print(str(key) + \" = \" + str(classifier_acc_mean[key].round(5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## helper function\n",
    "def clf_spec(classifier_name):\n",
    "    [type, degree, class_weights, C] = classifier_name.split(\"_\")\n",
    "    print(\"\\nclassifier name = \" + str(classifier_name))\n",
    "    print(\"              C = \" + str(C[1:])) if C != \"C001\" else print(\"              C = 0.001\")\n",
    "    print(\"         degree = \" + str(degree[4:]))\n",
    "    print(\"  class_weights = \" + str(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max CV score mean= 0.818375\n",
      "\n",
      "classifier name = svm_poly3_None_C100\n",
      "              C = 100\n",
      "         degree = 3\n",
      "  class_weights = None\n"
     ]
    }
   ],
   "source": [
    "## max CV mean among the classifier\n",
    "classifier_acc_mean_max = np.max(list(classifier_acc_mean.values()))\n",
    "print(\"max CV score mean= \" + str(classifier_acc_mean_max))\n",
    "\n",
    "key_cv_max = list(classifier_acc_mean.keys())[list(classifier_acc_mean.values()).index(classifier_acc_mean_max)]\n",
    "clf_spec(key_cv_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "#### 3.2.2 CV scores vs. the score generated by the overall training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the average of the CV scores to the score generated by the overall\n",
    "training set. Which combination overfits the most? The least?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer**:   \n",
    "> We calculate the difference between the average CV and the overal accuracy scores. The biggest difference would be the most overfitted model and the smallest difference would be the least overfitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1 =  8.7 secs\n",
      "iteration 2 =  8.6 secs\n",
      "iteration 3 =  8.9 secs\n",
      "iteration 4 = 13.1 secs\n",
      "iteration 5 = 13.1 secs\n",
      "iteration 6 = 11.4 secs\n",
      "iteration 7 =  8.2 secs\n",
      "iteration 8 = 12.9 secs\n",
      "iteration 9 = 10.7 secs\n",
      "iteration 10 = 10.0 secs\n",
      "iteration 11 = 12.6 secs\n",
      "iteration 12 = 12.5 secs\n",
      "iteration 13 = 11.1 secs\n",
      "iteration 14 =  9.7 secs\n",
      "iteration 15 =  9.6 secs\n",
      "iteration 16 =  8.8 secs\n",
      "iteration 17 =  8.4 secs\n",
      "iteration 18 = 10.1 secs\n"
     ]
    }
   ],
   "source": [
    "classifier_acc_overall = {}\n",
    "\n",
    "for i in range(0,len(classifier_name_list)):\n",
    "    time_start = time.perf_counter()\n",
    "    \n",
    "    classifier = globals()[classifier_name_list[i]]\n",
    "    classifier.fit(X_train_10k, y_train_10k_lb)\n",
    "    temp_acc_overall = classifier.score(X_train_10k, y_train_10k_lb)\n",
    "    classifier_acc_overall[classifier_name_list[i]] = temp_acc_overall\n",
    "\n",
    "    time_elapsed = (time.perf_counter() - time_start)\n",
    "    print (\"iteration\", i+1, \"=%5.1f secs\" % time_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall accuracy of the classifiers:\n",
      "\n",
      "svm_poly3_None_C001 = 0.64175\n",
      "svm_poly5_None_C001 = 0.64462\n",
      "svm_poly7_None_C001 = 0.64938\n",
      "svm_poly3_balanced_C001 = 0.38512\n",
      "svm_poly5_balanced_C001 = 0.41925\n",
      "svm_poly7_balanced_C001 = 0.43262\n",
      "svm_poly3_None_C1 = 0.77762\n",
      "svm_poly5_None_C1 = 0.74412\n",
      "svm_poly7_None_C1 = 0.71462\n",
      "svm_poly3_balanced_C1 = 0.77025\n",
      "svm_poly5_balanced_C1 = 0.66212\n",
      "svm_poly7_balanced_C1 = 0.60788\n",
      "svm_poly3_None_C100 = 0.872\n",
      "svm_poly5_None_C100 = 0.874\n",
      "svm_poly7_None_C100 = 0.83938\n",
      "svm_poly3_balanced_C100 = 0.861\n",
      "svm_poly5_balanced_C100 = 0.87012\n",
      "svm_poly7_balanced_C100 = 0.77938\n"
     ]
    }
   ],
   "source": [
    "## overall accuracy of the folds\n",
    "for i, key in enumerate(classifier_acc_overall.keys()):\n",
    "    if i == 0:\n",
    "        print(\"overall accuracy of the classifiers:\\n\")        \n",
    "    print(str(key) + \" = \" + str(classifier_acc_overall[key].round(5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV dif = 0.0, svm_poly3_None_C001\n",
      "CV dif = 0.00125, svm_poly5_None_C001\n",
      "CV dif = 0.00475, svm_poly7_None_C001\n",
      "CV dif = 0.0035, svm_poly3_balanced_C001\n",
      "CV dif = 0.00225, svm_poly5_balanced_C001\n",
      "CV dif = 0.0055, svm_poly7_balanced_C001\n",
      "CV dif = 0.01588, svm_poly3_None_C1\n",
      "CV dif = 0.02137, svm_poly5_None_C1\n",
      "CV dif = 0.026, svm_poly7_None_C1\n",
      "CV dif = 0.03412, svm_poly3_balanced_C1\n",
      "CV dif = 0.02537, svm_poly5_balanced_C1\n",
      "CV dif = 0.03238, svm_poly7_balanced_C1\n",
      "CV dif = 0.05363, svm_poly3_None_C100\n",
      "CV dif = 0.067, svm_poly5_None_C100\n",
      "CV dif = 0.06137, svm_poly7_None_C100\n",
      "CV dif = 0.0555, svm_poly3_balanced_C100\n",
      "CV dif = 0.069, svm_poly5_balanced_C100\n",
      "CV dif = 0.0645, svm_poly7_balanced_C100\n"
     ]
    }
   ],
   "source": [
    "## difference between the overall accuracy and the average CV accuracy\n",
    "classifier_acc_dif = {}\n",
    "for k in classifier_acc_overall.keys():\n",
    "    classifier_acc_dif[k] = classifier_acc_overall[k] - classifier_acc_mean[k]\n",
    "    \n",
    "classifier_acc_dif_values = np.reshape(list(classifier_acc_dif.values()), len(classifier_acc_dif.values()), 1)\n",
    "for i,clf in enumerate(classifier_acc_overall.keys()):\n",
    "    print(\"CV dif = \" + str(classifier_acc_dif_values[i].round(5)) + \", \" + str(clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min CV difference= 0.0\n",
      "\n",
      "classifier name = svm_poly3_None_C001\n",
      "              C = 0.001\n",
      "         degree = 3\n",
      "  class_weights = None\n"
     ]
    }
   ],
   "source": [
    "clf_cv_dif_min_value = classifier_acc_dif_values.min()\n",
    "print(\"min CV difference= \" + str(clf_cv_dif_min_value.round(5)))\n",
    "\n",
    "key_cv_dif_min = list(classifier_acc_dif.keys())[list(classifier_acc_dif.values()).index(clf_cv_dif_min_value)]\n",
    "clf_spec(key_cv_dif_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max CV difference= 0.069\n",
      "\n",
      "classifier name = svm_poly5_balanced_C100\n",
      "              C = 100\n",
      "         degree = 5\n",
      "  class_weights = balanced\n"
     ]
    }
   ],
   "source": [
    "clf_cv_dif_max_value = classifier_acc_dif_values.max()\n",
    "print(\"max CV difference= \" + str(clf_cv_dif_max_value.round(5)))\n",
    "\n",
    "key_cv_dif_max = list(classifier_acc_dif.keys())[list(classifier_acc_dif.values()).index(clf_cv_dif_max_value)]\n",
    "clf_spec(key_cv_dif_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "#### 3.2.3 The classifier that correctly classifies as many spruce/fir samples as possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wanted a classifier that prioritized correctly classifying as many\n",
    "spruce/fir samples as possible without concern for misclassifying other\n",
    "types as spruce/fir, which combination is the best?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer**:   \n",
    "> Correctly classifying as many spruce/fir samples as possible without concern for misclassifying other types as spruce/fir means having the highest percision possible. So, we pick the one with the highest recall regradless of recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1 =  7.8 secs\n",
      "iteration 2 =  7.7 secs\n",
      "iteration 3 =  8.8 secs\n",
      "iteration 4 = 11.6 secs\n",
      "iteration 5 = 12.0 secs\n",
      "iteration 6 = 11.5 secs\n",
      "iteration 7 =  6.7 secs\n",
      "iteration 8 =  8.1 secs\n",
      "iteration 9 =  8.2 secs\n",
      "iteration 10 =  7.5 secs\n",
      "iteration 11 =  8.3 secs\n",
      "iteration 12 =  9.6 secs\n",
      "iteration 13 =  8.9 secs\n",
      "iteration 14 =  9.2 secs\n",
      "iteration 15 = 14.2 secs\n",
      "iteration 16 =  8.6 secs\n",
      "iteration 17 =  8.3 secs\n",
      "iteration 18 = 10.4 secs\n"
     ]
    }
   ],
   "source": [
    "classifier_precision = {}\n",
    "classifier_recall = {}\n",
    "\n",
    "for i in range(0,len(classifier_name_list)):\n",
    "    time_start = time.perf_counter()\n",
    "    \n",
    "    classifier = globals()[classifier_name_list[i]]\n",
    "    classifier.fit(X_train_10k, y_train_10k_lb)\n",
    "    svm_clf_10k_train_pred = classifier.predict(X_train_10k)\n",
    "    classifier_precision[classifier_name_list[i]] = precision_score(y_train_10k_lb, svm_clf_10k_train_pred)\n",
    "    classifier_recall[classifier_name_list[i]] = recall_score(y_train_10k_lb, svm_clf_10k_train_pred)\n",
    "\n",
    "    time_elapsed = (time.perf_counter() - time_start)\n",
    "    print (\"iteration\", i+1, \"=%5.1f secs\" % time_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percision scores of the classifiers:\n",
      "\n",
      "percision = 0.93333, svm_poly3_None_C001\n",
      "percision = 0.8913, svm_poly5_None_C001\n",
      "percision = 0.89362, svm_poly7_None_C001\n",
      "percision = 0.369, svm_poly3_balanced_C001\n",
      "percision = 0.38187, svm_poly5_balanced_C001\n",
      "percision = 0.38787, svm_poly7_balanced_C001\n",
      "percision = 0.75253, svm_poly3_None_C1\n",
      "percision = 0.81325, svm_poly5_None_C1\n",
      "percision = 0.87157, svm_poly7_None_C1\n",
      "percision = 0.63187, svm_poly3_balanced_C1\n",
      "percision = 0.51679, svm_poly5_balanced_C1\n",
      "percision = 0.47801, svm_poly7_balanced_C1\n",
      "percision = 0.84725, svm_poly3_None_C100\n",
      "percision = 0.88293, svm_poly5_None_C100\n",
      "percision = 0.90498, svm_poly7_None_C100\n",
      "percision = 0.7635, svm_poly3_balanced_C100\n",
      "percision = 0.78032, svm_poly5_balanced_C100\n",
      "percision = 0.62717, svm_poly7_balanced_C100\n"
     ]
    }
   ],
   "source": [
    "## percision scores of the classifiers\n",
    "print(\"percision scores of the classifiers:\\n\")\n",
    "\n",
    "for clf in classifier_precision.keys():\n",
    "    print(\"percision = \" + str(classifier_precision[clf].round(5)) + \", \" + str(clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max precision score = 0.93333\n",
      "\n",
      "classifier name = svm_poly3_None_C001\n",
      "              C = 0.001\n",
      "         degree = 3\n",
      "  class_weights = None\n"
     ]
    }
   ],
   "source": [
    "## maximum precision score classifier\n",
    "classifier_precision_values = np.reshape(list(classifier_precision.values()), len(classifier_precision.values()), 1)\n",
    "classifier_precision_max_value = classifier_precision_values.max()\n",
    "print(\"max precision score = \" + str(classifier_precision_max_value.round(5)))\n",
    "\n",
    "key_precision_max_value = list(classifier_precision.keys())[list(classifier_precision.values()).index(classifier_precision_max_value)]\n",
    "clf_spec(key_precision_max_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "#### 3.2.4 Making sure other cover types are not classified as spruce/fir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wanted a classifier that prioritized making sure other cover types\n",
    "are not classified as spruce/fir even if it means misclassifying spruce/\f",
    "r\n",
    "types incorrectly, which combination is the best?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer**:   \n",
    "> Making sure other cover types are not classified as spruce/fir even if misclassifying spruce/fir\n",
    "types incorrectly implies having the highest recall (or the minimum false negatives) possible. So, we pick the one with the highest recall score regradless of recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall scores of the classifiers:\n",
      "\n",
      "recall = 0.00486, svm_poly3_None_C001\n",
      "recall = 0.01424, svm_poly5_None_C001\n",
      "recall = 0.02918, svm_poly7_None_C001\n",
      "recall = 0.99792, svm_poly3_balanced_C001\n",
      "recall = 0.99201, svm_poly5_balanced_C001\n",
      "recall = 0.99722, svm_poly7_balanced_C001\n",
      "recall = 0.56929, svm_poly3_None_C1\n",
      "recall = 0.37513, svm_poly5_None_C1\n",
      "recall = 0.24279, svm_poly7_None_C1\n",
      "recall = 0.86627, svm_poly3_balanced_C1\n",
      "recall = 0.94095, svm_poly5_balanced_C1\n",
      "recall = 0.97395, svm_poly7_balanced_C1\n",
      "recall = 0.78604, svm_poly3_None_C100\n",
      "recall = 0.74922, svm_poly5_None_C100\n",
      "recall = 0.61862, svm_poly7_None_C100\n",
      "recall = 0.8892, svm_poly3_balanced_C100\n",
      "recall = 0.88954, svm_poly5_balanced_C100\n",
      "recall = 0.95415, svm_poly7_balanced_C100\n"
     ]
    }
   ],
   "source": [
    "## recall scores of the classifiers\n",
    "print(\"recall scores of the classifiers:\\n\")\n",
    "\n",
    "for clf in classifier_recall.keys():\n",
    "    print(\"recall = \" + str(classifier_recall[clf].round(5)) + \", \" + str(clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max recall score = 0.99792\n",
      "\n",
      "classifier name = svm_poly3_balanced_C001\n",
      "              C = 0.001\n",
      "         degree = 3\n",
      "  class_weights = balanced\n"
     ]
    }
   ],
   "source": [
    "## maximum recall classifier\n",
    "classifier_recall_values = np.reshape(list(classifier_recall.values()), len(classifier_recall.values()), 1)\n",
    "classifier_recall_max_value = classifier_recall_values.max()\n",
    "print(\"max recall score = \" + str(classifier_recall_max_value.round(5)))\n",
    "\n",
    "key_recall_max_value = list(classifier_recall.keys())[list(classifier_recall.values()).index(classifier_recall_max_value)]\n",
    "clf_spec(key_recall_max_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "#### 3.2.5 Accuracy score for each combination of options on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the accuracy score for each combination of options on the test set.\n",
    "Which combination actually worked the best on the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1 =  0.7 secs\n",
      "iteration 2 =  0.8 secs\n",
      "iteration 3 =  0.9 secs\n",
      "iteration 4 =  1.1 secs\n",
      "iteration 5 =  1.0 secs\n",
      "iteration 6 =  1.1 secs\n",
      "iteration 7 =  0.8 secs\n",
      "iteration 8 =  0.8 secs\n",
      "iteration 9 =  0.7 secs\n",
      "iteration 10 =  0.7 secs\n",
      "iteration 11 =  0.9 secs\n",
      "iteration 12 =  0.8 secs\n",
      "iteration 13 =  0.4 secs\n",
      "iteration 14 =  0.5 secs\n",
      "iteration 15 =  0.6 secs\n",
      "iteration 16 =  0.5 secs\n",
      "iteration 17 =  0.6 secs\n",
      "iteration 18 =  0.6 secs\n"
     ]
    }
   ],
   "source": [
    "classifier_test_acc = {}\n",
    "\n",
    "for i in range(0,len(classifier_name_list)):\n",
    "    time_start = time.perf_counter()\n",
    "    \n",
    "    classifier = globals()[classifier_name_list[i]]\n",
    "    classifier_test_acc[classifier_name_list[i]] = classifier.score(X_test_10k, y_test_10k_lb)\n",
    "    \n",
    "    time_elapsed = (time.perf_counter() - time_start)\n",
    "    print (\"iteration\", i+1, \"=%5.1f secs\" % time_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy scores of the classifiers on the test set:\n",
      "\n",
      "accuracy = 0.6265, svm_poly3_None_C001\n",
      "accuracy = 0.6285, svm_poly5_None_C001\n",
      "accuracy = 0.6295, svm_poly7_None_C001\n",
      "accuracy = 0.395, svm_poly3_balanced_C001\n",
      "accuracy = 0.426, svm_poly5_balanced_C001\n",
      "accuracy = 0.437, svm_poly7_balanced_C001\n",
      "accuracy = 0.7535, svm_poly3_None_C1\n",
      "accuracy = 0.7155, svm_poly5_None_C1\n",
      "accuracy = 0.681, svm_poly7_None_C1\n",
      "accuracy = 0.7515, svm_poly3_balanced_C1\n",
      "accuracy = 0.634, svm_poly5_balanced_C1\n",
      "accuracy = 0.583, svm_poly7_balanced_C1\n",
      "accuracy = 0.8285, svm_poly3_None_C100\n",
      "accuracy = 0.819, svm_poly5_None_C100\n",
      "accuracy = 0.7875, svm_poly7_None_C100\n",
      "accuracy = 0.8125, svm_poly3_balanced_C100\n",
      "accuracy = 0.8055, svm_poly5_balanced_C100\n",
      "accuracy = 0.736, svm_poly7_balanced_C100\n"
     ]
    }
   ],
   "source": [
    "## accuracy scores of the classifiers on the test set\n",
    "print(\"accuracy scores of the classifiers on the test set:\\n\")\n",
    "\n",
    "for clf in classifier_test_acc.keys():\n",
    "    print(\"accuracy = \" + str(classifier_test_acc[clf].round(5)) + \", \" + str(clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max accuracy score = 0.8285\n",
      "\n",
      "classifier name = svm_poly3_None_C100\n",
      "              C = 100\n",
      "         degree = 3\n",
      "  class_weights = None\n"
     ]
    }
   ],
   "source": [
    "## maximum accuracy classifier\n",
    "classifier_test_acc_values = np.reshape(list(classifier_test_acc.values()), len(classifier_test_acc.values()), 1)\n",
    "classifier_test_acc_max_value = classifier_test_acc_values.max()\n",
    "print(\"max accuracy score = \" + str(classifier_test_acc_max_value.round(5)))\n",
    "\n",
    "key_acc_max_value = list(classifier_test_acc.keys())[list(classifier_test_acc.values()).index(classifier_test_acc_max_value)]\n",
    "clf_spec(key_acc_max_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "#### 3.2.6 Overall effect of increasing C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What was the overall effect of increasing C?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer**:   \n",
    "> We take the standard case of `polyDeg = 3` and `class_weight=None` to study the effect of `C` using our classifiers and the evaluation of their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## helper function\n",
    "def clf_eval(classifier_name_list, criteria):\n",
    "    '''\n",
    "    returns the accuracy criteria measure before\n",
    "    for the list of the names of the classifiers provided.\n",
    "    '''\n",
    "    assert criteria in [\"C\", \"degree\", \"class_weight\"], '>>> InputError: criteria NOT in [\"C\", \"degree\", \"class_weight\"]! <<<\\n'\n",
    "    \n",
    "    for i in range(0, len(classifier_name_list)):\n",
    "        clf_acc = classifier_acc[classifier_name_list[i]]\n",
    "        clf_acc_mean = classifier_acc_mean[classifier_name_list[i]]\n",
    "        clf_acc_overall = classifier_acc_overall[classifier_name_list[i]]\n",
    "        clf_precision = classifier_precision[classifier_name_list[i]]\n",
    "        clf_recall = classifier_recall[classifier_name_list[i]]\n",
    "        clf_test_acc = classifier_test_acc[classifier_name_list[i]]\n",
    "        \n",
    "        [type, degree, class_weights, C] = classifier_name_list[i].split(\"_\")\n",
    "        if C == \"C001\":\n",
    "            C = \"C0.001\"\n",
    "        \n",
    "        if criteria == \"C\":\n",
    "            print(\"clf_CV_mean = \" + str(clf_acc_mean.round(3)) + \", \" +\n",
    "                 \"clf_acc_overall = \" + str(clf_acc_overall.round(3)) + \", \" +\n",
    "                 \"clf_precision = \" + str(clf_precision.round(3)) + \", \" +\n",
    "                 \"clf_recall = \" + str(clf_recall.round(3)) + \", \" +\n",
    "                 \"clf_test_acc = \" + str(clf_test_acc.round(3)) + \"   |C = \" + C[1:])\n",
    "            \n",
    "        elif criteria == \"degree\":\n",
    "            print(\"clf_CV_mean = \" + str(clf_acc_mean.round(3)) + \", \" +\n",
    "                 \"clf_acc_overall = \" + str(clf_acc_overall.round(3)) + \", \" +\n",
    "                 \"clf_precision = \" + str(clf_precision.round(3)) + \", \" +\n",
    "                 \"clf_recall = \" + str(clf_recall.round(3)) + \", \" +\n",
    "                 \"clf_test_acc = \" + str(clf_test_acc.round(3)) + \"   |degree = \" + degree[4:])\n",
    "        else:\n",
    "            print(\"clf_CV_mean = \" + str(clf_acc_mean.round(3)) + \", \" +\n",
    "                 \"clf_acc_overall = \" + str(clf_acc_overall.round(3)) + \", \" +\n",
    "                 \"clf_precision = \" + str(clf_precision.round(3)) + \", \" +\n",
    "                 \"clf_recall = \" + str(clf_recall.round(3)) + \", \" +\n",
    "                 \"clf_test_acc = \" + str(clf_test_acc.round(3)) + \"|weight = \" + class_weights)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf_CV_mean = 0.642, clf_acc_overall = 0.642, clf_precision = 0.933, clf_recall = 0.005, clf_test_acc = 0.626   |C = 0.001\n",
      "clf_CV_mean = 0.762, clf_acc_overall = 0.778, clf_precision = 0.753, clf_recall = 0.569, clf_test_acc = 0.754   |C = 1\n",
      "clf_CV_mean = 0.818, clf_acc_overall = 0.872, clf_precision = 0.847, clf_recall = 0.786, clf_test_acc = 0.828   |C = 100\n"
     ]
    }
   ],
   "source": [
    "classifier_compar_C = [\"svm_poly3_None_C001\",\n",
    "                       \"svm_poly3_None_C1\",\n",
    "                       \"svm_poly3_None_C100\"]\n",
    "\n",
    "clf_eval(classifier_compar_C, \"C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer**:   \n",
    "> `C` is the penalization parameter that controls the tradeoff between smoothness of the boundary curve and the number of correct classification of points. Increasing `C` may lead to overfitting.   \n",
    "As we can see from the printout above, accuracy scores (clf_CV_mean, clf_acc_overall, clf_test_acc) as well as clf_recall increase as `C` increases but clf_precision decreases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "#### 3.2.7 Overall effect of increasing the polynomial degree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What was the overall effect of increasing the polynomial degree?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer**:   \n",
    "> We take the standard case of `C = 1` and `class_weight=None` to study the effect of `polyDeg` using our classifiers and the evaluation of their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf_CV_mean = 0.762, clf_acc_overall = 0.778, clf_precision = 0.753, clf_recall = 0.569, clf_test_acc = 0.754   |degree = 3\n",
      "clf_CV_mean = 0.723, clf_acc_overall = 0.744, clf_precision = 0.813, clf_recall = 0.375, clf_test_acc = 0.716   |degree = 5\n",
      "clf_CV_mean = 0.689, clf_acc_overall = 0.715, clf_precision = 0.872, clf_recall = 0.243, clf_test_acc = 0.681   |degree = 7\n"
     ]
    }
   ],
   "source": [
    "classifier_compar_deg = [\"svm_poly3_None_C1\",\n",
    "                         \"svm_poly5_None_C1\",\n",
    "                         \"svm_poly7_None_C1\"]\n",
    "\n",
    "clf_eval(classifier_compar_deg, \"degree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer**:   \n",
    "> Using `degree=1` is the same as using a linear kernel. Increasing this parameters increases the complexity of the model and consequently the training time. Increasing the degree of the polynomial does not necessarily lead to overfitting but rather makes the shape of the boundaries more complicated and the computation more time consuming.   \n",
    "As we can see from the printout above, accuracy scores (clf_CV_mean, clf_acc_overall, clf_test_acc) and also clf_recall decrease as `polyDeg` goes up but clf_precision increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "#### 3.2.8 Assigning balanced weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning balanced weights is meant to mitigate the effect of larger label\n",
    "counts skewing the SVM result. Does it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer**:   \n",
    "> We take the standard case of `C = 1` and `polyDeg = 3` to study the effect of `class_weight` using our classifiers and the evaluation of their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf_CV_mean = 0.762, clf_acc_overall = 0.778, clf_precision = 0.753, clf_recall = 0.569, clf_test_acc = 0.754|weight = None\n",
      "clf_CV_mean = 0.736, clf_acc_overall = 0.77, clf_precision = 0.632, clf_recall = 0.866, clf_test_acc = 0.752|weight = balanced\n"
     ]
    }
   ],
   "source": [
    "classifier_compar_classWeight = [\"svm_poly3_None_C1\",\n",
    "                                 \"svm_poly3_balanced_C1\"]\n",
    "\n",
    "clf_eval(classifier_compar_classWeight, \"class_weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf_CV_mean = 0.723, clf_acc_overall = 0.744, clf_precision = 0.813, clf_recall = 0.375, clf_test_acc = 0.716|weight = None\n",
      "clf_CV_mean = 0.637, clf_acc_overall = 0.662, clf_precision = 0.517, clf_recall = 0.941, clf_test_acc = 0.634|weight = balanced\n"
     ]
    }
   ],
   "source": [
    "classifier_compar_classWeight = [\"svm_poly5_None_C1\",\n",
    "                                 \"svm_poly5_balanced_C1\"]\n",
    "\n",
    "clf_eval(classifier_compar_classWeight, \"class_weight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer**:   \n",
    ">`C` get multiplied by `class_weight` to change the magnitude of penalization. As we can see from the printouts above, accuracy scores (clf_CV_mean, clf_acc_overall) and also clf_precision decrease when `class_weight = balanced`. In other words, the classifier works more in favor of increasing recall and somehow helps mitigate the effect of larger label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### 3.3 Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did the CV scores you encountered give you confidence that the polynomial\n",
    "kernal SVM would be an improvement over the \"NOT spruce/fir\" classifier? What\n",
    "would you try to do differently to find a better SVM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max ave-CV accuracy of classifiers = 0.818375\n",
      "min ave-CV accuracy of classifiers = 0.381625\n",
      "\n",
      "mean ave-CV accuracy of classifiers = 0.66677\n",
      ">>>  ave_CV accuracy of never_1_clf = 0.64013\n"
     ]
    }
   ],
   "source": [
    "classifier_acc_mean_values = list(classifier_acc_mean.values())\n",
    "print(\"max ave-CV accuracy of classifiers = \" + str(np.max(classifier_acc_mean_values)))\n",
    "print(\"min ave-CV accuracy of classifiers = \" + str(np.min(classifier_acc_mean_values)))\n",
    "print(\"\\nmean ave-CV accuracy of classifiers = \" + str(np.mean(classifier_acc_mean_values).round(5)))\n",
    "\n",
    "## never-1-calssifier defined in Problem 1\n",
    "never_1_clf_10k_acc = cross_val_score(never_1_clf_10k, X_train_10k, y_train_10k_lb, scoring=\"accuracy\")\n",
    "print(\">>>  ave_CV accuracy of never_1_clf = \" + str(np.mean(never_1_clf_10k_acc).round(5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer**:   \n",
    ">As we can see, the average accuracy of CV for the 18 classifiers created earlier is almost the same as `never-1-clf` and it deos not provide any *significant* advantage over the `never-1-clf` even though for some of them the CV accuracy reached around 80%.  \n",
    "We can try tuning other parameters such as `gamma` and try other kernels to see if we get better results using `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[CV] C=0.001, class_weight=balanced, gamma=1, kernel=rbf .............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.001, class_weight=balanced, gamma=1, kernel=rbf, score=0.641, total=   9.1s\n",
      "[CV] C=0.001, class_weight=balanced, gamma=1, kernel=rbf .............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    9.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.001, class_weight=balanced, gamma=1, kernel=rbf, score=0.640, total=   8.2s\n",
      "[CV] C=0.001, class_weight=balanced, gamma=1, kernel=rbf .............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   17.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.001, class_weight=balanced, gamma=1, kernel=rbf, score=0.640, total=   8.3s\n",
      "[CV] C=0.001, class_weight=balanced, gamma=1, kernel=rbf .............\n",
      "[CV]  C=0.001, class_weight=balanced, gamma=1, kernel=rbf, score=0.640, total=   9.1s\n",
      "[CV] C=0.001, class_weight=balanced, gamma=1, kernel=rbf .............\n",
      "[CV]  C=0.001, class_weight=balanced, gamma=1, kernel=rbf, score=0.640, total=   9.5s\n",
      "[CV] C=0.001, class_weight=balanced, gamma=0.01, kernel=rbf ..........\n",
      "[CV]  C=0.001, class_weight=balanced, gamma=0.01, kernel=rbf, score=0.641, total=   9.2s\n",
      "[CV] C=0.001, class_weight=balanced, gamma=0.01, kernel=rbf ..........\n",
      "[CV]  C=0.001, class_weight=balanced, gamma=0.01, kernel=rbf, score=0.640, total=   8.2s\n",
      "[CV] C=0.001, class_weight=balanced, gamma=0.01, kernel=rbf ..........\n",
      "[CV]  C=0.001, class_weight=balanced, gamma=0.01, kernel=rbf, score=0.640, total=   8.3s\n",
      "[CV] C=0.001, class_weight=balanced, gamma=0.01, kernel=rbf ..........\n",
      "[CV]  C=0.001, class_weight=balanced, gamma=0.01, kernel=rbf, score=0.640, total=   8.0s\n",
      "[CV] C=0.001, class_weight=balanced, gamma=0.01, kernel=rbf ..........\n",
      "[CV]  C=0.001, class_weight=balanced, gamma=0.01, kernel=rbf, score=0.640, total=   8.0s\n",
      "[CV] C=0.001, class_weight=balanced, gamma=0.0001, kernel=rbf ........\n",
      "[CV]  C=0.001, class_weight=balanced, gamma=0.0001, kernel=rbf, score=0.641, total=   7.1s\n",
      "[CV] C=0.001, class_weight=balanced, gamma=0.0001, kernel=rbf ........\n",
      "[CV]  C=0.001, class_weight=balanced, gamma=0.0001, kernel=rbf, score=0.640, total=   7.1s\n",
      "[CV] C=0.001, class_weight=balanced, gamma=0.0001, kernel=rbf ........\n",
      "[CV]  C=0.001, class_weight=balanced, gamma=0.0001, kernel=rbf, score=0.640, total=   7.8s\n",
      "[CV] C=0.001, class_weight=balanced, gamma=0.0001, kernel=rbf ........\n",
      "[CV]  C=0.001, class_weight=balanced, gamma=0.0001, kernel=rbf, score=0.640, total=   9.3s\n",
      "[CV] C=0.001, class_weight=balanced, gamma=0.0001, kernel=rbf ........\n",
      "[CV]  C=0.001, class_weight=balanced, gamma=0.0001, kernel=rbf, score=0.640, total=   8.2s\n",
      "[CV] C=0.001, class_weight=None, gamma=1, kernel=rbf .................\n",
      "[CV]  C=0.001, class_weight=None, gamma=1, kernel=rbf, score=0.641, total=   7.4s\n",
      "[CV] C=0.001, class_weight=None, gamma=1, kernel=rbf .................\n",
      "[CV]  C=0.001, class_weight=None, gamma=1, kernel=rbf, score=0.640, total=   7.7s\n",
      "[CV] C=0.001, class_weight=None, gamma=1, kernel=rbf .................\n",
      "[CV]  C=0.001, class_weight=None, gamma=1, kernel=rbf, score=0.640, total=   7.5s\n",
      "[CV] C=0.001, class_weight=None, gamma=1, kernel=rbf .................\n",
      "[CV]  C=0.001, class_weight=None, gamma=1, kernel=rbf, score=0.640, total=   8.1s\n",
      "[CV] C=0.001, class_weight=None, gamma=1, kernel=rbf .................\n",
      "[CV]  C=0.001, class_weight=None, gamma=1, kernel=rbf, score=0.640, total=   7.6s\n",
      "[CV] C=0.001, class_weight=None, gamma=0.01, kernel=rbf ..............\n",
      "[CV]  C=0.001, class_weight=None, gamma=0.01, kernel=rbf, score=0.641, total=   8.4s\n",
      "[CV] C=0.001, class_weight=None, gamma=0.01, kernel=rbf ..............\n",
      "[CV]  C=0.001, class_weight=None, gamma=0.01, kernel=rbf, score=0.640, total=  10.0s\n",
      "[CV] C=0.001, class_weight=None, gamma=0.01, kernel=rbf ..............\n",
      "[CV]  C=0.001, class_weight=None, gamma=0.01, kernel=rbf, score=0.640, total=   8.0s\n",
      "[CV] C=0.001, class_weight=None, gamma=0.01, kernel=rbf ..............\n",
      "[CV]  C=0.001, class_weight=None, gamma=0.01, kernel=rbf, score=0.640, total=   9.5s\n",
      "[CV] C=0.001, class_weight=None, gamma=0.01, kernel=rbf ..............\n",
      "[CV]  C=0.001, class_weight=None, gamma=0.01, kernel=rbf, score=0.640, total=   7.5s\n",
      "[CV] C=0.001, class_weight=None, gamma=0.0001, kernel=rbf ............\n",
      "[CV]  C=0.001, class_weight=None, gamma=0.0001, kernel=rbf, score=0.641, total=   4.7s\n",
      "[CV] C=0.001, class_weight=None, gamma=0.0001, kernel=rbf ............\n",
      "[CV]  C=0.001, class_weight=None, gamma=0.0001, kernel=rbf, score=0.640, total=   4.7s\n",
      "[CV] C=0.001, class_weight=None, gamma=0.0001, kernel=rbf ............\n",
      "[CV]  C=0.001, class_weight=None, gamma=0.0001, kernel=rbf, score=0.640, total=   4.8s\n",
      "[CV] C=0.001, class_weight=None, gamma=0.0001, kernel=rbf ............\n",
      "[CV]  C=0.001, class_weight=None, gamma=0.0001, kernel=rbf, score=0.640, total=   5.1s\n",
      "[CV] C=0.001, class_weight=None, gamma=0.0001, kernel=rbf ............\n",
      "[CV]  C=0.001, class_weight=None, gamma=0.0001, kernel=rbf, score=0.640, total=   4.7s\n",
      "[CV] C=1, class_weight=balanced, gamma=1, kernel=rbf .................\n",
      "[CV]  C=1, class_weight=balanced, gamma=1, kernel=rbf, score=0.641, total=   8.3s\n",
      "[CV] C=1, class_weight=balanced, gamma=1, kernel=rbf .................\n",
      "[CV]  C=1, class_weight=balanced, gamma=1, kernel=rbf, score=0.640, total=   9.1s\n",
      "[CV] C=1, class_weight=balanced, gamma=1, kernel=rbf .................\n",
      "[CV]  C=1, class_weight=balanced, gamma=1, kernel=rbf, score=0.640, total=   8.7s\n",
      "[CV] C=1, class_weight=balanced, gamma=1, kernel=rbf .................\n",
      "[CV]  C=1, class_weight=balanced, gamma=1, kernel=rbf, score=0.640, total=   8.3s\n",
      "[CV] C=1, class_weight=balanced, gamma=1, kernel=rbf .................\n",
      "[CV]  C=1, class_weight=balanced, gamma=1, kernel=rbf, score=0.640, total=   9.2s\n",
      "[CV] C=1, class_weight=balanced, gamma=0.01, kernel=rbf ..............\n",
      "[CV]  C=1, class_weight=balanced, gamma=0.01, kernel=rbf, score=0.641, total=  11.3s\n",
      "[CV] C=1, class_weight=balanced, gamma=0.01, kernel=rbf ..............\n",
      "[CV]  C=1, class_weight=balanced, gamma=0.01, kernel=rbf, score=0.640, total=  12.4s\n",
      "[CV] C=1, class_weight=balanced, gamma=0.01, kernel=rbf ..............\n",
      "[CV]  C=1, class_weight=balanced, gamma=0.01, kernel=rbf, score=0.640, total=  12.6s\n",
      "[CV] C=1, class_weight=balanced, gamma=0.01, kernel=rbf ..............\n",
      "[CV]  C=1, class_weight=balanced, gamma=0.01, kernel=rbf, score=0.640, total=  10.1s\n",
      "[CV] C=1, class_weight=balanced, gamma=0.01, kernel=rbf ..............\n",
      "[CV]  C=1, class_weight=balanced, gamma=0.01, kernel=rbf, score=0.640, total=  10.3s\n",
      "[CV] C=1, class_weight=balanced, gamma=0.0001, kernel=rbf ............\n",
      "[CV]  C=1, class_weight=balanced, gamma=0.0001, kernel=rbf, score=0.751, total=   7.4s\n",
      "[CV] C=1, class_weight=balanced, gamma=0.0001, kernel=rbf ............\n",
      "[CV]  C=1, class_weight=balanced, gamma=0.0001, kernel=rbf, score=0.741, total=   7.8s\n",
      "[CV] C=1, class_weight=balanced, gamma=0.0001, kernel=rbf ............\n",
      "[CV]  C=1, class_weight=balanced, gamma=0.0001, kernel=rbf, score=0.736, total=   8.0s\n",
      "[CV] C=1, class_weight=balanced, gamma=0.0001, kernel=rbf ............\n",
      "[CV]  C=1, class_weight=balanced, gamma=0.0001, kernel=rbf, score=0.747, total=  10.3s\n",
      "[CV] C=1, class_weight=balanced, gamma=0.0001, kernel=rbf ............\n",
      "[CV]  C=1, class_weight=balanced, gamma=0.0001, kernel=rbf, score=0.750, total=   9.9s\n",
      "[CV] C=1, class_weight=None, gamma=1, kernel=rbf .....................\n",
      "[CV]  C=1, class_weight=None, gamma=1, kernel=rbf, score=0.641, total=  13.4s\n",
      "[CV] C=1, class_weight=None, gamma=1, kernel=rbf .....................\n",
      "[CV]  C=1, class_weight=None, gamma=1, kernel=rbf, score=0.640, total=   9.2s\n",
      "[CV] C=1, class_weight=None, gamma=1, kernel=rbf .....................\n",
      "[CV]  C=1, class_weight=None, gamma=1, kernel=rbf, score=0.640, total=   8.2s\n",
      "[CV] C=1, class_weight=None, gamma=1, kernel=rbf .....................\n",
      "[CV]  C=1, class_weight=None, gamma=1, kernel=rbf, score=0.640, total=  11.9s\n",
      "[CV] C=1, class_weight=None, gamma=1, kernel=rbf .....................\n",
      "[CV]  C=1, class_weight=None, gamma=1, kernel=rbf, score=0.640, total=   9.2s\n",
      "[CV] C=1, class_weight=None, gamma=0.01, kernel=rbf ..................\n",
      "[CV]  C=1, class_weight=None, gamma=0.01, kernel=rbf, score=0.641, total=  10.6s\n",
      "[CV] C=1, class_weight=None, gamma=0.01, kernel=rbf ..................\n",
      "[CV]  C=1, class_weight=None, gamma=0.01, kernel=rbf, score=0.640, total=   9.4s\n",
      "[CV] C=1, class_weight=None, gamma=0.01, kernel=rbf ..................\n",
      "[CV]  C=1, class_weight=None, gamma=0.01, kernel=rbf, score=0.640, total=  10.8s\n",
      "[CV] C=1, class_weight=None, gamma=0.01, kernel=rbf ..................\n",
      "[CV]  C=1, class_weight=None, gamma=0.01, kernel=rbf, score=0.640, total=  11.3s\n",
      "[CV] C=1, class_weight=None, gamma=0.01, kernel=rbf ..................\n",
      "[CV]  C=1, class_weight=None, gamma=0.01, kernel=rbf, score=0.640, total=  10.0s\n",
      "[CV] C=1, class_weight=None, gamma=0.0001, kernel=rbf ................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1, class_weight=None, gamma=0.0001, kernel=rbf, score=0.734, total=   8.1s\n",
      "[CV] C=1, class_weight=None, gamma=0.0001, kernel=rbf ................\n",
      "[CV]  C=1, class_weight=None, gamma=0.0001, kernel=rbf, score=0.721, total=   8.2s\n",
      "[CV] C=1, class_weight=None, gamma=0.0001, kernel=rbf ................\n",
      "[CV]  C=1, class_weight=None, gamma=0.0001, kernel=rbf, score=0.722, total=   7.9s\n",
      "[CV] C=1, class_weight=None, gamma=0.0001, kernel=rbf ................\n",
      "[CV]  C=1, class_weight=None, gamma=0.0001, kernel=rbf, score=0.729, total=   8.0s\n",
      "[CV] C=1, class_weight=None, gamma=0.0001, kernel=rbf ................\n",
      "[CV]  C=1, class_weight=None, gamma=0.0001, kernel=rbf, score=0.724, total=   7.9s\n",
      "[CV] C=100, class_weight=balanced, gamma=1, kernel=rbf ...............\n",
      "[CV]  C=100, class_weight=balanced, gamma=1, kernel=rbf, score=0.641, total=   9.6s\n",
      "[CV] C=100, class_weight=balanced, gamma=1, kernel=rbf ...............\n",
      "[CV]  C=100, class_weight=balanced, gamma=1, kernel=rbf, score=0.640, total=  10.0s\n",
      "[CV] C=100, class_weight=balanced, gamma=1, kernel=rbf ...............\n",
      "[CV]  C=100, class_weight=balanced, gamma=1, kernel=rbf, score=0.640, total=   9.8s\n",
      "[CV] C=100, class_weight=balanced, gamma=1, kernel=rbf ...............\n",
      "[CV]  C=100, class_weight=balanced, gamma=1, kernel=rbf, score=0.640, total=   9.6s\n",
      "[CV] C=100, class_weight=balanced, gamma=1, kernel=rbf ...............\n",
      "[CV]  C=100, class_weight=balanced, gamma=1, kernel=rbf, score=0.640, total=   9.6s\n",
      "[CV] C=100, class_weight=balanced, gamma=0.01, kernel=rbf ............\n",
      "[CV]  C=100, class_weight=balanced, gamma=0.01, kernel=rbf, score=0.641, total=   9.9s\n",
      "[CV] C=100, class_weight=balanced, gamma=0.01, kernel=rbf ............\n",
      "[CV]  C=100, class_weight=balanced, gamma=0.01, kernel=rbf, score=0.640, total=  10.3s\n",
      "[CV] C=100, class_weight=balanced, gamma=0.01, kernel=rbf ............\n",
      "[CV]  C=100, class_weight=balanced, gamma=0.01, kernel=rbf, score=0.640, total=   9.8s\n",
      "[CV] C=100, class_weight=balanced, gamma=0.01, kernel=rbf ............\n",
      "[CV]  C=100, class_weight=balanced, gamma=0.01, kernel=rbf, score=0.640, total=   9.7s\n",
      "[CV] C=100, class_weight=balanced, gamma=0.01, kernel=rbf ............\n",
      "[CV]  C=100, class_weight=balanced, gamma=0.01, kernel=rbf, score=0.640, total=   8.5s\n",
      "[CV] C=100, class_weight=balanced, gamma=0.0001, kernel=rbf ..........\n",
      "[CV]  C=100, class_weight=balanced, gamma=0.0001, kernel=rbf, score=0.751, total=   7.0s\n",
      "[CV] C=100, class_weight=balanced, gamma=0.0001, kernel=rbf ..........\n",
      "[CV]  C=100, class_weight=balanced, gamma=0.0001, kernel=rbf, score=0.741, total=   7.3s\n",
      "[CV] C=100, class_weight=balanced, gamma=0.0001, kernel=rbf ..........\n",
      "[CV]  C=100, class_weight=balanced, gamma=0.0001, kernel=rbf, score=0.736, total=   8.2s\n",
      "[CV] C=100, class_weight=balanced, gamma=0.0001, kernel=rbf ..........\n",
      "[CV]  C=100, class_weight=balanced, gamma=0.0001, kernel=rbf, score=0.744, total=   7.4s\n",
      "[CV] C=100, class_weight=balanced, gamma=0.0001, kernel=rbf ..........\n",
      "[CV]  C=100, class_weight=balanced, gamma=0.0001, kernel=rbf, score=0.746, total=   6.9s\n",
      "[CV] C=100, class_weight=None, gamma=1, kernel=rbf ...................\n",
      "[CV]  C=100, class_weight=None, gamma=1, kernel=rbf, score=0.641, total=   8.5s\n",
      "[CV] C=100, class_weight=None, gamma=1, kernel=rbf ...................\n",
      "[CV]  C=100, class_weight=None, gamma=1, kernel=rbf, score=0.640, total=   9.8s\n",
      "[CV] C=100, class_weight=None, gamma=1, kernel=rbf ...................\n",
      "[CV]  C=100, class_weight=None, gamma=1, kernel=rbf, score=0.640, total=   9.7s\n",
      "[CV] C=100, class_weight=None, gamma=1, kernel=rbf ...................\n",
      "[CV]  C=100, class_weight=None, gamma=1, kernel=rbf, score=0.640, total=  10.4s\n",
      "[CV] C=100, class_weight=None, gamma=1, kernel=rbf ...................\n",
      "[CV]  C=100, class_weight=None, gamma=1, kernel=rbf, score=0.640, total=   9.7s\n",
      "[CV] C=100, class_weight=None, gamma=0.01, kernel=rbf ................\n",
      "[CV]  C=100, class_weight=None, gamma=0.01, kernel=rbf, score=0.641, total=  10.2s\n",
      "[CV] C=100, class_weight=None, gamma=0.01, kernel=rbf ................\n",
      "[CV]  C=100, class_weight=None, gamma=0.01, kernel=rbf, score=0.640, total=   9.9s\n",
      "[CV] C=100, class_weight=None, gamma=0.01, kernel=rbf ................\n",
      "[CV]  C=100, class_weight=None, gamma=0.01, kernel=rbf, score=0.640, total=   9.7s\n",
      "[CV] C=100, class_weight=None, gamma=0.01, kernel=rbf ................\n",
      "[CV]  C=100, class_weight=None, gamma=0.01, kernel=rbf, score=0.640, total=   9.7s\n",
      "[CV] C=100, class_weight=None, gamma=0.01, kernel=rbf ................\n",
      "[CV]  C=100, class_weight=None, gamma=0.01, kernel=rbf, score=0.640, total=   9.9s\n",
      "[CV] C=100, class_weight=None, gamma=0.0001, kernel=rbf ..............\n",
      "[CV]  C=100, class_weight=None, gamma=0.0001, kernel=rbf, score=0.751, total=   8.3s\n",
      "[CV] C=100, class_weight=None, gamma=0.0001, kernel=rbf ..............\n",
      "[CV]  C=100, class_weight=None, gamma=0.0001, kernel=rbf, score=0.741, total=   8.1s\n",
      "[CV] C=100, class_weight=None, gamma=0.0001, kernel=rbf ..............\n",
      "[CV]  C=100, class_weight=None, gamma=0.0001, kernel=rbf, score=0.736, total=   7.9s\n",
      "[CV] C=100, class_weight=None, gamma=0.0001, kernel=rbf ..............\n",
      "[CV]  C=100, class_weight=None, gamma=0.0001, kernel=rbf, score=0.744, total=   8.0s\n",
      "[CV] C=100, class_weight=None, gamma=0.0001, kernel=rbf ..............\n",
      "[CV]  C=100, class_weight=None, gamma=0.0001, kernel=rbf, score=0.746, total=   8.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  90 out of  90 | elapsed: 13.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                           class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': [0.001, 1, 100],\n",
       "                         'class_weight': ['balanced', None],\n",
       "                         'gamma': [1, 0.01, 0.0001], 'kernel': ['rbf']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "\n",
    "# defining parameter range \n",
    "param_grid = {'C': [0.001, 1, 100],\n",
    "              'gamma': [1, 0.01, 0.0001],\n",
    "              'kernel': ['rbf'],\n",
    "              'class_weight': ['balanced', None]\n",
    "             } \n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3) \n",
    "\n",
    "# fitting the model for grid search \n",
    "grid.fit(X_train_10k, y_train_10k_lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 1\n",
      "class_weight = balanced\n",
      "gamma = 0.0001\n",
      "kernel = rbf\n",
      "\n",
      "best classifier =\n",
      " SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.0001, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "# best parameter after tuning\n",
    "best_params = grid.best_params_\n",
    "best_clf = grid.best_estimator_\n",
    "for key in best_params:\n",
    "    print(str(key) + \" = \" + str(best_params[key]))\n",
    "print(\"\\nbest classifier =\\n\", best_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.95      0.83      1252\n",
      "           1       0.84      0.42      0.56       748\n",
      "\n",
      "    accuracy                           0.75      2000\n",
      "   macro avg       0.79      0.68      0.69      2000\n",
      "weighted avg       0.77      0.75      0.73      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "\n",
    "grid_pred = grid.predict(X_test_10k) \n",
    "print(classification_report(y_test_10k_lb, grid_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bit17cc54603a5a49bf946cac7f856dc37b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
