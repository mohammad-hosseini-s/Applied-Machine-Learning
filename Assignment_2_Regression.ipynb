{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 2_Regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.7.6 64-bit",
      "language": "python",
      "name": "python37664bit17cc54603a5a49bf946cac7f856dc37b"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0PsCSfu8bCW0"
      },
      "source": [
        "\n",
        "# ME 5984 Applied Machine Learning, Assignment 2: Regression\n",
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tIvECWxObCW3"
      },
      "source": [
        "In this assignment, you will attempt to identify a regressor that performs the best (using cross validation) on the California housing data set. Instead of using the example code I provided earlier, you will use Scikit-Learn's curated version of the data as the starting point.  \n",
        "The goal of this assignment is to have you gain experience in trying a variety of methods to identify the best regressor for a possibly modifi\fed data set. Your score will be based on the eff\u000bort, and not on exact CV scores or exceeding a minimum score threshold.  \n",
        "Copy the following code into your notebook to get started."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Jc_21N2IbjBU",
        "colab": {}
      },
      "source": [
        "from helper import *\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X,y = fetch_california_housing(return_X_y=True)\n",
        "Xs,ys = shuffle(X, y, random_state=5984)\n",
        "Xstrain, Xstest, Ystrain, Ystest = train_test_split(Xs, ys, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "c0SzXeAObpve"
      },
      "source": [
        "You have now created standardized training and test sets that will be consistent among submissions. Set the test sets aside and do not use them again except where speci\fcally noted."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QU38MrmcbCW4"
      },
      "source": [
        "## 1. Problem 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oYoDnk-abCW5"
      },
      "source": [
        "Using *regression methods that you already learned about*, try to \ffind a regressor that maximizes the cross validation score over 5 folds, where the regressor and training sets in the example below are stand-ins for regressors and set you provide. For example, if you not using a method such as `GridSearchCV` which implements cross validation internally, you may evaluate it speci\fcally via:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "a6zG6CA-pH64"
      },
      "source": [
        "`from sklearn.model_selection import cross_val_score`  \n",
        "`cv_scores = cross_val_score(regressor_, X_training_, y_training_, cv=5)`    \n",
        "`cv_mean_score = np.mean(cv_scores)`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fVt1aSzfcga-"
      },
      "source": [
        "Create pipelines that use StandardScaler as a \ffirst step. Based on how you choose to modify features and perform hyperparameter searches, your pipeline may grow to include more.  \n",
        "Choose from the following regression methods:\n",
        "* `LinearRegression`  \n",
        "* `\u000fRidge`  \n",
        "* `Lasso` and/or `LassoLars` \n",
        "* `ElasticNet`\n",
        "* `DecisionTreeRegressor`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fvp1sgpQdupv"
      },
      "source": [
        "Choose from the following methods for modifying the feature vectors for use in the regression methods:  \n",
        "*   `PolynomialFeatures` for creating \u001e vectors  \n",
        "*   `RFE`, which implements a variation of backward stepwise subset selection  \n",
        "*   `VarianceThreshold` for removing features with low variance  \n",
        "*   `SelectKBest` for choosing the K best features with highest scores\n",
        "*   Hand-made additional features, such as the \"bedrooms per room\" feature from the example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8IPWPqQneQ8z"
      },
      "source": [
        "Choose from the following methods for generating a search for optimal hyperparameters (Note: these methods implement cross validation internally): \n",
        "*   `GridSearchCV`\n",
        "*   `RandomizedSearchCV`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uEi3p8vcfiCs"
      },
      "source": [
        "**Tip**: utilize the documentation provided by scikit-learn as much as possible to better understand these methods, their parameters, and how to best utilize them.  \n",
        "`https://scikit-learn.org/stable/supervised_learning.html`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SdFEZjKnfziq"
      },
      "source": [
        "You may also use other regressors, feature modi\fcations, and search methods besides those listed above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1UbSt3IabCXE"
      },
      "source": [
        "-----\n",
        "### 1.1 Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "r_8n9XmJgE_F"
      },
      "source": [
        "Report the best combination of regression methods, feature modi\fcations, and hyperparameters as a function of the average CV score on the training set using 5-fold cross validation. Compare the best combination's CV score to the score on the test set. Describe what you tried, what you observed, and the insights you may have gained from those trials that led you to discovering the best combination.  \n",
        "Do not use the test set for any part of the hyperparameter search and training above.  \n",
        "You will be scored based on the thoroughness of your search and eff\u000bort.\n",
        "Trying just one method without modifying any hyperparameters, for example, is low eff\u000bort and will be scored as such. Trying several methods with some kind of search over the hyperparameter space, and trying feature modi\fcations for example, will likely result in a higher CV score and will defi\fnitely result in a higher score on this problem. There is not a minimum threshold for CV score that will be checked."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jTcRpAbQRFLi",
        "colab": {}
      },
      "source": [
        "## Import libraries\n",
        "import time\n",
        "import numpy as np\n",
        "np.set_printoptions(suppress=True)\n",
        "import pandas as pd\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import LassoLars\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_regression\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import r2_score\n",
        "from scipy.stats import randint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zx_LrYjc5Zyp"
      },
      "source": [
        "---\n",
        "### 1.1.1 Data set Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "p0zo-Rq558Ey"
      },
      "source": [
        "> First we take a look at the data set and plot the features separately to get a feel for the data set and then check if the there is any `NaN` entries in the data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qjjJPdo15yvS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "fd205cde-9ae6-4cf9-f502-173f5d8e6ed8"
      },
      "source": [
        "## Extract feature names\n",
        "housing = fetch_california_housing()\n",
        "feature_names = housing.feature_names\n",
        "housing = pd.DataFrame(data=housing, columns=feature_names)\n",
        "\n",
        "## Assign feature names to the columns of Xstrain, and Xstest\n",
        "Xstrain_df = pd.DataFrame(data=Xstrain, columns=feature_names)\n",
        "Xstest_df = pd.DataFrame(data=Xstest, columns=feature_names)\n",
        "print(\"Ystrain =\", Ystrain, \"\\n\")\n",
        "Xstrain_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ystrain = [0.996 2.349 0.485 ... 3.493 0.619 3.854] \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MedInc</th>\n",
              "      <th>HouseAge</th>\n",
              "      <th>AveRooms</th>\n",
              "      <th>AveBedrms</th>\n",
              "      <th>Population</th>\n",
              "      <th>AveOccup</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.9074</td>\n",
              "      <td>37.0</td>\n",
              "      <td>4.098662</td>\n",
              "      <td>1.117057</td>\n",
              "      <td>2824.0</td>\n",
              "      <td>4.722408</td>\n",
              "      <td>34.01</td>\n",
              "      <td>-118.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.3889</td>\n",
              "      <td>33.0</td>\n",
              "      <td>6.078880</td>\n",
              "      <td>1.043257</td>\n",
              "      <td>1229.0</td>\n",
              "      <td>3.127226</td>\n",
              "      <td>33.86</td>\n",
              "      <td>-118.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.2167</td>\n",
              "      <td>18.0</td>\n",
              "      <td>3.782468</td>\n",
              "      <td>1.084416</td>\n",
              "      <td>1119.0</td>\n",
              "      <td>3.633117</td>\n",
              "      <td>36.01</td>\n",
              "      <td>-120.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.5557</td>\n",
              "      <td>36.0</td>\n",
              "      <td>7.743396</td>\n",
              "      <td>1.083019</td>\n",
              "      <td>699.0</td>\n",
              "      <td>2.637736</td>\n",
              "      <td>32.73</td>\n",
              "      <td>-117.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.9038</td>\n",
              "      <td>21.0</td>\n",
              "      <td>3.586357</td>\n",
              "      <td>0.982583</td>\n",
              "      <td>1486.0</td>\n",
              "      <td>2.156749</td>\n",
              "      <td>37.36</td>\n",
              "      <td>-122.02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
              "0  1.9074      37.0  4.098662   1.117057      2824.0  4.722408     34.01   \n",
              "1  5.3889      33.0  6.078880   1.043257      1229.0  3.127226     33.86   \n",
              "2  2.2167      18.0  3.782468   1.084416      1119.0  3.633117     36.01   \n",
              "3  7.5557      36.0  7.743396   1.083019       699.0  2.637736     32.73   \n",
              "4  3.9038      21.0  3.586357   0.982583      1486.0  2.156749     37.36   \n",
              "\n",
              "   Longitude  \n",
              "0    -118.26  \n",
              "1    -118.11  \n",
              "2    -120.12  \n",
              "3    -117.23  \n",
              "4    -122.02  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cW5WBJyZOsuA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "bd14a6e4-d010-491d-d02b-4c5027e8142f"
      },
      "source": [
        "## No of NaN entries\n",
        "print(\"No. of NaN entries:\\n\" + 19*\"=\"); housing.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No. of NaN entries:\n",
            "===================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MedInc        0\n",
              "HouseAge      0\n",
              "AveRooms      0\n",
              "AveBedrms     0\n",
              "Population    0\n",
              "AveOccup      0\n",
              "Latitude      0\n",
              "Longitude     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pHvhADyIEWaM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 716
        },
        "outputId": "d71730f7-2e09-456b-d2d0-0f36d0ae641f"
      },
      "source": [
        "## Plot histograms of features\n",
        "Xstrain_df.hist(bins=50, figsize=(15, 12))\n",
        "fig = plt.gcf()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x864 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CZb1OfzQvVah"
      },
      "source": [
        "> As we can see, the `Y` vectors are not in `$` and the data set doesn't have any missing value. The spikes at the end of the range for `HouseAge` and `MdeInc` show that they are capped and the values indicate data was pre-scaled.  Needless to say, the variablity is very different across the features.  \n",
        "For now we don't add any new feature to our data set and try to reduce the prediction error by tuning the parameters as much as possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gVQb4EISVm_8"
      },
      "source": [
        "-----\n",
        "### 1.1.2 Regression Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DG65Or8NyF9Z"
      },
      "source": [
        "> We run all the aforementioned regressors plus `RandomForestRegressor` using two or more of the methods for modifying the features and store the errors and useful parameters to compare the regressors in the end."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2EeamdMKVmvF",
        "colab": {}
      },
      "source": [
        "## Best regressors' MSE and MAE\n",
        "best_regressors = []\n",
        "best_regressors_cr = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SYObEoOVmu0t",
        "colab": {}
      },
      "source": [
        "## Helper functions\n",
        "def get_best_parameters(grid_search_fit):\n",
        "  parameters = grid_search_fit.best_params_  \n",
        "  for key in parameters: \n",
        "    print(\"{} = {}\".format(key, parameters[key]))\n",
        "\n",
        "def get_regressor_name(regressor):\n",
        "  try:\n",
        "    regressor_name = str(type(regressor.named_steps.reg)).split(\".\")[-1][:-2]\n",
        "    if regressor_name in [\"Ridge\", \"Lasso\", \"LassoLars\"]:\n",
        "      regressor_name = \"\".join([regressor_name, \"Regressor\"])\n",
        "    return regressor_name\n",
        "\n",
        "  except AttributeError:\n",
        "    if str(type(regressor)).split(\".\")[-1][:-2] == \"RandomizedSearchCV\":\n",
        "      regressor_name = \"RandomForestRegressor\"\n",
        "      return regressor_name\n",
        "\n",
        "warnings.simplefilter('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_XfxHAo82gNB"
      },
      "source": [
        "-----\n",
        "#### 1.1.2.1 Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PfEJdb9S4Ljy"
      },
      "source": [
        "> We run `LinearRegression`, having added the `PolynomialFeatures` and `SelectKBest` (including all features = 8) methods to the pipeline for feature selection."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ulEPIREaaRUC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "outputId": "6c1d52a4-ed21-47a4-ef52-02e41bb890f3"
      },
      "source": [
        "## Linear Regression\n",
        "lin_reg_start_time = time.perf_counter()\n",
        "lin_reg = Pipeline([(\"poly\", PolynomialFeatures()),\n",
        "                    (\"scaler\", StandardScaler()),\n",
        "                    (\"sk\", SelectKBest(score_func=f_regression)),\n",
        "                    (\"reg\", LinearRegression())])\n",
        "lin_reg_param_grid = {\"poly__degree\": [2, 3],\n",
        "                      \"sk__k\": [2, 4, 6, 8]}\n",
        "lin_reg_grid_search = GridSearchCV(lin_reg, lin_reg_param_grid, cv=5,\n",
        "                                     scoring='neg_mean_squared_error', return_train_score=True)\n",
        "lin_reg_grid_search_fit = lin_reg_grid_search.fit(Xstrain, Ystrain)\n",
        "lin_reg_grid_search_fit_best = lin_reg_grid_search_fit.best_estimator_\n",
        "best_regressors.append(lin_reg_grid_search_fit_best)\n",
        "\n",
        "# Predict\n",
        "lin_reg_grid_search_pred = lin_reg_grid_search_fit_best.predict(Xstest)\n",
        "lin_reg_grid_search_pred_mse = mean_squared_error(Ystest, lin_reg_grid_search_pred)\n",
        "lin_reg_grid_search_pred_rmse = np.sqrt(lin_reg_grid_search_pred_mse)\n",
        "lin_reg_grid_search_pred_mae = mean_absolute_error(Ystest, lin_reg_grid_search_pred)\n",
        "lin_reg_grid_search_pred_r2 = r2_score(Ystest, lin_reg_grid_search_pred)\n",
        "lin_reg_compute_time = time.perf_counter() - lin_reg_start_time\n",
        "\n",
        "# Save the errors for final regression model comparisons\n",
        "best_regressors_cr[\"Linear\"] = [lin_reg_grid_search_pred_rmse,\n",
        "                                lin_reg_grid_search_pred_mse,\n",
        "                                lin_reg_grid_search_pred_mae,\n",
        "                                lin_reg_grid_search_pred_r2,\n",
        "                                lin_reg_grid_search_fit.best_params_[\"poly__degree\"],\n",
        "                                lin_reg_grid_search_fit.best_params_[\"sk__k\"],\n",
        "                                \"-\", \"-\", lin_reg_compute_time]\n",
        "\n",
        "# Report results\n",
        "print(\"Best Parameters:\\n\"+ 16*\"=\"); get_best_parameters(lin_reg_grid_search_fit)\n",
        "print(24*\"=\" + \"\\nComputation time = %1.3f\\n\" %lin_reg_compute_time + 31*\"=\")\n",
        "print(\"Linear Regression RMSE = %.4f\" %lin_reg_grid_search_pred_rmse)\n",
        "print(\"Linear Regression MSE  = %.4f\" %lin_reg_grid_search_pred_mse)\n",
        "print(\"Linear Regression MAE  = %.4f\" %lin_reg_grid_search_pred_mae); print(31*\"=\")\n",
        "print(\"mean train CV score = \\n{}\".format(lin_reg_grid_search.cv_results_[\"mean_train_score\"]))\n",
        "print(\"\\nmean test CV score  = \\n{}\".format(lin_reg_grid_search.cv_results_[\"mean_test_score\"]))\n",
        "print(72*\"=\" + \"\\nBest Estimator:\\n\"); lin_reg_grid_search_fit_best"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Parameters:\n",
            "================\n",
            "poly__degree = 2\n",
            "sk__k = 6\n",
            "========================\n",
            "Computation time = 5.535\n",
            "===============================\n",
            "Linear Regression RMSE = 0.7120\n",
            "Linear Regression MSE  = 0.5070\n",
            "Linear Regression MAE  = 0.5243\n",
            "===============================\n",
            "mean train CV score = \n",
            "[-0.70512106 -0.54774165 -0.53022399 -0.52400737 -0.7051312  -0.55563969\n",
            " -0.54753229 -0.53657062]\n",
            "\n",
            "mean test CV score  = \n",
            "[-0.70546132 -0.54824854 -0.53190686 -0.53318228 -0.70547002 -0.55614551\n",
            " -0.54826078 -0.53752899]\n",
            "========================================================================\n",
            "Best Estimator:\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('poly',\n",
              "                 PolynomialFeatures(degree=2, include_bias=True,\n",
              "                                    interaction_only=False, order='C')),\n",
              "                ('scaler',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('sk',\n",
              "                 SelectKBest(k=6,\n",
              "                             score_func=<function f_regression at 0x000001A19CEA5B88>)),\n",
              "                ('reg',\n",
              "                 LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
              "                                  normalize=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vQC2B4bh7bFZ"
      },
      "source": [
        "> The mean CV scores for the `train` and `test` sets are very close and shows that we are not overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_BzT78-d4J1_"
      },
      "source": [
        "-----\n",
        "#### 1.1.2.2 Ridge Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "c2pPgdgo6Q7m"
      },
      "source": [
        "> We run `Ridge` regression, having added the `PolynomialFeatures` and `SelectKBest` methods to the pipeline for feature selection  ||`GridSearchCV`||."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iioRVk26caas",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 924
        },
        "outputId": "6398775e-8d51-479f-ef43-63c31dfcfaae"
      },
      "source": [
        "## Ridge Regression\n",
        "ridge_reg_start_time = time.perf_counter()\n",
        "ridge_reg = Pipeline([(\"poly\", PolynomialFeatures()),\n",
        "                      (\"scaler\", StandardScaler()),\n",
        "                      (\"sk\", SelectKBest(score_func=f_regression)),\n",
        "                      (\"reg\", Ridge())])\n",
        "ridge_reg_param_grid = {\"reg__alpha\": [100.0, 10.0, 1.0, 0.1, 0.01, 0.001, 0.0001, 0],\n",
        "                        \"poly__degree\": [2, 3],\n",
        "                        \"sk__k\": [2, 4, 6, 8]}\n",
        "ridge_reg_grid_search = GridSearchCV(ridge_reg, ridge_reg_param_grid, cv=5,\n",
        "                                     scoring='neg_mean_squared_error', return_train_score=True)\n",
        "ridge_reg_grid_search_fit = ridge_reg_grid_search.fit(Xstrain, Ystrain)\n",
        "ridge_reg_grid_search_fit_best = ridge_reg_grid_search_fit.best_estimator_\n",
        "best_regressors.append(ridge_reg_grid_search_fit_best)\n",
        "\n",
        "# Predict\n",
        "ridge_reg_grid_search_pred = ridge_reg_grid_search_fit_best.predict(Xstest)\n",
        "ridge_reg_grid_search_pred_mse = mean_squared_error(Ystest, ridge_reg_grid_search_pred)\n",
        "ridge_reg_grid_search_pred_rmse = np.sqrt(ridge_reg_grid_search_pred_mse)\n",
        "ridge_reg_grid_search_pred_mae = mean_absolute_error(Ystest, ridge_reg_grid_search_pred)\n",
        "ridge_reg_grid_search_pred_r2 = r2_score(Ystest, ridge_reg_grid_search_pred)\n",
        "ridge_reg_compute_time = time.perf_counter() - ridge_reg_start_time\n",
        "\n",
        "# Save the errors for final regression model comparisons\n",
        "best_regressors_cr[\"Ridge\"] = [ridge_reg_grid_search_pred_rmse,\n",
        "                               ridge_reg_grid_search_pred_mse, \n",
        "                               ridge_reg_grid_search_pred_mae,\n",
        "                               ridge_reg_grid_search_pred_r2,\n",
        "                               ridge_reg_grid_search_fit.best_params_[\"poly__degree\"],\n",
        "                               ridge_reg_grid_search_fit.best_params_[\"sk__k\"],\n",
        "                               ridge_reg_grid_search_fit.best_params_[\"reg__alpha\"],\n",
        "                               \"-\", ridge_reg_compute_time]\n",
        "\n",
        "# Report results\n",
        "print(\"Best Parameters:\\n\"+ 16*\"=\"); get_best_parameters(ridge_reg_grid_search_fit)\n",
        "print(25*\"=\" + \"\\nComputation time = %1.3f\\n\" %ridge_reg_compute_time + 30*\"=\")\n",
        "print(\"Ridge Regression RMSE = %.4f\" %ridge_reg_grid_search_pred_rmse)\n",
        "print(\"Ridge Regression MSE  = %.4f\" %ridge_reg_grid_search_pred_mse)\n",
        "print(\"Ridge Regression MAE  = %.4f\" %ridge_reg_grid_search_pred_mae); print(30*\"=\")\n",
        "print(\"mean train CV score = \\n{}\".format(ridge_reg_grid_search.cv_results_[\"mean_train_score\"]))\n",
        "print(\"\\nmean test CV score  = \\n{}\".format(ridge_reg_grid_search.cv_results_[\"mean_test_score\"]))\n",
        "print(72*\"=\" + \"\\nBest Estimator:\\n\"); ridge_reg_grid_search_fit_best"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Parameters:\n",
            "================\n",
            "poly__degree = 2\n",
            "reg__alpha = 0.01\n",
            "sk__k = 6\n",
            "=========================\n",
            "Computation time = 42.863\n",
            "==============================\n",
            "Ridge Regression RMSE = 0.7120\n",
            "Ridge Regression MSE  = 0.5070\n",
            "Ridge Regression MAE  = 0.5244\n",
            "==============================\n",
            "mean train CV score = \n",
            "[-0.70625741 -0.69083193 -0.64282988 -0.62695136 -0.70547997 -0.66117671\n",
            " -0.62130046 -0.60768436 -0.70513356 -0.57732236 -0.5572987  -0.5493382\n",
            " -0.70512121 -0.54859443 -0.53110533 -0.52484676 -0.70512106 -0.54775151\n",
            " -0.53023441 -0.52401734 -0.70512106 -0.54774175 -0.53022409 -0.52400748\n",
            " -0.70512106 -0.54774165 -0.53022399 -0.52400738 -0.70512106 -0.54774165\n",
            " -0.53022399 -0.52400737 -0.70518343 -0.68662461 -0.67914627 -0.67072254\n",
            " -0.70514499 -0.61739686 -0.61002815 -0.60060142 -0.70513168 -0.56033362\n",
            " -0.56048993 -0.55151003 -0.70513121 -0.55675129 -0.55653789 -0.54585198\n",
            " -0.70513121 -0.55664303 -0.55396636 -0.54355997 -0.7051312  -0.55624911\n",
            " -0.55045387 -0.54023213 -0.7051312  -0.55569905 -0.54882989 -0.53831754\n",
            " -0.7051312  -0.55563969 -0.54753229 -0.53657062]\n",
            "\n",
            "mean test CV score  = \n",
            "[-0.70647984 -0.69108283 -0.64358068 -0.63211313 -0.70575438 -0.66144174\n",
            " -0.62200791 -0.61396018 -0.70546152 -0.57768494 -0.55816422 -0.55679593\n",
            " -0.70546013 -0.54906779 -0.53257825 -0.53367168 -0.70546119 -0.54825455\n",
            " -0.53189296 -0.53315319 -0.70546131 -0.54824825 -0.53190449 -0.53317843\n",
            " -0.70546132 -0.5482485  -0.53190661 -0.53318188 -0.70546132 -0.54824854\n",
            " -0.53190686 -0.53318228 -0.70541707 -0.6868701  -0.67939763 -0.67098411\n",
            " -0.70542546 -0.6177301  -0.61037203 -0.60096167 -0.70545964 -0.56078941\n",
            " -0.56095973 -0.55206362 -0.70546884 -0.55726062 -0.55706597 -0.54650334\n",
            " -0.7054699  -0.55715931 -0.55452822 -0.54426486 -0.70547001 -0.55676308\n",
            " -0.5510348  -0.54096717 -0.70547002 -0.55620689 -0.54944547 -0.53910211\n",
            " -0.70547002 -0.55614551 -0.54826078 -0.53752899]\n",
            "========================================================================\n",
            "Best Estimator:\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('poly',\n",
              "                 PolynomialFeatures(degree=2, include_bias=True,\n",
              "                                    interaction_only=False, order='C')),\n",
              "                ('scaler',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('sk',\n",
              "                 SelectKBest(k=6,\n",
              "                             score_func=<function f_regression at 0x000001A19CEA5B88>)),\n",
              "                ('reg',\n",
              "                 Ridge(alpha=0.01, copy_X=True, fit_intercept=True,\n",
              "                       max_iter=None, normalize=False, random_state=None,\n",
              "                       solver='auto', tol=0.001))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xO_loiFp70Ue"
      },
      "source": [
        "> The mean CV scores for the `train` and `test` sets are very close and shows that we are not overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_dPPi09b8EgF"
      },
      "source": [
        "-----\n",
        "#### 1.1.2.3 LASSO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8LR6BA248LEK"
      },
      "source": [
        "> `Lasso` with `PolynomialFeatures` and `SelectKBest` methods for feature selection ||`GridSearchCV`||."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qFhxRzTvccfy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        },
        "outputId": "48551b26-01c3-45f2-ccf5-d9d414164b23"
      },
      "source": [
        "## LASSO\n",
        "lasso_reg_start_time = time.perf_counter()\n",
        "lasso_reg = Pipeline([(\"poly\", PolynomialFeatures()),\n",
        "                      (\"scaler\", StandardScaler()),\n",
        "                      (\"sk\", SelectKBest(score_func=f_regression)),\n",
        "                      (\"reg\", Lasso())])\n",
        "lasso_reg_param_grid = {\"reg__alpha\": [100, 10, 1, 0.1, 0.01, 0.001, 0.0001, 0],\n",
        "                        \"poly__degree\": [2, 3],\n",
        "                        \"sk__k\": [2, 4, 6, 8]}\n",
        "lasso_reg_grid_search = GridSearchCV(lasso_reg, lasso_reg_param_grid, cv=5,\n",
        "                                     scoring='neg_mean_squared_error', return_train_score=True)\n",
        "lasso_reg_grid_search_fit = lasso_reg_grid_search.fit(Xstrain, Ystrain)\n",
        "lasso_reg_grid_search_fit_best = lasso_reg_grid_search_fit.best_estimator_\n",
        "best_regressors.append(lasso_reg_grid_search_fit_best)\n",
        "\n",
        "# Predict\n",
        "lasso_reg_grid_search_pred = lasso_reg_grid_search_fit_best.predict(Xstest)\n",
        "lasso_reg_grid_search_pred_mse = mean_squared_error(Ystest, lasso_reg_grid_search_pred)\n",
        "lasso_reg_grid_search_pred_rmse = np.sqrt(lasso_reg_grid_search_pred_mse)\n",
        "lasso_reg_grid_search_pred_mae = mean_absolute_error(Ystest, lasso_reg_grid_search_pred)\n",
        "lasso_reg_grid_search_pred_r2 = r2_score(Ystest, lasso_reg_grid_search_pred)\n",
        "lasso_reg_compute_time = time.perf_counter() - lasso_reg_start_time\n",
        "\n",
        "# Save the errors for final regression model comparisons\n",
        "best_regressors_cr[\"LASSO\"] = [lasso_reg_grid_search_pred_rmse,\n",
        "                               lasso_reg_grid_search_pred_mse,\n",
        "                               lasso_reg_grid_search_pred_mae,\n",
        "                               lasso_reg_grid_search_pred_r2,\n",
        "                               lasso_reg_grid_search_fit.best_params_[\"poly__degree\"],\n",
        "                               lasso_reg_grid_search_fit.best_params_[\"sk__k\"],\n",
        "                               lasso_reg_grid_search_fit.best_params_[\"reg__alpha\"],\n",
        "                               \"-\", lasso_reg_compute_time]\n",
        "# Report results\n",
        "print(\"Best Parameters:\\n\"+ 16*\"=\"); get_best_parameters(lasso_reg_grid_search_fit)\n",
        "print(25*\"=\" + \"\\nComputation_time = %1.3f\\n\" %lasso_reg_compute_time + 30*\"=\")\n",
        "print(\"LASSO Regression RMSE = %.4f\" %lasso_reg_grid_search_pred_rmse)\n",
        "print(\"LASSO Regression MSE  = %.4f\" %lasso_reg_grid_search_pred_mse)\n",
        "print(\"LASSO Regression MAE  = %.4f\" %lasso_reg_grid_search_pred_mae); print(30*\"=\")\n",
        "print(\"mean train CV score = \\n{}\".format(lasso_reg_grid_search.cv_results_[\"mean_train_score\"]))\n",
        "print(\"\\nmean test CV score  = \\n{}\".format(lasso_reg_grid_search.cv_results_[\"mean_test_score\"]))\n",
        "print(72*\"=\" + \"\\nBest Estimator:\\n\"); lasso_reg_grid_search_fit_best"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Parameters:\n",
            "================\n",
            "poly__degree = 3\n",
            "reg__alpha = 0\n",
            "sk__k = 8\n",
            "=========================\n",
            "Computation_time = 49.855\n",
            "==============================\n",
            "LASSO Regression RMSE = 0.7504\n",
            "LASSO Regression MSE  = 0.5631\n",
            "LASSO Regression MAE  = 0.5562\n",
            "==============================\n",
            "mean train CV score = \n",
            "[-1.33677595 -1.33677595 -1.33677595 -1.33677595 -1.33677595 -1.33677595\n",
            " -1.33677595 -1.33677595 -1.33677595 -1.33677595 -1.33677595 -1.33677595\n",
            " -0.71559919 -0.71559919 -0.67732931 -0.67732931 -0.70569919 -0.70172957\n",
            " -0.6542816  -0.63917402 -0.70560019 -0.66068543 -0.62238092 -0.60963539\n",
            " -0.70533686 -0.6479926  -0.61238348 -0.60017853 -0.70527653 -0.64660485\n",
            " -0.61126925 -0.59912793 -1.33677595 -1.33677595 -1.33677595 -1.33677595\n",
            " -1.33677595 -1.33677595 -1.33677595 -1.33677595 -1.33677595 -1.33677595\n",
            " -1.33677595 -1.33677595 -0.71513966 -0.71513364 -0.71513364 -0.71513364\n",
            " -0.70525592 -0.70524048 -0.68502    -0.67769733 -0.70515904 -0.62554282\n",
            " -0.61041193 -0.6014325  -0.70515826 -0.61661615 -0.59974694 -0.5897869\n",
            " -0.70515828 -0.61566259 -0.59864089 -0.5884456 ]\n",
            "\n",
            "mean test CV score  = \n",
            "[-1.33679333 -1.33679333 -1.33679333 -1.33679333 -1.33679333 -1.33679333\n",
            " -1.33679333 -1.33679333 -1.33679333 -1.33679333 -1.33679333 -1.33679333\n",
            " -0.71576367 -0.71576367 -0.67782871 -0.67782871 -0.70591271 -0.70210825\n",
            " -0.65533269 -0.64294219 -0.7058193  -0.66097557 -0.6231095  -0.61559574\n",
            " -0.70563825 -0.64828925 -0.61311223 -0.60684477 -0.70558704 -0.64690214\n",
            " -0.61199823 -0.605876   -1.33679333 -1.33679333 -1.33679333 -1.33679333\n",
            " -1.33679333 -1.33679333 -1.33679333 -1.33679333 -1.33679333 -1.33679333\n",
            " -1.33679333 -1.33679333 -0.71539251 -0.71538066 -0.71538066 -0.71538066\n",
            " -0.70556123 -0.7055375  -0.68525519 -0.6780503  -0.70547029 -0.62589907\n",
            " -0.61078631 -0.6018136  -0.70547012 -0.61697382 -0.60012452 -0.59015581\n",
            " -0.7054702  -0.61602043 -0.59901887 -0.58881338]\n",
            "========================================================================\n",
            "Best Estimator:\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('poly',\n",
              "                 PolynomialFeatures(degree=3, include_bias=True,\n",
              "                                    interaction_only=False, order='C')),\n",
              "                ('scaler',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('sk',\n",
              "                 SelectKBest(k=8,\n",
              "                             score_func=<function f_regression at 0x000001A19CEA5B88>)),\n",
              "                ('reg',\n",
              "                 Lasso(alpha=0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
              "                       normalize=False, positive=False, precompute=False,\n",
              "                       random_state=None, selection='cyclic', tol=0.0001,\n",
              "                       warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rUPcFLPX9suz"
      },
      "source": [
        "> The mean CV scores for the `train` and `test` sets are very close and shows that we are not overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aaIVtJmS9uw8"
      },
      "source": [
        "-----\n",
        "#### 1.1.2.4 LARS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YxHdeQO-91DA"
      },
      "source": [
        "> `LassoLars` with `PolynomialFeatures` and `SelectKBest` methods for feature selection ||`GridSearchCV`||."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0pEjl3aOceST",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        },
        "outputId": "9de1e098-91cd-493d-fe60-0174d8c32999"
      },
      "source": [
        "## LARS\n",
        "lassoLars_reg_start_time = time.perf_counter()\n",
        "lassoLars_reg = Pipeline([(\"poly\", PolynomialFeatures()),\n",
        "                          (\"scaler\", StandardScaler()),\n",
        "                          (\"sk\", SelectKBest(score_func=f_regression)),\n",
        "                          (\"reg\", LassoLars())])\n",
        "lassoLars_reg_param_grid = {\"reg__alpha\": [100, 10, 1, 0.1, 0.01, 0.001, 0.0001, 0],\n",
        "                            \"poly__degree\": [2, 3],\n",
        "                            \"sk__k\": [2, 4, 6, 8]}\n",
        "lassoLars_reg_grid_search = GridSearchCV(lassoLars_reg, lassoLars_reg_param_grid, cv=5,\n",
        "                                         scoring='neg_mean_squared_error', return_train_score=True)\n",
        "lassoLars_reg_grid_search_fit = lassoLars_reg_grid_search.fit(Xstrain, Ystrain)\n",
        "lassoLars_reg_grid_search_fit_best = lassoLars_reg_grid_search_fit.best_estimator_\n",
        "best_regressors.append(lassoLars_reg_grid_search_fit_best)\n",
        "\n",
        "# Predict\n",
        "lassoLars_reg_grid_search_pred = lassoLars_reg_grid_search_fit_best.predict(Xstest)\n",
        "lassoLars_reg_grid_search_pred_mse = mean_squared_error(Ystest, lassoLars_reg_grid_search_pred)\n",
        "lassoLars_reg_grid_search_pred_rmse = np.sqrt(lassoLars_reg_grid_search_pred_mse)\n",
        "lassoLars_reg_grid_search_pred_mae = mean_absolute_error(Ystest, lassoLars_reg_grid_search_pred)\n",
        "LassoLars_reg_grid_search_pred_r2 = r2_score(Ystest, lassoLars_reg_grid_search_pred)\n",
        "lassoLars_reg_compute_time = time.perf_counter() - lassoLars_reg_start_time\n",
        "\n",
        "# Save the errors for final regression model comparisons\n",
        "best_regressors_cr[\"LARS\"] = [lassoLars_reg_grid_search_pred_rmse,\n",
        "                              lassoLars_reg_grid_search_pred_mse,\n",
        "                              lassoLars_reg_grid_search_pred_mae,\n",
        "                              LassoLars_reg_grid_search_pred_r2,\n",
        "                              lassoLars_reg_grid_search_fit.best_params_[\"poly__degree\"],\n",
        "                              lassoLars_reg_grid_search_fit.best_params_[\"sk__k\"],\n",
        "                              lassoLars_reg_grid_search_fit.best_params_[\"reg__alpha\"],\n",
        "                              \"-\", lassoLars_reg_compute_time]\n",
        "\n",
        "# Report results\n",
        "print(\"Best Parameters:\\n\"+ 16*\"=\"); get_best_parameters(lassoLars_reg_grid_search_fit)\n",
        "print(25*\"=\" + \"\\nComputation_time = %1.3f\\n\" %lassoLars_reg_compute_time + 34*\"=\")\n",
        "print(\"LassoLars Regression RMSE = %.4f\" %lassoLars_reg_grid_search_pred_rmse)\n",
        "print(\"LassoLars Regression MSE  = %.4f\" %lassoLars_reg_grid_search_pred_mse)\n",
        "print(\"LassoLars Regression MAE  = %.4f\" %lassoLars_reg_grid_search_pred_mae); print(34*\"=\")\n",
        "print(\"mean train CV score = \\n{}\".format(lassoLars_reg_grid_search.cv_results_[\"mean_train_score\"]))\n",
        "print(\"\\nmean test CV score  = \\n{}\".format(lassoLars_reg_grid_search.cv_results_[\"mean_test_score\"]))\n",
        "print(72*\"=\" + \"\\nBest Estimator:\\n\"); lassoLars_reg_grid_search_fit_best"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Parameters:\n",
            "================\n",
            "poly__degree = 2\n",
            "reg__alpha = 0\n",
            "sk__k = 6\n",
            "=========================\n",
            "Computation_time = 43.753\n",
            "==================================\n",
            "LassoLars Regression RMSE = 0.7120\n",
            "LassoLars Regression MSE  = 0.5070\n",
            "LassoLars Regression MAE  = 0.5243\n",
            "==================================\n",
            "mean train CV score = \n",
            "[-1.33677595 -1.33677595 -1.33677595 -1.33677595 -1.33677595 -1.33677595\n",
            " -1.33677595 -1.33677595 -1.33677595 -1.33677595 -1.33677595 -1.33677595\n",
            " -1.33677595 -1.33677595 -1.33677595 -1.33677595 -1.33677595 -1.33677595\n",
            " -1.33677595 -1.33677595 -0.71880879 -0.71880879 -0.68118236 -0.68118236\n",
            " -0.70573128 -0.70277275 -0.65553083 -0.64150135 -0.70512106 -0.54774165\n",
            " -0.53022399 -0.52400737 -1.33677595 -1.33677595 -1.33677595 -1.33677595\n",
            " -1.33677595 -1.33677595 -1.33677595 -1.33677595 -1.33677595 -1.33677595\n",
            " -1.33677595 -1.33677595 -1.33677595 -1.33677595 -1.33677595 -1.33677595\n",
            " -1.33677595 -1.33677595 -1.33677595 -1.33677595 -0.71834551 -0.71834551\n",
            " -0.71834551 -0.71834551 -0.70526335 -0.70526335 -0.68862566 -0.68321131\n",
            " -0.7051312  -0.55675217 -0.55341439 -0.54313252]\n",
            "\n",
            "mean test CV score  = \n",
            "[-1.33679333 -1.33679333 -1.33679333 -1.33679333 -1.33679333 -1.33679333\n",
            " -1.33679333 -1.33679333 -1.33679333 -1.33679333 -1.33679333 -1.33679333\n",
            " -1.33679333 -1.33679333 -1.33679333 -1.33679333 -1.33679333 -1.33679333\n",
            " -1.33679333 -1.33679333 -0.71896635 -0.71896635 -0.68166656 -0.68166656\n",
            " -0.70594389 -0.70318534 -0.65655407 -0.64481234 -0.70546132 -0.54824854\n",
            " -0.53190686 -0.53318228 -1.33679333 -1.33679333 -1.33679333 -1.33679333\n",
            " -1.33679333 -1.33679333 -1.33679333 -1.33679333 -1.33679333 -1.33679333\n",
            " -1.33679333 -1.33679333 -1.33679333 -1.33679333 -1.33679333 -1.33679333\n",
            " -1.33679333 -1.33679333 -1.33679333 -1.33679333 -0.71861717 -0.71861717\n",
            " -0.71861717 -0.71861717 -0.70559452 -0.70559452 -0.68886166 -0.68360858\n",
            " -0.70547002 -0.55727018 -0.55398871 -0.54385996]\n",
            "========================================================================\n",
            "Best Estimator:\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('poly',\n",
              "                 PolynomialFeatures(degree=2, include_bias=True,\n",
              "                                    interaction_only=False, order='C')),\n",
              "                ('scaler',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('sk',\n",
              "                 SelectKBest(k=6,\n",
              "                             score_func=<function f_regression at 0x000001A19CEA5B88>)),\n",
              "                ('reg',\n",
              "                 LassoLars(alpha=0, copy_X=True, eps=2.220446049250313e-16,\n",
              "                           fit_intercept=True, fit_path=True, max_iter=500,\n",
              "                           normalize=True, positive=False, precompute='auto',\n",
              "                           verbose=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uIzqXw---xqa"
      },
      "source": [
        "> The mean CV scores for the `train` and `test` sets are very close and shows that we are not overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mp6rkHqt-n1D"
      },
      "source": [
        "-----\n",
        "#### 1.1.2.5 Elastic Net"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "f2v-JhvW-6-s"
      },
      "source": [
        "> `ElasticNet` with `PolynomialFeatures` and `SelectKBest` methods for feature selection ||`GridSearchCV`||."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DiVtTajGcfve",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "95708e48-c5d5-4e55-a57c-fc0ae2a9614b"
      },
      "source": [
        "## Elastic Net and scores\n",
        "ElNet_reg_start_time = time.perf_counter()\n",
        "ElNet_reg = Pipeline([(\"poly\", PolynomialFeatures()),\n",
        "                      (\"scaler\", StandardScaler()),\n",
        "                      (\"sk\", SelectKBest(score_func=f_regression)),\n",
        "                      (\"reg\", ElasticNet())])\n",
        "ElNet_reg_param_grid = {\"reg__alpha\": [100, 10, 1, 0.1, 0.01, 0.001, 0.0001, 0],\n",
        "                        \"reg__l1_ratio\": [0.9, 0.6, 0.3, 0.2, 0.1, 0.01],\n",
        "                        \"poly__degree\": [2, 3],\n",
        "                        \"sk__k\": [2, 4, 6, 8]}\n",
        "ElNet_reg_grid_search = GridSearchCV(ElNet_reg, ElNet_reg_param_grid, cv=5,\n",
        "                           scoring='neg_mean_squared_error', return_train_score=True)\n",
        "ElNet_reg_grid_search_fit = ElNet_reg_grid_search.fit(Xstrain, Ystrain)\n",
        "ElNet_reg_grid_search_fit_best = ElNet_reg_grid_search_fit.best_estimator_\n",
        "best_regressors.append(ElNet_reg_grid_search_fit_best)\n",
        "\n",
        "# Predict\n",
        "ElNet_reg_grid_search_pred = ElNet_reg_grid_search_fit_best.predict(Xstest)\n",
        "ElNet_reg_grid_search_pred_mse = mean_squared_error(Ystest, ElNet_reg_grid_search_pred)\n",
        "ElNet_reg_grid_search_pred_rmse = np.sqrt(ElNet_reg_grid_search_pred_mse)\n",
        "ElNet_reg_grid_search_pred_mae = mean_absolute_error(Ystest, ElNet_reg_grid_search_pred)\n",
        "ElNet_reg_grid_search_pred_r2 = r2_score(Ystest, ElNet_reg_grid_search_pred)\n",
        "ElNet_reg_compute_time = time.perf_counter() - ElNet_reg_start_time\n",
        "\n",
        "# Save the errors for final regression model comparisons\n",
        "best_regressors_cr[\"Elastic Net\"] = [ElNet_reg_grid_search_pred_rmse,\n",
        "                                     ElNet_reg_grid_search_pred_mse,\n",
        "                                     ElNet_reg_grid_search_pred_mae,\n",
        "                                     ElNet_reg_grid_search_pred_r2,\n",
        "                                     ElNet_reg_grid_search_fit.best_params_[\"poly__degree\"],\n",
        "                                     ElNet_reg_grid_search_fit.best_params_[\"sk__k\"],\n",
        "                                     ElNet_reg_grid_search_fit.best_params_[\"reg__alpha\"],\n",
        "                                     ElNet_reg_grid_search_fit.best_params_[\"reg__l1_ratio\"],\n",
        "                                     ElNet_reg_compute_time]\n",
        "\n",
        "# Report results\n",
        "print(\"Best Parameters:\\n\"+ 16*\"=\"); get_best_parameters(ElNet_reg_grid_search_fit)\n",
        "print(25*\"=\" + \"\\nComputation_time = %1.2f\\n\" %ElNet_reg_compute_time + 36*\"=\")\n",
        "print(\"Elastic Net Regression RMSE = %.4f\" %ElNet_reg_grid_search_pred_rmse)\n",
        "print(\"Elastic Net Regression MSE  = %.4f\" %ElNet_reg_grid_search_pred_mse)\n",
        "print(\"Elastic Net Regression MAE  = %.4f\" %ElNet_reg_grid_search_pred_mae); print(36*\"=\")\n",
        "print(\"mean train CV score = \\n{}\".format(ElNet_reg_grid_search.cv_results_[\"mean_train_score\"]))\n",
        "print(\"\\nmean test CV score  = \\n{}\".format(ElNet_reg_grid_search.cv_results_[\"mean_test_score\"]))\n",
        "print(73*\"=\" + \"\\nBest Estimator:\\n\"); ElNet_reg_grid_search_fit_best"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Parameters:\n",
            "================\n",
            "poly__degree = 3\n",
            "reg__alpha = 0\n",
            "reg__l1_ratio = 0.9\n",
            "sk__k = 8\n",
            "=========================\n",
            "Computation_time = 298.97\n",
            "====================================\n",
            "Elastic Net Regression RMSE = 0.7504\n",
            "Elastic Net Regression MSE  = 0.5631\n",
            "Elastic Net Regression MAE  = 0.5562\n",
            "====================================\n",
            "mean train CV score = \n",
            "[-1.33677595 -1.33677595 -1.33677595 -1.33677595 -1.33677595 -1.33677595\n",
            " -1.33677595 -1.33677595 -1.33677595 -1.33677595 -1.33677595 -1.33677595\n",
            " -1.33677595 -1.33677595 -1.33677595 -1.33677595 -1.33677595 -1.33677595\n",
            " -1.33677595 -1.33677595 -1.33677595 -1.33677595 -1.33677595 -1.33677595\n",
            " -1.33677595 -1.33677595 -1.33677595 -1.33677595 -1.33677595 -1.33677595\n",
            " -1.33677595 -1.33677595 -1.33677595 -1.33677595 -1.33677595 -1.33677595\n",
            " -1.33677595 -1.33677595 -1.33677595 -1.33677595 -1.33677595 -1.33677595\n",
            " -1.33677595 -1.33677595 -1.16524647 -1.07341542 -1.01917109 -1.00192018\n",
            " -1.33677595 -1.33677595 -1.33677595 -1.33677595 -1.10641518 -1.10108502\n",
            " -1.10108502 -1.10108502 -0.88975585 -0.86377934 -0.83545447 -0.83520918\n",
            " -0.84318817 -0.81346822 -0.77812337 -0.77690628 -0.8059555  -0.77581648\n",
            " -0.736604   -0.73436562 -0.77916135 -0.7516041  -0.71177096 -0.7080551\n",
            " -0.71504393 -0.71504393 -0.6758167  -0.6758167  -0.71195825 -0.71254965\n",
            " -0.67152979 -0.67142924 -0.7095608  -0.71211342 -0.67004228 -0.66826998\n",
            " -0.70892348 -0.7118815  -0.66966054 -0.66758205 -0.70836396 -0.71167982\n",
            " -0.66905726 -0.6618816  -0.7079256  -0.71163398 -0.66445976 -0.65499529\n",
            " -0.70573522 -0.70144458 -0.65369905 -0.63823147 -0.70616387 -0.70069602\n",
            " -0.65234735 -0.63594966 -0.70627345 -0.69639522 -0.64823551 -0.6325679\n",
            " -0.706292   -0.69508484 -0.64686597 -0.63107986 -0.70630635 -0.69397343\n",
            " -0.64570962 -0.62983789 -0.70631678 -0.6931721  -0.64487264 -0.62892815\n",
            " -0.70560015 -0.66196162 -0.6230443  -0.61008449 -0.70560003 -0.66517974\n",
            " -0.6247428  -0.61126441 -0.70559992 -0.66766177 -0.6260916  -0.61223349\n",
            " -0.70560388 -0.66836061 -0.62648251 -0.61251993 -0.70561137 -0.66900522\n",
            " -0.62685248 -0.61279267 -0.70562393 -0.66954445 -0.62717197 -0.61302907\n",
            " -0.70533415 -0.64820946 -0.61251975 -0.60028774 -0.70532643 -0.64884965\n",
            " -0.61292123 -0.60061018 -0.70531928 -0.64947405 -0.61331328 -0.60092592\n",
            " -0.70531702 -0.64967874 -0.6134419  -0.60102952 -0.70531481 -0.64988182\n",
            " -0.61356948 -0.60113244 -0.70531286 -0.65006309 -0.61368343 -0.6012244\n",
            " -0.70527653 -0.64660485 -0.61126925 -0.59912793 -0.70527653 -0.64660485\n",
            " -0.61126925 -0.59912793 -0.70527653 -0.64660485 -0.61126925 -0.59912793\n",
            " -0.70527653 -0.64660485 -0.61126925 -0.59912793 -0.70527653 -0.64660485\n",
            " -0.61126925 -0.59912793 -0.70527653 -0.64660485 -0.61126925 -0.59912793\n",
            " -1.33677595 -1.33677595 -1.33677595 -1.33677595 -1.33677595 -1.33677595\n",
            " -1.33677595 -1.33677595 -1.33677595 -1.33677595 -1.33677595 -1.33677595\n",
            " -1.33677595 -1.33677595 -1.33677595 -1.33677595 -1.33677595 -1.33677595\n",
            " -1.33677595 -1.33677595 -1.33677595 -1.33677595 -1.33677595 -1.33677595\n",
            " -1.33677595 -1.33677595 -1.33677595 -1.33677595 -1.33677595 -1.33677595\n",
            " -1.33677595 -1.33677595 -1.33677595 -1.33677595 -1.33677595 -1.33677595\n",
            " -1.33677595 -1.33677595 -1.33677595 -1.33677595 -1.33677595 -1.33677595\n",
            " -1.33677595 -1.33677595 -1.16487323 -1.06228547 -1.00043731 -0.96318732\n",
            " -1.33677595 -1.33677595 -1.33677595 -1.33677595 -1.10530377 -1.09242037\n",
            " -1.091814   -1.091814   -0.88865142 -0.85042637 -0.84335632 -0.84257273\n",
            " -0.84207473 -0.80027897 -0.79279282 -0.79168558 -0.80482922 -0.76265061\n",
            " -0.75651829 -0.75637878 -0.77802091 -0.73835657 -0.73514273 -0.73711369\n",
            " -0.71392037 -0.71395159 -0.71395159 -0.71395159 -0.71071752 -0.71040229\n",
            " -0.71040229 -0.71040229 -0.70830218 -0.70868752 -0.70916529 -0.70916515\n",
            " -0.7076618  -0.70858564 -0.70933086 -0.70933084 -0.70709974 -0.70850704\n",
            " -0.70949851 -0.70949779 -0.70665949 -0.70847941 -0.70749329 -0.70611779\n",
            " -0.70524132 -0.70524804 -0.68452221 -0.67710193 -0.7052274  -0.70094894\n",
            " -0.68520716 -0.67747661 -0.70520798 -0.69412514 -0.68451721 -0.6763848\n",
            " -0.70520229 -0.69277253 -0.68434885 -0.67638573 -0.70519716 -0.69166803\n",
            " -0.68379397 -0.67583657 -0.70519307 -0.69080817 -0.68307073 -0.67501359\n",
            " -0.70515627 -0.62576073 -0.61230702 -0.60346646 -0.70515265 -0.62727182\n",
            " -0.61740427 -0.60876478 -0.70515249 -0.62973307 -0.62175078 -0.61345898\n",
            " -0.70515281 -0.63069811 -0.6230607  -0.61487832 -0.70515323 -0.63171446\n",
            " -0.62431005 -0.61622352 -0.70515368 -0.63266401 -0.62538714 -0.61737182\n",
            " -0.70515794 -0.6165955  -0.59990703 -0.58996613 -0.70515705 -0.61654888\n",
            " -0.60038623 -0.59050303 -0.70515627 -0.61652449 -0.60086382 -0.59103851\n",
            " -0.70515603 -0.61652116 -0.60102258 -0.59121665 -0.7051558  -0.61652018\n",
            " -0.60118115 -0.59139461 -0.7051556  -0.6165213  -0.60132369 -0.59155459\n",
            " -0.70515828 -0.61566259 -0.59864089 -0.5884456  -0.70515828 -0.61566259\n",
            " -0.59864089 -0.5884456  -0.70515828 -0.61566259 -0.59864089 -0.5884456\n",
            " -0.70515828 -0.61566259 -0.59864089 -0.5884456  -0.70515828 -0.61566259\n",
            " -0.59864089 -0.5884456  -0.70515828 -0.61566259 -0.59864089 -0.5884456 ]\n",
            "\n",
            "mean test CV score  = \n",
            "[-1.33679333 -1.33679333 -1.33679333 -1.33679333 -1.33679333 -1.33679333\n",
            " -1.33679333 -1.33679333 -1.33679333 -1.33679333 -1.33679333 -1.33679333\n",
            " -1.33679333 -1.33679333 -1.33679333 -1.33679333 -1.33679333 -1.33679333\n",
            " -1.33679333 -1.33679333 -1.33679333 -1.33679333 -1.33679333 -1.33679333\n",
            " -1.33679333 -1.33679333 -1.33679333 -1.33679333 -1.33679333 -1.33679333\n",
            " -1.33679333 -1.33679333 -1.33679333 -1.33679333 -1.33679333 -1.33679333\n",
            " -1.33679333 -1.33679333 -1.33679333 -1.33679333 -1.33679333 -1.33679333\n",
            " -1.33679333 -1.33679333 -1.16525937 -1.07339849 -1.01921271 -1.00220182\n",
            " -1.33679333 -1.33679333 -1.33679333 -1.33679333 -1.10652208 -1.10119901\n",
            " -1.10119901 -1.10119901 -0.88982052 -0.86383463 -0.8356343  -0.83546921\n",
            " -0.84325406 -0.81356238 -0.77846907 -0.77777866 -0.80602783 -0.77596448\n",
            " -0.73704963 -0.73578113 -0.77924308 -0.75181175 -0.71231634 -0.70986233\n",
            " -0.71521497 -0.71521497 -0.67632503 -0.67632503 -0.71213232 -0.71273067\n",
            " -0.6720423  -0.67228141 -0.70974326 -0.71230522 -0.67057863 -0.66976235\n",
            " -0.70910896 -0.71207724 -0.67020213 -0.6692162  -0.70855254 -0.71187958\n",
            " -0.66971494 -0.66379545 -0.708117   -0.71191898 -0.66529204 -0.6573882\n",
            " -0.70596714 -0.70186018 -0.65466722 -0.64210169 -0.70639149 -0.70103242\n",
            " -0.65320547 -0.64009879 -0.70649493 -0.69668921 -0.64905184 -0.63707924\n",
            " -0.70651253 -0.69536456 -0.647661   -0.63570804 -0.7065262  -0.6942406\n",
            " -0.64648611 -0.63458916 -0.70653619 -0.69342895 -0.64563399 -0.63379405\n",
            " -0.70581927 -0.66224708 -0.62377068 -0.61606407 -0.70581919 -0.66545341\n",
            " -0.62546372 -0.61731018 -0.70581912 -0.66792659 -0.6268084  -0.61835551\n",
            " -0.70583057 -0.66862299 -0.6271982  -0.61866905 -0.70585831 -0.66926535\n",
            " -0.62756714 -0.61896956 -0.70588643 -0.66980272 -0.62788581 -0.61923146\n",
            " -0.70563572 -0.64850542 -0.61324801 -0.60695286 -0.70562851 -0.64914361\n",
            " -0.61364809 -0.60727223 -0.70562192 -0.64976609 -0.61403879 -0.60758542\n",
            " -0.70561986 -0.64997015 -0.61416697 -0.60768828 -0.70561785 -0.6501726\n",
            " -0.61429413 -0.60779051 -0.7056161  -0.65035333 -0.6144077  -0.6078819\n",
            " -0.70558704 -0.64690214 -0.61199823 -0.605876   -0.70558704 -0.64690214\n",
            " -0.61199823 -0.605876   -0.70558704 -0.64690214 -0.61199823 -0.605876\n",
            " -0.70558704 -0.64690214 -0.61199823 -0.605876   -0.70558704 -0.64690214\n",
            " -0.61199823 -0.605876   -0.70558704 -0.64690214 -0.61199823 -0.605876\n",
            " -1.33679333 -1.33679333 -1.33679333 -1.33679333 -1.33679333 -1.33679333\n",
            " -1.33679333 -1.33679333 -1.33679333 -1.33679333 -1.33679333 -1.33679333\n",
            " -1.33679333 -1.33679333 -1.33679333 -1.33679333 -1.33679333 -1.33679333\n",
            " -1.33679333 -1.33679333 -1.33679333 -1.33679333 -1.33679333 -1.33679333\n",
            " -1.33679333 -1.33679333 -1.33679333 -1.33679333 -1.33679333 -1.33679333\n",
            " -1.33679333 -1.33679333 -1.33679333 -1.33679333 -1.33679333 -1.33679333\n",
            " -1.33679333 -1.33679333 -1.33679333 -1.33679333 -1.33679333 -1.33679333\n",
            " -1.33679333 -1.33679333 -1.16488505 -1.06230184 -1.00046129 -0.96318969\n",
            " -1.33679333 -1.33679333 -1.33679333 -1.33679333 -1.10540782 -1.09253556\n",
            " -1.09193254 -1.09193254 -0.88871586 -0.85050623 -0.84344519 -0.84263559\n",
            " -0.84214149 -0.8003682  -0.79289493 -0.7918084  -0.80490358 -0.76275766\n",
            " -0.75664436 -0.75658296 -0.77810576 -0.73848602 -0.73529871 -0.73740799\n",
            " -0.7140995  -0.7141454  -0.7141454  -0.7141454  -0.71090083 -0.71058932\n",
            " -0.71058932 -0.71058932 -0.70849464 -0.7088867  -0.70936971 -0.70936956\n",
            " -0.70785751 -0.70878899 -0.70953966 -0.70953965 -0.70729879 -0.70871474\n",
            " -0.70971196 -0.70971123 -0.70686158 -0.70869115 -0.70771342 -0.70647021\n",
            " -0.7055066  -0.70553069 -0.6847559  -0.67743918 -0.70546528 -0.70122146\n",
            " -0.68544824 -0.67778675 -0.70544049 -0.69437591 -0.6847513  -0.6766743\n",
            " -0.70543401 -0.69301907 -0.68458677 -0.67666541 -0.70542833 -0.69191104\n",
            " -0.68404186 -0.67611152 -0.70542389 -0.6910485  -0.68331679 -0.67527615\n",
            " -0.7054613  -0.62611358 -0.61267612 -0.60384122 -0.70544271 -0.62761364\n",
            " -0.61775817 -0.60910934 -0.7054317  -0.63006348 -0.62209138 -0.61379679\n",
            " -0.70542907 -0.63102479 -0.62339728 -0.61521371 -0.70542682 -0.63203748\n",
            " -0.62464278 -0.61655652 -0.70542508 -0.6329838  -0.62571655 -0.61770277\n",
            " -0.70546914 -0.61695288 -0.60028405 -0.59033452 -0.70546633 -0.61690534\n",
            " -0.60076155 -0.59086989 -0.70546369 -0.61688001 -0.60123748 -0.59140384\n",
            " -0.70546285 -0.61687635 -0.6013957  -0.59158147 -0.70546202 -0.61687505\n",
            " -0.60155371 -0.59175893 -0.70546129 -0.61687587 -0.60169576 -0.59191846\n",
            " -0.7054702  -0.61602043 -0.59901887 -0.58881338 -0.7054702  -0.61602043\n",
            " -0.59901887 -0.58881338 -0.7054702  -0.61602043 -0.59901887 -0.58881338\n",
            " -0.7054702  -0.61602043 -0.59901887 -0.58881338 -0.7054702  -0.61602043\n",
            " -0.59901887 -0.58881338 -0.7054702  -0.61602043 -0.59901887 -0.58881338]\n",
            "=========================================================================\n",
            "Best Estimator:\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('poly',\n",
              "                 PolynomialFeatures(degree=3, include_bias=True,\n",
              "                                    interaction_only=False, order='C')),\n",
              "                ('scaler',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('sk',\n",
              "                 SelectKBest(k=8,\n",
              "                             score_func=<function f_regression at 0x000001A19CEA5B88>)),\n",
              "                ('reg',\n",
              "                 ElasticNet(alpha=0, copy_X=True, fit_intercept=True,\n",
              "                            l1_ratio=0.9, max_iter=1000, normalize=False,\n",
              "                            positive=False, precompute=False, random_state=None,\n",
              "                            selection='cyclic', tol=0.0001,\n",
              "                            warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tY7A0oJ__fGr"
      },
      "source": [
        "> The mean CV scores for the `train` and `test` sets are very close and shows that we are not overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AOxs3AJV_hvS"
      },
      "source": [
        "-----\n",
        "#### 1.1.2.6 Decision Tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vimrNPP3_pJc"
      },
      "source": [
        "> `DecisionTreeRegressor` with `PolynomialFeatures` and `SelectKBest` methods for feature selection ||`GridSearchCV`||."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VQIjzvB5cg1_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 958
        },
        "outputId": "33f4c3ea-2a14-45a0-a86b-52448600034a"
      },
      "source": [
        "## Decision Tree\n",
        "tree_reg_start_time = time.perf_counter()\n",
        "tree_reg = Pipeline([(\"poly\", PolynomialFeatures()),\n",
        "                     (\"sk\", SelectKBest(score_func=f_regression)),\n",
        "                     (\"reg\", DecisionTreeRegressor())])\n",
        "tree_reg_param_grid = {\"reg__max_depth\": np.arange(3, 10),\n",
        "                       \"poly__degree\": [2, 3],\n",
        "                       \"sk__k\": [2, 4, 6, 8]}\n",
        "tree_reg_grid_search = GridSearchCV(tree_reg, tree_reg_param_grid, cv=5,\n",
        "                           scoring='neg_mean_squared_error', return_train_score=True)\n",
        "tree_reg_grid_search_fit = tree_reg_grid_search.fit(Xstrain, Ystrain)\n",
        "tree_reg_grid_search_fit_best = tree_reg_grid_search_fit.best_estimator_\n",
        "best_regressors.append(tree_reg_grid_search_fit_best)\n",
        "\n",
        "# Predict\n",
        "tree_reg_grid_search_pred = tree_reg_grid_search_fit_best.predict(Xstest)\n",
        "tree_reg_grid_search_pred_mse = mean_squared_error(Ystest, tree_reg_grid_search_pred)\n",
        "tree_reg_grid_search_pred_rmse = np.sqrt(tree_reg_grid_search_pred_mse)\n",
        "tree_reg_grid_search_pred_mae = mean_absolute_error(Ystest, tree_reg_grid_search_pred)\n",
        "tree_reg_grid_search_pred_r2 = r2_score(Ystest, tree_reg_grid_search_pred)\n",
        "tree_reg_compute_time = time.perf_counter() - tree_reg_start_time\n",
        "\n",
        "# Save the errors for final regression model comparisons\n",
        "best_regressors_cr[\"Decision Tree\"] = [tree_reg_grid_search_pred_rmse,\n",
        "                                       tree_reg_grid_search_pred_mse,\n",
        "                                       tree_reg_grid_search_pred_mae,\n",
        "                                       tree_reg_grid_search_pred_r2,\n",
        "                                       tree_reg_grid_search_fit.best_params_[\"poly__degree\"],\n",
        "                                       tree_reg_grid_search_fit.best_params_[\"sk__k\"],\n",
        "                                       \"-\", \"-\", tree_reg_compute_time]\n",
        "\n",
        "# Report results\n",
        "print(\"Best Parameters:\\n\"+ 16*\"=\"); get_best_parameters(tree_reg_grid_search_fit)\n",
        "print(25*\"=\" + \"\\nComputation_time = %1.3f\\n\" %tree_reg_compute_time + 38*\"=\")\n",
        "print(\"Decision Tree Regression RMSE = %.4f\" %tree_reg_grid_search_pred_rmse)\n",
        "print(\"Decision Tree Regression MSE  = %.4f\" %tree_reg_grid_search_pred_mse)\n",
        "print(\"Decision Tree Regression MAE  = %.4f\" %tree_reg_grid_search_pred_mae); print(38*\"=\")\n",
        "print(\"mean train CV score = \\n{}\".format(tree_reg_grid_search.cv_results_[\"mean_train_score\"]))\n",
        "print(\"\\nmean test CV score  = \\n{}\".format(tree_reg_grid_search.cv_results_[\"mean_test_score\"]))\n",
        "print(72*\"=\" + \"\\nDetails:\\n\"); tree_reg_grid_search_fit_best"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Parameters:\n",
            "================\n",
            "poly__degree = 2\n",
            "reg__max_depth = 7\n",
            "sk__k = 8\n",
            "=========================\n",
            "Computation_time = 35.343\n",
            "======================================\n",
            "Decision Tree Regression RMSE = 0.7486\n",
            "Decision Tree Regression MSE  = 0.5603\n",
            "Decision Tree Regression MAE  = 0.5388\n",
            "======================================\n",
            "mean train CV score = \n",
            "[-0.68939232 -0.68939232 -0.65936444 -0.65565006 -0.67757963 -0.67709465\n",
            " -0.61714709 -0.61222599 -0.66918545 -0.65943767 -0.58645804 -0.57651271\n",
            " -0.6597493  -0.64209005 -0.54803378 -0.53099296 -0.6454054  -0.62068347\n",
            " -0.51352149 -0.48993164 -0.62969853 -0.59324582 -0.47544517 -0.44862666\n",
            " -0.60969291 -0.56054002 -0.43563289 -0.40335379 -0.68934411 -0.68876238\n",
            " -0.68876238 -0.68881531 -0.67698607 -0.67531368 -0.67254537 -0.67291354\n",
            " -0.66937135 -0.65463363 -0.65057239 -0.65049034 -0.65945583 -0.63184775\n",
            " -0.62667948 -0.62749577 -0.64541582 -0.60001752 -0.60182234 -0.60144047\n",
            " -0.62782425 -0.56263473 -0.56692824 -0.5649062  -0.60614927 -0.51934738\n",
            " -0.52943078 -0.52663546]\n",
            "\n",
            "mean test CV score  = \n",
            "[-0.69994112 -0.69994112 -0.67400574 -0.6693341  -0.69004472 -0.69009999\n",
            " -0.6384505  -0.63548948 -0.69273568 -0.68494552 -0.62121242 -0.61070756\n",
            " -0.69746713 -0.68394637 -0.60188195 -0.58882853 -0.7043263  -0.68160234\n",
            " -0.60097909 -0.58681565 -0.71737508 -0.68613046 -0.60916293 -0.58891791\n",
            " -0.72882473 -0.68836374 -0.63345615 -0.61505791 -0.69888625 -0.70031704\n",
            " -0.70031704 -0.70000442 -0.68674808 -0.69042569 -0.69084378 -0.68976111\n",
            " -0.69062522 -0.681189   -0.6747254  -0.67608975 -0.69640315 -0.67222788\n",
            " -0.6680922  -0.67036296 -0.70669774 -0.66481487 -0.66853295 -0.66875037\n",
            " -0.72766113 -0.66053024 -0.66956106 -0.66480102 -0.7400197  -0.65625093\n",
            " -0.66810908 -0.66837688]\n",
            "========================================================================\n",
            "Details:\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('poly',\n",
              "                 PolynomialFeatures(degree=2, include_bias=True,\n",
              "                                    interaction_only=False, order='C')),\n",
              "                ('sk',\n",
              "                 SelectKBest(k=8,\n",
              "                             score_func=<function f_regression at 0x000001A19CEA5B88>)),\n",
              "                ('reg',\n",
              "                 DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse',\n",
              "                                       max_depth=7, max_features=None,\n",
              "                                       max_leaf_nodes=None,\n",
              "                                       min_impurity_decrease=0.0,\n",
              "                                       min_impurity_split=None,\n",
              "                                       min_samples_leaf=1, min_samples_split=2,\n",
              "                                       min_weight_fraction_leaf=0.0,\n",
              "                                       presort='deprecated', random_state=None,\n",
              "                                       splitter='best'))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QzjVeJUSBORT"
      },
      "source": [
        "> The difference between the mean CV scores for the `train` and `test` sets is more than previous regressors but still it is small."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NpUw_WbCBOIR"
      },
      "source": [
        "-----\n",
        "#### 1.1.2.7 Random Forests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TtKQD_2mBnAS"
      },
      "source": [
        "> We run `RandomForestRegressor` regression, having added the `PolynomialFeatures` and `SelectKBest` methods to the pipeline for feature selection but this time we use `RandomizedSearchCV` to tune the parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JpH8sprcjhhT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "fc0dc5b7-a3b2-4aaf-fe0d-503c279b85d5"
      },
      "source": [
        "## Random Forests Tree I (RandomizedSearchCV)\n",
        "forest_reg_start_time = time.perf_counter()\n",
        "forest_reg = RandomForestRegressor()\n",
        "forest_reg_param_distrib = {\"n_estimators\": randint(low=5, high=100),\n",
        "                            \"max_features\": randint(low=2, high=8)}\n",
        "forest_reg_rand_search = RandomizedSearchCV(forest_reg, forest_reg_param_distrib, cv=5, n_iter=10,\n",
        "                                            scoring='neg_mean_squared_error', return_train_score=True)\n",
        "forest_reg_rand_search_fit = forest_reg_rand_search.fit(Xstrain, Ystrain)\n",
        "forest_reg_rand_search_fit_best = forest_reg_rand_search_fit.best_estimator_\n",
        "best_regressors.append(forest_reg_rand_search_fit_best)\n",
        "\n",
        "# Predict\n",
        "forest_reg_rand_search_pred = forest_reg_rand_search_fit_best.predict(Xstest)\n",
        "forest_reg_rand_search_pred_mse = mean_squared_error(Ystest, forest_reg_rand_search_pred)\n",
        "forest_reg_rand_search_pred_rmse = np.sqrt(forest_reg_rand_search_pred_mse)\n",
        "forest_reg_rand_search_pred_mae = mean_absolute_error(Ystest, forest_reg_rand_search_pred)\n",
        "forest_reg_rand_search_pred_r2 = r2_score(Ystest, forest_reg_rand_search_pred)\n",
        "forest_reg_compute_time = time.perf_counter() - forest_reg_start_time\n",
        "\n",
        "# Save the errors for final regression model comparisons\n",
        "best_regressors_cr[\"Random Forest\"] = [forest_reg_rand_search_pred_rmse,\n",
        "                                       forest_reg_rand_search_pred_mse,\n",
        "                                       forest_reg_rand_search_pred_mae,\n",
        "                                       forest_reg_rand_search_pred_r2,\n",
        "                                       \"-\", \"-\", \"-\", \"-\", forest_reg_compute_time]\n",
        "\n",
        "# Report results\n",
        "print(\"Best Parameters:\\n\"+ 16*\"=\"); get_best_parameters(forest_reg_rand_search_fit)\n",
        "print(25*\"=\" + \"\\nComputation_time = %1.2f\\n\" %forest_reg_compute_time + 38*\"=\")\n",
        "print(\"Random Forest Regression RMSE = %.4f\" %forest_reg_rand_search_pred_rmse)\n",
        "print(\"Random Forest Regression MSE  = %.4f\" %forest_reg_rand_search_pred_mse)\n",
        "print(\"Random Forest Regression MAE  = %.4f\" %forest_reg_rand_search_pred_mae); print(38*\"=\")\n",
        "print(\"mean train CV score = \\n{}\".format(forest_reg_rand_search.cv_results_[\"mean_train_score\"]))\n",
        "print(\"\\nmean test CV score  = \\n{}\".format(forest_reg_rand_search.cv_results_[\"mean_test_score\"]))\n",
        "print(72*\"=\" + \"\\nDetails:\\n\"); forest_reg_rand_search_fit_best"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Parameters:\n",
            "================\n",
            "max_features = 3\n",
            "n_estimators = 59\n",
            "=========================\n",
            "Computation_time = 164.66\n",
            "======================================\n",
            "Random Forest Regression RMSE = 0.4803\n",
            "Random Forest Regression MSE  = 0.2307\n",
            "Random Forest Regression MAE  = 0.3212\n",
            "======================================\n",
            "mean train CV score = \n",
            "[-0.0360674  -0.03678531 -0.03585972 -0.04077506 -0.0386582  -0.03714244\n",
            " -0.06038708 -0.0405081  -0.0373122  -0.03610858]\n",
            "\n",
            "mean test CV score  = \n",
            "[-0.24704466 -0.25464819 -0.25200492 -0.25814358 -0.25361185 -0.25234119\n",
            " -0.2980926  -0.26552585 -0.26120998 -0.25032598]\n",
            "========================================================================\n",
            "Details:\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
              "                      max_depth=None, max_features=3, max_leaf_nodes=None,\n",
              "                      max_samples=None, min_impurity_decrease=0.0,\n",
              "                      min_impurity_split=None, min_samples_leaf=1,\n",
              "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
              "                      n_estimators=59, n_jobs=None, oob_score=False,\n",
              "                      random_state=None, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GsOAFvuEEnRB"
      },
      "source": [
        "> We have the widest gap between the mean CV scores for the `train` and `test` sets compared to the previous regressors. However, the `test` CV scores are smaller compared to the previous models but chances are we are not overfitting. Let's try `RandomForestRegressor` using `GridSearchCV` to what we get."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lf732SKKHqQl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "e3e7afd9-dd84-4a60-b49e-0b49b655a4a0"
      },
      "source": [
        "## Random Forest II (GridSearchCV)\n",
        "forest_reg_II_start_time = time.perf_counter()\n",
        "forest_reg_II = RandomForestRegressor()\n",
        "forest_reg_param_grid = {\"n_estimators\": [5, 50, 80, 100],\n",
        "                         \"max_features\": [2, 4, 6, 8]}\n",
        "forest_reg_grid_search = GridSearchCV(forest_reg_II, forest_reg_param_grid, cv=5,\n",
        "                           scoring='neg_mean_squared_error', return_train_score=True)\n",
        "forest_reg_grid_search_fit = forest_reg_grid_search.fit(Xstrain, Ystrain)\n",
        "forest_reg_grid_search_fit_best = forest_reg_grid_search_fit.best_estimator_\n",
        "best_regressors.append(forest_reg_grid_search_fit_best)\n",
        "\n",
        "# Predict\n",
        "forest_reg_grid_search_pred = forest_reg_grid_search_fit_best.predict(Xstest)\n",
        "forest_reg_grid_search_pred_mse = mean_squared_error(Ystest, forest_reg_grid_search_pred)\n",
        "forest_reg_grid_search_pred_rmse = np.sqrt(forest_reg_grid_search_pred_mse)\n",
        "forest_reg_grid_search_pred_mae = mean_absolute_error(Ystest, forest_reg_grid_search_pred)\n",
        "forest_reg_grid_search_pred_r2 = r2_score(Ystest, forest_reg_grid_search_pred)\n",
        "forest_reg_II_compute_time = time.perf_counter() - forest_reg_II_start_time\n",
        "\n",
        "# Save the errors for final regression model comparisons\n",
        "best_regressors_cr[\"Random Forest II\"] = [forest_reg_grid_search_pred_rmse,\n",
        "                                          forest_reg_grid_search_pred_mse,\n",
        "                                          forest_reg_grid_search_pred_mae,\n",
        "                                          forest_reg_grid_search_pred_r2,\n",
        "                                          \"-\", \"-\",\"-\", \"-\", forest_reg_II_compute_time]\n",
        "\n",
        "# Report errors and scores\n",
        "print(\"Best Parameters:\\n\"+ 16*\"=\"); get_best_parameters(forest_reg_grid_search_fit)\n",
        "print(25*\"=\" + \"\\nComputation_time = %1.2f\\n\" %forest_reg_II_compute_time + 41*\"=\")\n",
        "print(\"Random Forest II Regression RMSE = %.4f\" %forest_reg_grid_search_pred_rmse)\n",
        "print(\"Random Forest II Regression MSE  = %.4f\" %forest_reg_grid_search_pred_mse)\n",
        "print(\"Random Forest II Regression MAE  = %.4f\" %forest_reg_grid_search_pred_mae); print(41*\"=\")\n",
        "print(\"mean train CV score = \\n{}\".format(forest_reg_grid_search.cv_results_[\"mean_train_score\"]))\n",
        "print(\"\\nmean test CV score  = \\n{}\".format(forest_reg_grid_search.cv_results_[\"mean_test_score\"]))\n",
        "print(72*\"=\" + \"\\nDetails:\\n\"); forest_reg_grid_search_fit_best"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Parameters:\n",
            "================\n",
            "max_features = 2\n",
            "n_estimators = 100\n",
            "=========================\n",
            "Computation_time = 300.48\n",
            "=========================================\n",
            "Random Forest II Regression RMSE = 0.4868\n",
            "Random Forest II Regression MSE  = 0.2370\n",
            "Random Forest II Regression MAE  = 0.3301\n",
            "=========================================\n",
            "mean train CV score = \n",
            "[-0.07286395 -0.03758424 -0.03610891 -0.0353696  -0.07004139 -0.03724119\n",
            " -0.0358779  -0.03571492 -0.07222097 -0.03854001 -0.0371497  -0.03662915\n",
            " -0.07197942 -0.03939137 -0.03757846 -0.03712628]\n",
            "\n",
            "mean test CV score  = \n",
            "[-0.32239179 -0.25364076 -0.25131963 -0.24864769 -0.3190279  -0.25303393\n",
            " -0.25105702 -0.25013142 -0.32130209 -0.2637834  -0.25884954 -0.25809588\n",
            " -0.32637641 -0.26729843 -0.26342059 -0.26115364]\n",
            "========================================================================\n",
            "Details:\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
              "                      max_depth=None, max_features=2, max_leaf_nodes=None,\n",
              "                      max_samples=None, min_impurity_decrease=0.0,\n",
              "                      min_impurity_split=None, min_samples_leaf=1,\n",
              "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
              "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
              "                      random_state=None, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fS0hGK4EN65a"
      },
      "source": [
        "> The difference between the mean CV scores for the `train` and `test` sets is more `RandomizedSearchCV` version but MSE and MAE are greater. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OIORqx4kEall"
      },
      "source": [
        "-----\n",
        "### 1.1.3 Comparing Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7ISnF-PxPgCR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "549d2170-d56d-4417-e814-7db9544fcfaa"
      },
      "source": [
        "## Compare the predictions with Ystest\n",
        "print(\"Predictions (same order as before):\\n\")\n",
        "for regr in best_regressors:\n",
        "  print(regr.predict(Xstest).round(3))\n",
        "print(\"\\nYstest:\\n\" + str(Ystest.round(3)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predictions (same order as before):\n",
            "\n",
            "[2.342 1.596 0.852 ... 2.558 3.342 4.59 ]\n",
            "[2.34  1.596 0.857 ... 2.556 3.343 4.587]\n",
            "[2.288 1.532 1.223 ... 2.258 3.835 4.18 ]\n",
            "[2.342 1.596 0.852 ... 2.558 3.342 4.59 ]\n",
            "[2.288 1.532 1.223 ... 2.258 3.835 4.18 ]\n",
            "[1.962 1.934 1.261 ... 1.962 3.835 4.672]\n",
            "[1.897 1.731 0.771 ... 2.283 3.456 4.706]\n",
            "[1.731 1.732 0.85  ... 2.383 3.517 4.57 ]\n",
            "\n",
            "Ystest:\n",
            "[2.938 1.75  0.574 ... 2.359 3.505 5.   ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DCkj15fU1rKa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "974faf1e-05e3-4765-df19-5522361ac496"
      },
      "source": [
        "## Compare regressors\n",
        "best_regressors_cr_df = pd.DataFrame.from_dict(best_regressors_cr, orient='index',\n",
        "                                               columns=[\"RMSE\", \"MSE\", \"MAE\", \"R2\", \"Poly-Deg\",\n",
        "                                                        \"K-Best\", \"alpha\", \"L1-Ratio\",\"Comp-Time\"])\n",
        "best_regressors_cr_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RMSE</th>\n",
              "      <th>MSE</th>\n",
              "      <th>MAE</th>\n",
              "      <th>R2</th>\n",
              "      <th>Poly-Deg</th>\n",
              "      <th>K-Best</th>\n",
              "      <th>alpha</th>\n",
              "      <th>L1-Ratio</th>\n",
              "      <th>Comp-Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Linear</th>\n",
              "      <td>0.712040</td>\n",
              "      <td>0.507001</td>\n",
              "      <td>0.524339</td>\n",
              "      <td>0.613162</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>5.534568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ridge</th>\n",
              "      <td>0.712024</td>\n",
              "      <td>0.506978</td>\n",
              "      <td>0.524374</td>\n",
              "      <td>0.613179</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-</td>\n",
              "      <td>42.863136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LASSO</th>\n",
              "      <td>0.750433</td>\n",
              "      <td>0.563149</td>\n",
              "      <td>0.556163</td>\n",
              "      <td>0.570321</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>-</td>\n",
              "      <td>49.855419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LARS</th>\n",
              "      <td>0.712040</td>\n",
              "      <td>0.507001</td>\n",
              "      <td>0.524339</td>\n",
              "      <td>0.613162</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>-</td>\n",
              "      <td>43.752914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Elastic Net</th>\n",
              "      <td>0.750433</td>\n",
              "      <td>0.563149</td>\n",
              "      <td>0.556163</td>\n",
              "      <td>0.570321</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>298.972989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Decision Tree</th>\n",
              "      <td>0.748553</td>\n",
              "      <td>0.560332</td>\n",
              "      <td>0.538830</td>\n",
              "      <td>0.572471</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>35.342943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random Forest</th>\n",
              "      <td>0.480346</td>\n",
              "      <td>0.230732</td>\n",
              "      <td>0.321237</td>\n",
              "      <td>0.823953</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>164.659506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random Forest II</th>\n",
              "      <td>0.486789</td>\n",
              "      <td>0.236963</td>\n",
              "      <td>0.330119</td>\n",
              "      <td>0.819199</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>300.483322</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      RMSE       MSE       MAE        R2 Poly-Deg K-Best  \\\n",
              "Linear            0.712040  0.507001  0.524339  0.613162        2      6   \n",
              "Ridge             0.712024  0.506978  0.524374  0.613179        2      6   \n",
              "LASSO             0.750433  0.563149  0.556163  0.570321        3      8   \n",
              "LARS              0.712040  0.507001  0.524339  0.613162        2      6   \n",
              "Elastic Net       0.750433  0.563149  0.556163  0.570321        3      8   \n",
              "Decision Tree     0.748553  0.560332  0.538830  0.572471        2      8   \n",
              "Random Forest     0.480346  0.230732  0.321237  0.823953        -      -   \n",
              "Random Forest II  0.486789  0.236963  0.330119  0.819199        -      -   \n",
              "\n",
              "                 alpha L1-Ratio   Comp-Time  \n",
              "Linear               -        -    5.534568  \n",
              "Ridge             0.01        -   42.863136  \n",
              "LASSO                0        -   49.855419  \n",
              "LARS                 0        -   43.752914  \n",
              "Elastic Net          0      0.9  298.972989  \n",
              "Decision Tree        -        -   35.342943  \n",
              "Random Forest        -        -  164.659506  \n",
              "Random Forest II     -        -  300.483322  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sm6bpA2vu394"
      },
      "source": [
        "> As we can see, `RandomForestRegressor` gives the lowest RMSE and the highest `R_Squared`.\n"
      ]
    }
  ]
}